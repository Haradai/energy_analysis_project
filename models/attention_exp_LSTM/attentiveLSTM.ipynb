{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"mps\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.attention_exp_LSTM.dataset import energyProject_dataset\n",
    "from models.attention_exp_LSTM.network import attentiveLSTM_model\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import yaml\n",
    "import wandb\n",
    "from typing import Dict\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nested_dict(original_dict):\n",
    "    nested_dict = {}\n",
    "    for key, value in original_dict.items():\n",
    "        parts = key.split(\".\")\n",
    "        d = nested_dict\n",
    "        for part in parts[:-1]:\n",
    "            if part not in d:\n",
    "                d[part] = {}\n",
    "            d = d[part]\n",
    "        d[parts[-1]] = value\n",
    "    return nested_dict\n",
    "\n",
    "\n",
    "#load dataset object file\n",
    "with (open('data/dataset_class.pkl', \"rb\")) as openfile:\n",
    "    dataset = pickle.load(openfile)\n",
    "\n",
    "dataset.activitivity_encoding_mode = 2 #or any value\n",
    "# Splitting the dataset into training and validation sets\n",
    "train_data, val_data = train_test_split(dataset, test_size=0.2, random_state=42, shuffle=False )\n",
    "\n",
    "train_dataloader = DataLoader(train_data, batch_size=100, shuffle=False) #!!! useful to shuffle?\n",
    "val_dataloader = DataLoader(val_data, batch_size=100, shuffle=False)\n",
    "whole_dataloader = DataLoader(dataset, batch_size=len(dataset), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup wandb stuff\n",
    "with open('models/attention_exp_LSTM/config.yaml', 'r') as stream:\n",
    "    try:\n",
    "        sweep_config = yaml.safe_load(stream)\n",
    "    except yaml.YAMLError as exc:\n",
    "        print(exc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sweep to find best hyperparams:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_idx=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = dataset.column_scalers[dataset.target_labels[y_idx]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(config: Dict = None):\n",
    "    with wandb.init(config=config) as run:\n",
    "        run.name = \"ENERGY_METER_0\"\n",
    "        config = wandb.config\n",
    "        config = nested_dict(config)\n",
    "        optimizer_config = config[\"optimizer\"]\n",
    "        model = attentiveLSTM_model(espai_emb_dim=config[\"espai_emb_dim\"],hidden_dim=config['hidden_size'],lstm_nl=config['num_layers'],nheads=config['heads'],attnFCdim=config['attnFCdim'])\n",
    "        model.init_weights()\n",
    "        model.to(device)\n",
    "\n",
    "        criterion =  nn.MSELoss()\n",
    "\n",
    "        if optimizer_config[\"type\"] == 'adam':\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr = optimizer_config['lr'])\n",
    "\n",
    "        num_epochs = 80\n",
    "        best_loss = float('inf')\n",
    "        for epoch in range(num_epochs):\n",
    "            model.train()\n",
    "            training_losses = [] # renamed from epoch_losses\n",
    "            progress_bar = tqdm(enumerate(train_dataloader), desc=f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "            for batch,data in progress_bar:\n",
    "                ocu_emb, espai_enc, general_data = data[\"ocu_ber_emb\"].float().to(device) ,data[\"espai_enc\"].float().to(device) ,data[\"general_data\"].float().to(device)\n",
    "                y = data[\"y\"][:,y_idx].float().to(device) #we'll do one counter for now\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                #current batch size size\n",
    "                b_sz = ocu_emb.shape[0]\n",
    "\n",
    "                #note the dataloader with a batch of 100 when reachs the end expects a batch of 60\n",
    "                h, c = model.init_hidden(b_sz) # Start with a new state in each batch            \n",
    "                h = h.to(device)\n",
    "                c = c.to(device)\n",
    "                y_pred, h,c= model(ocu_emb, espai_enc, general_data, h, c)\n",
    "                y_pred = y_pred[:,0,0]\n",
    "\n",
    "                loss = criterion(y_pred,y)  #cross entropy loss needs (N,C,seq_lenght)\n",
    "                loss.backward()\n",
    "                optimizer.step()    \n",
    "\n",
    "                training_losses.append(loss.item())\n",
    "                progress_bar.set_postfix({'Batch Loss': loss.item()})\n",
    "\n",
    "            average_training_loss = sum(training_losses) / len(training_losses) # renamed from avg_loss\n",
    "            #average_training_loss = np.power(dataset.denormalize_values(np.sqrt(average_training_loss),scaler),2)\n",
    "            wandb.log({'Train_Epoch_Loss': average_training_loss})\n",
    "\n",
    "            model.eval()  \n",
    "            with torch.no_grad():  \n",
    "                validation_losses = [] # renamed from val_losses\n",
    "                for batch in tqdm(val_dataloader, desc='Validation'):\n",
    "                    ocu_emb, espai_enc, general_data = data[\"ocu_ber_emb\"].float().to(device) ,data[\"espai_enc\"].float().to(device) ,data[\"general_data\"].float().to(device)\n",
    "                    y = data[\"y\"][:,y_idx].float().to(device) #we'll do one counter for now\n",
    "\n",
    "                    #current batch size size\n",
    "                    b_sz = ocu_emb.shape[0]\n",
    "\n",
    "                    #note the dataloader with a batch of 100 when reachs the end expects a batch of 60\n",
    "                    h, c = model.init_hidden(b_sz) # Start with a new state in each batch            \n",
    "                    h = h.to(device)\n",
    "                    c = c.to(device)\n",
    "                    y_pred, h,c= model(ocu_emb, espai_enc, general_data, h, c)\n",
    "                    y_pred = y_pred[:,0,0]\n",
    "                    \n",
    "                    loss = criterion(y_pred,y) \n",
    "                    validation_losses.append(loss.item())\n",
    "\n",
    "                average_validation_loss = sum(validation_losses) / len(validation_losses) # renamed from avg_val_loss\n",
    "                #average_validation_loss = np.power(dataset.denormalize_values(np.sqrt(average_validation_loss),scaler),2)\n",
    "                wandb.log({'Validation_Epoch_Loss': average_validation_loss})\n",
    "\n",
    "            if average_training_loss < best_loss:\n",
    "                best_loss = average_training_loss\n",
    "                torch.save(model.state_dict(), 'models/attention_exp_LSTM/tranformLSTM.pt')\n",
    "                wandb.save('gru_model.pt')\n",
    "                print(f\"Model saved at {'gru_model.pt'}\")\n",
    "\n",
    "        wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mharadai\u001b[0m (\u001b[33menergy_project_uab\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    }
   ],
   "source": [
    "!wandb login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: aic13z0d\n",
      "Sweep URL: https://wandb.ai/energy_project_uab/energy_project_uab/sweeps/aic13z0d\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'aic13z0d'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sweep_id = wandb.sweep(sweep_config, project=\"energy_project_uab\")\n",
    "sweep_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 2c7x004j with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tattnFCdim: 1000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tespai_emb_dim: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \theads: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 1000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: {'lr': 0.00711967013233076, 'type': 'adam'}\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mharadai\u001b[0m (\u001b[33menergy_project_uab\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/josepsmachine/Documents/UNI/SYNTHS_PROJECT/energy_analysis_project/wandb/run-20230523_152304-2c7x004j</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/energy_project_uab/energy_project_uab/runs/2c7x004j' target=\"_blank\">winter-sweep-1</a></strong> to <a href='https://wandb.ai/energy_project_uab/energy_project_uab' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/energy_project_uab/energy_project_uab/sweeps/aic13z0d' target=\"_blank\">https://wandb.ai/energy_project_uab/energy_project_uab/sweeps/aic13z0d</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/energy_project_uab/energy_project_uab' target=\"_blank\">https://wandb.ai/energy_project_uab/energy_project_uab</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/energy_project_uab/energy_project_uab/sweeps/aic13z0d' target=\"_blank\">https://wandb.ai/energy_project_uab/energy_project_uab/sweeps/aic13z0d</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/energy_project_uab/energy_project_uab/runs/2c7x004j' target=\"_blank\">https://wandb.ai/energy_project_uab/energy_project_uab/runs/2c7x004j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/80: 71it [01:04,  1.09it/s, Batch Loss=0.102] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 23.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved at gru_model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/80: 71it [01:05,  1.08it/s, Batch Loss=0.174] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 22.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved at gru_model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/80: 71it [01:04,  1.10it/s, Batch Loss=0.0581]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 23.33it/s]\n",
      "Epoch 4/80: 71it [01:07,  1.05it/s, Batch Loss=0.0471]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 23.16it/s]\n",
      "Epoch 5/80: 71it [01:05,  1.09it/s, Batch Loss=0.0228]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 24.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved at gru_model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/80: 71it [01:04,  1.09it/s, Batch Loss=0.0027]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 23.77it/s]\n",
      "Epoch 7/80: 71it [01:05,  1.09it/s, Batch Loss=0.00904]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 22.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved at gru_model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/80: 71it [01:04,  1.10it/s, Batch Loss=0.011] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 23.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved at gru_model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/80: 71it [01:03,  1.11it/s, Batch Loss=0.0288]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 24.53it/s]\n",
      "Epoch 10/80: 71it [01:03,  1.11it/s, Batch Loss=0.00459]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 23.73it/s]\n",
      "Epoch 11/80: 71it [01:03,  1.11it/s, Batch Loss=0.00321]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 23.59it/s]\n",
      "Epoch 12/80: 71it [01:05,  1.09it/s, Batch Loss=0.01]  \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 24.42it/s]\n",
      "Epoch 13/80: 71it [01:03,  1.12it/s, Batch Loss=0.0123]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 24.79it/s]\n",
      "Epoch 14/80: 71it [01:03,  1.12it/s, Batch Loss=0.0168]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 25.09it/s]\n",
      "Epoch 15/80: 71it [01:03,  1.11it/s, Batch Loss=0.0177]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 24.59it/s]\n",
      "Epoch 16/80: 71it [01:04,  1.11it/s, Batch Loss=0.102] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 23.78it/s]\n",
      "Epoch 17/80: 71it [01:03,  1.11it/s, Batch Loss=0.008] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 22.86it/s]\n",
      "Epoch 18/80: 71it [01:03,  1.12it/s, Batch Loss=0.0109]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 23.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved at gru_model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/80: 71it [01:03,  1.11it/s, Batch Loss=0.0115]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 23.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved at gru_model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/80: 71it [01:03,  1.12it/s, Batch Loss=0.0125]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 24.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved at gru_model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/80: 71it [01:03,  1.12it/s, Batch Loss=0.0108]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 23.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved at gru_model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/80: 71it [01:02,  1.13it/s, Batch Loss=0.0181]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 24.54it/s]\n",
      "Epoch 23/80: 71it [01:02,  1.13it/s, Batch Loss=0.0163]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 24.82it/s]\n",
      "Epoch 24/80: 71it [01:02,  1.13it/s, Batch Loss=0.0206]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 23.59it/s]\n",
      "Epoch 25/80: 71it [01:03,  1.12it/s, Batch Loss=0.0154]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 25.30it/s]\n",
      "Epoch 26/80: 71it [01:03,  1.12it/s, Batch Loss=0.0173]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 24.04it/s]\n",
      "Epoch 27/80: 71it [01:03,  1.11it/s, Batch Loss=0.0135]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 23.94it/s]\n",
      "Epoch 28/80: 71it [01:03,  1.12it/s, Batch Loss=0.0116]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 23.25it/s]\n",
      "Epoch 29/80: 71it [01:03,  1.12it/s, Batch Loss=0.0118]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 23.77it/s]\n",
      "Epoch 30/80: 71it [01:04,  1.10it/s, Batch Loss=0.00478]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 24.86it/s]\n",
      "Epoch 31/80: 71it [01:04,  1.10it/s, Batch Loss=0.017] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 24.35it/s]\n",
      "Epoch 32/80: 71it [01:03,  1.11it/s, Batch Loss=0.0145]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 22.96it/s]\n",
      "Epoch 33/80: 71it [01:04,  1.10it/s, Batch Loss=0.0218]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 22.94it/s]\n",
      "Epoch 34/80: 71it [01:04,  1.10it/s, Batch Loss=0.0171]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 24.17it/s]\n",
      "Epoch 35/80: 71it [01:05,  1.08it/s, Batch Loss=0.0143]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 21.89it/s]\n",
      "Epoch 36/80: 71it [01:09,  1.02it/s, Batch Loss=0.0117]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 18.60it/s]\n",
      "Epoch 37/80: 71it [01:12,  1.03s/it, Batch Loss=0.012] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 23.56it/s]\n",
      "Epoch 38/80: 71it [01:08,  1.03it/s, Batch Loss=0.0109]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 23.44it/s]\n",
      "Epoch 39/80: 71it [01:05,  1.08it/s, Batch Loss=0.01]  \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 24.15it/s]\n",
      "Epoch 40/80: 71it [01:04,  1.10it/s, Batch Loss=0.0142]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 24.14it/s]\n",
      "Epoch 41/80: 71it [01:11,  1.00s/it, Batch Loss=0.0165]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 25.15it/s]\n",
      "Epoch 42/80: 71it [01:05,  1.09it/s, Batch Loss=0.0105]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 23.61it/s]\n",
      "Epoch 43/80: 71it [01:05,  1.09it/s, Batch Loss=0.015] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 24.14it/s]\n",
      "Epoch 44/80: 71it [01:05,  1.08it/s, Batch Loss=0.114] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 23.82it/s]\n",
      "Epoch 45/80: 71it [01:03,  1.12it/s, Batch Loss=0.0434]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 24.23it/s]\n",
      "Epoch 46/80: 71it [01:04,  1.10it/s, Batch Loss=0.0139]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 22.68it/s]\n",
      "Epoch 47/80: 71it [01:05,  1.09it/s, Batch Loss=0.0264]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 22.29it/s]\n",
      "Epoch 48/80: 71it [01:04,  1.11it/s, Batch Loss=0.0138]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 24.46it/s]\n",
      "Epoch 49/80: 71it [01:03,  1.11it/s, Batch Loss=0.0223]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 23.95it/s]\n",
      "Epoch 50/80: 71it [01:03,  1.11it/s, Batch Loss=0.0162]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 23.98it/s]\n",
      "Epoch 51/80: 71it [01:09,  1.02it/s, Batch Loss=0.0271]\n",
      "Validation: 100%|██████████| 18/18 [00:01<00:00, 17.17it/s]\n",
      "Epoch 52/80: 71it [01:08,  1.04it/s, Batch Loss=0.0223]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 22.31it/s]\n",
      "Epoch 53/80: 71it [01:07,  1.05it/s, Batch Loss=0.0141]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 25.03it/s]\n",
      "Epoch 54/80: 71it [01:12,  1.02s/it, Batch Loss=0.0206]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 21.05it/s]\n",
      "Epoch 55/80: 71it [01:05,  1.08it/s, Batch Loss=0.0224]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 24.25it/s]\n",
      "Epoch 56/80: 71it [01:04,  1.09it/s, Batch Loss=0.021] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 24.35it/s]\n",
      "Epoch 57/80: 71it [01:05,  1.09it/s, Batch Loss=0.0201]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 25.02it/s]\n",
      "Epoch 58/80: 71it [01:05,  1.08it/s, Batch Loss=0.0185]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 24.24it/s]\n",
      "Epoch 59/80: 71it [01:05,  1.09it/s, Batch Loss=0.0467]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 23.89it/s]\n",
      "Epoch 60/80: 71it [01:05,  1.09it/s, Batch Loss=0.0255]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 23.46it/s]\n",
      "Epoch 61/80: 71it [01:06,  1.07it/s, Batch Loss=0.0157]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 20.89it/s]\n",
      "Epoch 62/80: 71it [01:05,  1.08it/s, Batch Loss=0.0466]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 25.09it/s]\n",
      "Epoch 63/80: 71it [01:05,  1.09it/s, Batch Loss=0.019] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 23.50it/s]\n",
      "Epoch 64/80: 71it [01:05,  1.09it/s, Batch Loss=0.016] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 23.92it/s]\n",
      "Epoch 65/80: 71it [01:05,  1.09it/s, Batch Loss=0.0503]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 24.74it/s]\n",
      "Epoch 66/80: 71it [01:05,  1.09it/s, Batch Loss=0.0376]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 24.49it/s]\n",
      "Epoch 67/80: 71it [01:05,  1.09it/s, Batch Loss=0.0359]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 23.83it/s]\n",
      "Epoch 68/80: 48it [00:45,  1.00it/s, Batch Loss=0.0201]\u001b[34m\u001b[1mwandb\u001b[0m: Ctrl + C detected. Stopping sweep.\n"
     ]
    }
   ],
   "source": [
    "wandb.agent(sweep_id, function=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_consumption(model,dataloader,y_idx):\n",
    "    real = []\n",
    "    pred = []\n",
    "    h, c = model.init_hidden(dataloader.batch_size) # Start with a new state in each batch            \n",
    "    h = h.to(device)\n",
    "    c = c.to(device)\n",
    "    for batch, data in enumerate(dataloader):\n",
    "        with torch.no_grad():\n",
    "            #current batch size size\n",
    "            ocu_emb, espai_enc, general_data = data[\"ocu_ber_emb\"].float().to(device) ,data[\"espai_enc\"].float().to(device) ,data[\"general_data\"].float().to(device)\n",
    "            y = data[\"y\"][:,y_idx].float().to(device) #we'll do one counter for now\n",
    "            \n",
    "            b_sz = ocu_emb.shape[0]\n",
    "            h, c = model.init_hidden(b_sz) # Start with a new state in each batch            \n",
    "            h = h.to(device)\n",
    "            c = c.to(device)\n",
    "\n",
    "            y_pred, h,c= model(ocu_emb, espai_enc, general_data, h, c)\n",
    "            pred += list(y_pred[:,0,0].to(\"cpu\"))\n",
    "            real += list(y.to(\"cpu\"))\n",
    "    return real ,pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From out sweep these are the best parameters found: Let's train again such a model but for many more epochs:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we made a change in the model code as we added 0.2 dropout probability to the lstm, this is due to that lstm tends to overfit. We hope that with this change the model will generalize better the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll train one model for each energy counter:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# y = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/josepsmachine/miniforge3/envs/ML/lib/python3.10/site-packages/torch/nn/modules/rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mharadai\u001b[0m (\u001b[33menergy_project_uab\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/josepsmachine/Documents/UNI/SYNTHS_PROJECT/energy_analysis_project/wandb/run-20230601_015837-z5qlvjky</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/energy_project_uab/energy_project_uab/runs/z5qlvjky' target=\"_blank\">eager-rain-736</a></strong> to <a href='https://wandb.ai/energy_project_uab/energy_project_uab' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/energy_project_uab/energy_project_uab' target=\"_blank\">https://wandb.ai/energy_project_uab/energy_project_uab</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/energy_project_uab/energy_project_uab/runs/z5qlvjky' target=\"_blank\">https://wandb.ai/energy_project_uab/energy_project_uab/runs/z5qlvjky</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/200: 71it [00:10,  6.81it/s, Batch Loss=0.00857] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 55.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.001]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/200: 71it [00:09,  7.30it/s, Batch Loss=0.00318]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 88.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.001]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/200: 71it [00:09,  7.31it/s, Batch Loss=0.00555]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 82.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.001]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/200: 71it [00:09,  7.31it/s, Batch Loss=0.00663]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 88.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.001]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/200: 71it [00:09,  7.28it/s, Batch Loss=0.0158] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 89.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.0009000000000000001]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/200: 71it [00:09,  7.24it/s, Batch Loss=0.0135] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 86.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.0009000000000000001]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/200: 71it [00:09,  7.25it/s, Batch Loss=0.00349]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 87.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.0009000000000000001]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/200: 71it [00:09,  7.25it/s, Batch Loss=0.00246]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 88.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.0009000000000000001]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/200: 71it [00:09,  7.25it/s, Batch Loss=0.00108]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 89.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.0009000000000000001]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/200: 71it [00:09,  7.26it/s, Batch Loss=0.0101] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 81.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.0008100000000000001]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/200: 71it [00:09,  7.27it/s, Batch Loss=0.00693]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 90.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.0008100000000000001]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/200: 71it [00:09,  7.25it/s, Batch Loss=0.0024] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 89.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.0008100000000000001]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/200: 71it [00:09,  7.26it/s, Batch Loss=0.00506]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 89.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.0008100000000000001]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/200: 71it [00:09,  7.26it/s, Batch Loss=0.00706]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 86.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.0008100000000000001]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/200: 71it [00:09,  7.26it/s, Batch Loss=0.00143]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 88.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.000729]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/200: 71it [00:09,  7.26it/s, Batch Loss=0.00172]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 88.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.000729]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/200: 71it [00:09,  7.27it/s, Batch Loss=0.00201]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 84.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.000729]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/200: 71it [00:09,  7.26it/s, Batch Loss=0.0121] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 84.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.000729]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/200: 71it [00:09,  7.26it/s, Batch Loss=0.00216]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 87.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.000729]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/200: 71it [00:09,  7.27it/s, Batch Loss=0.00131]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 86.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.0006561000000000001]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/200: 71it [00:09,  7.26it/s, Batch Loss=0.000536]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 88.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.0006561000000000001]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/200: 71it [00:09,  7.27it/s, Batch Loss=0.000499]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 86.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.0006561000000000001]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/200: 71it [00:09,  7.31it/s, Batch Loss=0.00141]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 87.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.0006561000000000001]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/200: 71it [00:09,  7.36it/s, Batch Loss=0.00125]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 90.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.0006561000000000001]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/200: 71it [00:09,  7.35it/s, Batch Loss=0.000144]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 84.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00059049]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/200: 71it [00:09,  7.36it/s, Batch Loss=0.00184]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 81.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00059049]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/200: 71it [00:09,  7.35it/s, Batch Loss=0.000392]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 88.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00059049]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/200: 71it [00:09,  7.27it/s, Batch Loss=0.00048] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 85.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00059049]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/200: 71it [00:09,  7.26it/s, Batch Loss=0.00182]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 86.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00059049]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/200: 71it [00:09,  7.34it/s, Batch Loss=0.00203] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 89.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.000531441]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/200: 71it [00:09,  7.36it/s, Batch Loss=0.000527]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 85.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.000531441]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32/200: 71it [00:09,  7.35it/s, Batch Loss=0.000679]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 88.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.000531441]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33/200: 71it [00:09,  7.35it/s, Batch Loss=0.000656]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 88.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.000531441]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34/200: 71it [00:09,  7.35it/s, Batch Loss=9.27e-5]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 87.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.000531441]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35/200: 71it [00:09,  7.34it/s, Batch Loss=0.000431]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 84.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.0004782969]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36/200: 71it [00:09,  7.35it/s, Batch Loss=0.000373]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 82.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.0004782969]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37/200: 71it [00:09,  7.34it/s, Batch Loss=0.000124]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 90.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.0004782969]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38/200: 71it [00:09,  7.35it/s, Batch Loss=0.000272]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 87.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.0004782969]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39/200: 71it [00:09,  7.37it/s, Batch Loss=0.000318]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 89.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.0004782969]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40/200: 71it [00:09,  7.35it/s, Batch Loss=0.000333]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 88.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00043046721]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41/200: 71it [00:09,  7.35it/s, Batch Loss=0.000751]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 87.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00043046721]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42/200: 71it [00:09,  7.35it/s, Batch Loss=0.000171]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 86.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00043046721]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43/200: 71it [00:09,  7.36it/s, Batch Loss=0.00114] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 87.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00043046721]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44/200: 71it [00:09,  7.36it/s, Batch Loss=0.000219]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 88.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00043046721]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45/200: 71it [00:09,  7.35it/s, Batch Loss=0.000534]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 86.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.000387420489]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46/200: 71it [00:09,  7.36it/s, Batch Loss=0.000265]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 85.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.000387420489]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47/200: 71it [00:09,  7.34it/s, Batch Loss=0.00029]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 82.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.000387420489]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48/200: 71it [00:09,  7.36it/s, Batch Loss=0.00028] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 81.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.000387420489]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49/200: 71it [00:09,  7.35it/s, Batch Loss=0.000175]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 90.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.000387420489]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50/200: 71it [00:09,  7.37it/s, Batch Loss=0.000238]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 86.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.0003486784401]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 51/200: 71it [00:09,  7.36it/s, Batch Loss=0.000375]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 87.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.0003486784401]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 52/200: 71it [00:09,  7.37it/s, Batch Loss=0.000306]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 89.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.0003486784401]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 53/200: 71it [00:09,  7.37it/s, Batch Loss=0.000289]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 88.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.0003486784401]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 54/200: 71it [00:09,  7.37it/s, Batch Loss=0.000461]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 85.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.0003486784401]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 55/200: 71it [00:09,  7.39it/s, Batch Loss=0.0003]  \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 87.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00031381059609000004]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 56/200: 71it [00:09,  7.38it/s, Batch Loss=0.000338]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 87.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00031381059609000004]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 57/200: 71it [00:09,  7.39it/s, Batch Loss=0.000919]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 85.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00031381059609000004]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 58/200: 71it [00:09,  7.39it/s, Batch Loss=0.000286]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 87.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00031381059609000004]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 59/200: 71it [00:09,  7.39it/s, Batch Loss=0.00069] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 85.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00031381059609000004]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 60/200: 71it [00:09,  7.39it/s, Batch Loss=0.000519]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 88.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00028242953648100003]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 61/200: 71it [00:09,  7.38it/s, Batch Loss=0.000352]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 81.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00028242953648100003]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 62/200: 71it [00:09,  7.39it/s, Batch Loss=0.000336]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 82.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00028242953648100003]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 63/200: 71it [00:09,  7.37it/s, Batch Loss=0.000413]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 90.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00028242953648100003]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 64/200: 71it [00:09,  7.36it/s, Batch Loss=0.000203]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 89.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00028242953648100003]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 65/200: 71it [00:09,  7.35it/s, Batch Loss=0.000243]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 87.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00025418658283290005]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 66/200: 71it [00:09,  7.37it/s, Batch Loss=0.000494]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 89.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00025418658283290005]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 67/200: 71it [00:09,  7.36it/s, Batch Loss=0.000705]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 89.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00025418658283290005]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 68/200: 71it [00:09,  7.36it/s, Batch Loss=0.000293]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 86.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00025418658283290005]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 69/200: 71it [00:09,  7.36it/s, Batch Loss=0.000407]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 85.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00025418658283290005]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 70/200: 71it [00:09,  7.37it/s, Batch Loss=0.000549]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 88.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00022876792454961005]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 71/200: 71it [00:09,  7.35it/s, Batch Loss=0.000229]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 86.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00022876792454961005]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 72/200: 71it [00:09,  7.36it/s, Batch Loss=0.00056] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 88.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00022876792454961005]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 73/200: 71it [00:09,  7.35it/s, Batch Loss=0.000234]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 86.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00022876792454961005]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 74/200: 71it [00:09,  7.35it/s, Batch Loss=0.000367]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 82.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00022876792454961005]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 75/200: 71it [00:09,  7.36it/s, Batch Loss=0.0005]  \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 87.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00020589113209464906]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 76/200: 71it [00:09,  7.36it/s, Batch Loss=0.000449]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 90.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00020589113209464906]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 77/200: 71it [00:09,  7.38it/s, Batch Loss=0.000358]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 94.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00020589113209464906]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 78/200: 71it [00:09,  7.36it/s, Batch Loss=0.000136]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 88.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00020589113209464906]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 79/200: 71it [00:09,  7.37it/s, Batch Loss=0.000434]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 85.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00020589113209464906]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 80/200: 71it [00:09,  7.36it/s, Batch Loss=0.000946]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 89.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00018530201888518417]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 81/200: 71it [00:09,  7.37it/s, Batch Loss=0.000957]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 88.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00018530201888518417]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 82/200: 71it [00:09,  7.37it/s, Batch Loss=0.000199]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 89.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00018530201888518417]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 83/200: 71it [00:09,  7.36it/s, Batch Loss=0.000382]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 86.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00018530201888518417]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 84/200: 71it [00:09,  7.35it/s, Batch Loss=0.000571]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 86.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00018530201888518417]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 85/200: 71it [00:09,  7.33it/s, Batch Loss=0.000426]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 87.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00016677181699666576]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 86/200: 71it [00:09,  7.36it/s, Batch Loss=0.000326]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 85.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00016677181699666576]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 87/200: 71it [00:09,  7.36it/s, Batch Loss=0.000489]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 82.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00016677181699666576]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 88/200: 71it [00:09,  7.36it/s, Batch Loss=0.000769]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 88.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00016677181699666576]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 89/200: 71it [00:09,  7.37it/s, Batch Loss=0.000393]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 91.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00016677181699666576]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 90/200: 71it [00:09,  7.36it/s, Batch Loss=0.000937]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 87.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.0001500946352969992]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 91/200: 71it [00:09,  7.36it/s, Batch Loss=0.000337]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 88.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.0001500946352969992]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 92/200: 71it [00:09,  7.37it/s, Batch Loss=0.000591]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 89.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.0001500946352969992]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 93/200: 71it [00:09,  7.37it/s, Batch Loss=0.000324]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 88.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.0001500946352969992]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 94/200: 71it [00:09,  7.36it/s, Batch Loss=0.000489]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 87.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.0001500946352969992]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 95/200: 71it [00:09,  7.37it/s, Batch Loss=0.000269]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 86.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.0001350851717672993]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 96/200: 71it [00:09,  7.37it/s, Batch Loss=0.000303]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 89.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.0001350851717672993]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 97/200: 71it [00:09,  7.36it/s, Batch Loss=0.000505]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 88.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.0001350851717672993]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 98/200: 71it [00:09,  7.37it/s, Batch Loss=0.000567]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 85.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.0001350851717672993]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 99/200: 71it [00:09,  7.37it/s, Batch Loss=0.00017] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 86.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.0001350851717672993]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 100/200: 71it [00:09,  7.37it/s, Batch Loss=0.000811]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 81.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00012157665459056936]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 101/200: 71it [00:09,  7.37it/s, Batch Loss=0.000403]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 85.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00012157665459056936]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 102/200: 71it [00:09,  7.37it/s, Batch Loss=0.000366]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 90.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00012157665459056936]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 103/200: 71it [00:09,  7.37it/s, Batch Loss=0.000249]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 86.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00012157665459056936]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 104/200: 71it [00:09,  7.36it/s, Batch Loss=0.000364]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 89.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00012157665459056936]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 105/200: 71it [00:09,  7.37it/s, Batch Loss=0.000369]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 88.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00010941898913151243]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 106/200: 71it [00:09,  7.38it/s, Batch Loss=0.000336]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 85.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00010941898913151243]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 107/200: 71it [00:09,  7.35it/s, Batch Loss=0.000219]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 88.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00010941898913151243]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 108/200: 71it [00:09,  7.37it/s, Batch Loss=0.000509]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 87.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00010941898913151243]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 109/200: 71it [00:09,  7.38it/s, Batch Loss=0.000371]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 88.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00010941898913151243]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 110/200: 71it [00:09,  7.37it/s, Batch Loss=0.000236]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 87.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[9.847709021836118e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 111/200: 71it [00:09,  7.39it/s, Batch Loss=0.000325]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 87.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[9.847709021836118e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 112/200: 71it [00:09,  7.38it/s, Batch Loss=0.0003]  \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 86.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[9.847709021836118e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 113/200: 71it [00:09,  7.39it/s, Batch Loss=0.000256]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 76.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[9.847709021836118e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 114/200: 71it [00:09,  7.39it/s, Batch Loss=0.000197]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 83.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[9.847709021836118e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 115/200: 71it [00:09,  7.40it/s, Batch Loss=0.000265]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 87.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[8.862938119652506e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 116/200: 71it [00:09,  7.40it/s, Batch Loss=0.000255]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 92.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[8.862938119652506e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 117/200: 71it [00:09,  7.38it/s, Batch Loss=0.000207]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 86.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[8.862938119652506e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 118/200: 71it [00:09,  7.40it/s, Batch Loss=0.000188]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 87.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[8.862938119652506e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 119/200: 71it [00:09,  7.39it/s, Batch Loss=0.000256]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 87.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[8.862938119652506e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 120/200: 71it [00:09,  7.38it/s, Batch Loss=0.000248]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 87.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[7.976644307687256e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 121/200: 71it [00:09,  7.36it/s, Batch Loss=0.000177]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 88.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[7.976644307687256e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 122/200: 71it [00:09,  7.36it/s, Batch Loss=0.000195]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 87.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[7.976644307687256e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 123/200: 71it [00:09,  7.37it/s, Batch Loss=0.000277]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 89.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[7.976644307687256e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 124/200: 71it [00:09,  7.37it/s, Batch Loss=0.000196]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 87.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[7.976644307687256e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 125/200: 71it [00:09,  7.36it/s, Batch Loss=0.000186]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 89.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[7.17897987691853e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 126/200: 71it [00:09,  7.36it/s, Batch Loss=0.000204]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 84.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[7.17897987691853e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 127/200: 71it [00:09,  7.36it/s, Batch Loss=0.000209]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 81.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[7.17897987691853e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 128/200: 71it [00:09,  7.36it/s, Batch Loss=0.000281]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 86.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[7.17897987691853e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 129/200: 71it [00:09,  7.37it/s, Batch Loss=0.000172]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 89.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[7.17897987691853e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 130/200: 71it [00:09,  7.37it/s, Batch Loss=0.000135]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 87.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[6.461081889226677e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 131/200: 71it [00:09,  7.36it/s, Batch Loss=0.000336]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 89.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[6.461081889226677e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 132/200: 71it [00:09,  7.37it/s, Batch Loss=0.000166]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 87.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[6.461081889226677e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 133/200: 71it [00:09,  7.36it/s, Batch Loss=0.000179]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 88.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[6.461081889226677e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 134/200: 71it [00:09,  7.37it/s, Batch Loss=0.000151]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 87.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[6.461081889226677e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 135/200: 71it [00:09,  7.36it/s, Batch Loss=0.000186]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 86.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[5.81497370030401e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 136/200: 71it [00:09,  7.36it/s, Batch Loss=0.000167]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 88.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[5.81497370030401e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 137/200: 71it [00:09,  7.36it/s, Batch Loss=8.97e-5] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 84.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[5.81497370030401e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 138/200: 71it [00:09,  7.37it/s, Batch Loss=0.000118]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 88.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[5.81497370030401e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 139/200: 71it [00:09,  7.36it/s, Batch Loss=0.000176]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 77.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[5.81497370030401e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 140/200: 71it [00:09,  7.36it/s, Batch Loss=5.57e-5] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 79.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[5.233476330273609e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 141/200: 71it [00:09,  7.37it/s, Batch Loss=5.83e-5] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 89.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[5.233476330273609e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 142/200: 71it [00:09,  7.36it/s, Batch Loss=0.000114]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 87.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[5.233476330273609e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 143/200: 71it [00:09,  7.35it/s, Batch Loss=5.21e-5] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 86.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[5.233476330273609e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 144/200: 71it [00:09,  7.36it/s, Batch Loss=4.22e-5] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 86.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[5.233476330273609e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 145/200: 71it [00:09,  7.36it/s, Batch Loss=4.88e-5] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 89.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[4.7101286972462485e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 146/200: 71it [00:09,  7.35it/s, Batch Loss=6.38e-5] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 89.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[4.7101286972462485e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 147/200: 71it [00:09,  7.35it/s, Batch Loss=5.61e-5] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 87.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[4.7101286972462485e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 148/200: 71it [00:09,  7.37it/s, Batch Loss=3.96e-5] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 89.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[4.7101286972462485e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 149/200: 71it [00:09,  7.36it/s, Batch Loss=7.1e-5]  \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 88.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[4.7101286972462485e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 150/200: 71it [00:09,  7.35it/s, Batch Loss=5.77e-5] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 88.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[4.239115827521624e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 151/200: 71it [00:09,  7.36it/s, Batch Loss=4.29e-5] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 84.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[4.239115827521624e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 152/200: 71it [00:09,  7.35it/s, Batch Loss=6.89e-5] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 83.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[4.239115827521624e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 153/200: 71it [00:09,  7.36it/s, Batch Loss=4.52e-5] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 90.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[4.239115827521624e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 154/200: 71it [00:09,  7.37it/s, Batch Loss=3.76e-5] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 87.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[4.239115827521624e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 155/200: 71it [00:09,  7.36it/s, Batch Loss=5.67e-5] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 86.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[3.8152042447694614e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 156/200: 71it [00:09,  7.30it/s, Batch Loss=4.07e-5] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 57.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[3.8152042447694614e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 157/200: 71it [00:09,  7.32it/s, Batch Loss=4.2e-5]  \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 86.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[3.8152042447694614e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 158/200: 71it [00:09,  7.35it/s, Batch Loss=4.28e-5] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 86.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[3.8152042447694614e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 159/200: 71it [00:09,  7.35it/s, Batch Loss=3.8e-5]  \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 86.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[3.8152042447694614e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 160/200: 71it [00:09,  7.35it/s, Batch Loss=6.38e-5] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 85.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[3.433683820292515e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 161/200: 71it [00:09,  7.36it/s, Batch Loss=4.05e-5] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 86.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[3.433683820292515e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 162/200: 71it [00:09,  7.36it/s, Batch Loss=3.95e-5] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 85.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[3.433683820292515e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 163/200: 71it [00:09,  7.36it/s, Batch Loss=3.51e-5] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 81.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[3.433683820292515e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 164/200: 71it [00:09,  7.35it/s, Batch Loss=5.7e-5]  \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 88.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[3.433683820292515e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 165/200: 71it [00:09,  7.35it/s, Batch Loss=6.13e-5] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 91.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[3.090315438263264e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 166/200: 71it [00:09,  7.37it/s, Batch Loss=0.000111]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 89.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[3.090315438263264e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 167/200: 71it [00:09,  7.37it/s, Batch Loss=8.1e-5]  \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 88.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[3.090315438263264e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 168/200: 71it [00:09,  7.36it/s, Batch Loss=0.000104]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 86.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[3.090315438263264e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 169/200: 71it [00:09,  7.38it/s, Batch Loss=6.54e-5] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 87.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[3.090315438263264e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 170/200: 71it [00:09,  7.37it/s, Batch Loss=8.44e-5] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 86.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[2.7812838944369376e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 171/200: 71it [00:09,  7.37it/s, Batch Loss=6.71e-5] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 88.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[2.7812838944369376e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 172/200: 71it [00:09,  7.37it/s, Batch Loss=0.000119]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 87.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[2.7812838944369376e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 173/200: 71it [00:09,  7.37it/s, Batch Loss=0.000106]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 88.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[2.7812838944369376e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 174/200: 71it [00:09,  7.37it/s, Batch Loss=0.000123]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 89.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[2.7812838944369376e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 175/200: 71it [00:09,  7.36it/s, Batch Loss=6.3e-5]  \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 87.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[2.503155504993244e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 176/200: 71it [00:09,  7.35it/s, Batch Loss=4.57e-5] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 77.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[2.503155504993244e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 177/200: 71it [00:09,  7.34it/s, Batch Loss=2.76e-5] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 88.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[2.503155504993244e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 178/200: 71it [00:09,  7.35it/s, Batch Loss=3.05e-5] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 90.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[2.503155504993244e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 179/200: 71it [00:09,  7.35it/s, Batch Loss=2.82e-5] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 89.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[2.503155504993244e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 180/200: 71it [00:09,  7.34it/s, Batch Loss=3.66e-5] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 88.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[2.2528399544939195e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 181/200: 71it [00:09,  7.34it/s, Batch Loss=3.25e-5] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 85.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[2.2528399544939195e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 182/200: 71it [00:09,  7.35it/s, Batch Loss=4.29e-5] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 88.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[2.2528399544939195e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 183/200: 71it [00:09,  7.35it/s, Batch Loss=3.04e-5] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 89.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[2.2528399544939195e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 184/200: 71it [00:09,  7.35it/s, Batch Loss=3.45e-5] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 85.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[2.2528399544939195e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 185/200: 71it [00:09,  7.34it/s, Batch Loss=2.58e-5] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 86.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[2.0275559590445276e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 186/200: 71it [00:09,  7.35it/s, Batch Loss=2.65e-5] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 87.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[2.0275559590445276e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 187/200: 71it [00:09,  7.35it/s, Batch Loss=2.51e-5] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 83.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[2.0275559590445276e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 188/200: 71it [00:09,  7.35it/s, Batch Loss=2.58e-5] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 84.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[2.0275559590445276e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 189/200: 71it [00:09,  7.35it/s, Batch Loss=2.45e-5] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 90.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[2.0275559590445276e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 190/200: 71it [00:09,  7.35it/s, Batch Loss=2.81e-5] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 88.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[1.8248003631400748e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 191/200: 71it [00:09,  7.34it/s, Batch Loss=2.43e-5] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 87.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[1.8248003631400748e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 192/200: 71it [00:09,  7.34it/s, Batch Loss=2.83e-5] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 86.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[1.8248003631400748e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 193/200: 71it [00:09,  7.35it/s, Batch Loss=2.41e-5] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 89.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[1.8248003631400748e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 194/200: 71it [00:09,  7.34it/s, Batch Loss=2.61e-5] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 89.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[1.8248003631400748e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 195/200: 71it [00:09,  7.34it/s, Batch Loss=2.36e-5] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 88.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[1.6423203268260675e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 196/200: 71it [00:09,  7.35it/s, Batch Loss=2.42e-5] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 88.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[1.6423203268260675e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 197/200: 71it [00:09,  7.34it/s, Batch Loss=2.31e-5] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 85.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[1.6423203268260675e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 198/200: 71it [00:09,  7.34it/s, Batch Loss=2.38e-5] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 83.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[1.6423203268260675e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 199/200: 71it [00:09,  7.34it/s, Batch Loss=2.3e-5]  \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 81.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[1.6423203268260675e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 200/200: 71it [00:09,  7.34it/s, Batch Loss=2.35e-5] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 89.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[1.4780882941434607e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\n",
      "Running whole dataset prediction\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Train_loss</td><td>█▆▆▅▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Val_loss</td><td>▄█▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Train_loss</td><td>0.00244</td></tr><tr><td>Val_loss</td><td>2e-05</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">eager-rain-736</strong> at: <a href='https://wandb.ai/energy_project_uab/energy_project_uab/runs/z5qlvjky' target=\"_blank\">https://wandb.ai/energy_project_uab/energy_project_uab/runs/z5qlvjky</a><br/>Synced 6 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230601_015837-z5qlvjky/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_idx = 0\n",
    "model = attentiveLSTM_model(espai_emb_dim=50,hidden_dim=384,lstm_nl=1,nheads=2,attnFCdim=80)\n",
    "model.init_weights()\n",
    "model.to(device)\n",
    "\n",
    "criterion =  nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001) #lr used in that \n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=(1 - 0.0001 / 0.001))\n",
    "num_epochs = 200\n",
    "best_loss = float('inf')\n",
    "epoch_loss_tr = []\n",
    "epoch_loss_vl = []\n",
    "with wandb.init(project=\"energy_project_uab\", entity = \"energy_project_uab\") as run:\n",
    "    run.name = f\"LSTM_attention_regressor_0\"\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        training_losses = [] # renamed from epoch_losses\n",
    "        progress_bar = tqdm(enumerate(train_dataloader), desc=f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "        for batch,data in progress_bar:\n",
    "            ocu_emb, espai_enc, general_data = data[\"ocu_ber_emb\"].float().to(device) ,data[\"espai_enc\"].float().to(device) ,data[\"general_data\"].float().to(device)\n",
    "            y = data[\"y\"][:,y_idx].float().to(device) #we'll do one counter for now\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            #current batch size size\n",
    "            b_sz = ocu_emb.shape[0]\n",
    "\n",
    "            #note the dataloader with a batch of 100 when reachs the end expects a batch of 60\n",
    "            h, c = model.init_hidden(b_sz) # Start with a new state in each batch            \n",
    "            h = h.to(device)\n",
    "            c = c.to(device)\n",
    "            y_pred, h,c= model(ocu_emb, espai_enc, general_data, h, c)\n",
    "            y_pred = y_pred[:,0,0]\n",
    "\n",
    "            loss = criterion(y_pred,y)  #cross entropy loss needs (N,C,seq_lenght)\n",
    "            loss.backward()\n",
    "            optimizer.step()    \n",
    "\n",
    "            training_losses.append(loss.item())\n",
    "            progress_bar.set_postfix({'Batch Loss': loss.item()})\n",
    "\n",
    "        average_training_loss = sum(training_losses) / len(training_losses) # renamed from avg_loss\n",
    "        epoch_loss_tr.append(average_training_loss)\n",
    "        wandb.log({\"Train_loss\":average_training_loss})\n",
    "        #average_training_loss = np.power(dataset.denormalize_values(np.sqrt(average_training_loss),scaler),2)\n",
    "\n",
    "        model.eval()  \n",
    "        with torch.no_grad():  \n",
    "            validation_losses = [] # renamed from val_losses\n",
    "            for batch in tqdm(val_dataloader, desc='Validation'):\n",
    "                ocu_emb, espai_enc, general_data = data[\"ocu_ber_emb\"].float().to(device) ,data[\"espai_enc\"].float().to(device) ,data[\"general_data\"].float().to(device)\n",
    "                y = data[\"y\"][:,y_idx].float().to(device) #we'll do one counter for now\n",
    "\n",
    "                #current batch size size\n",
    "                b_sz = ocu_emb.shape[0]\n",
    "\n",
    "                #note the dataloader with a batch of 100 when reachs the end expects a batch of 60\n",
    "                h, c = model.init_hidden(b_sz) # Start with a new state in each batch            \n",
    "                h = h.to(device)\n",
    "                c = c.to(device)\n",
    "                y_pred, h,c= model(ocu_emb, espai_enc, general_data, h, c)\n",
    "                y_pred = y_pred[:,0,0]\n",
    "                \n",
    "                loss = criterion(y_pred,y) \n",
    "                validation_losses.append(loss.item())\n",
    "\n",
    "            average_validation_loss = sum(validation_losses) / len(validation_losses) # renamed from avg_val_loss\n",
    "            #average_validation_loss = np.power(dataset.denormalize_values(np.sqrt(average_validation_loss),scaler),2)\n",
    "            epoch_loss_vl.append(average_validation_loss)\n",
    "            wandb.log({\"Val_loss\":average_validation_loss})\n",
    "        \n",
    "        scheduler.step() #change lr\n",
    "        print(f\"lr:{scheduler.get_last_lr()}\")#print current lr\n",
    "\n",
    "        if average_validation_loss < best_loss:\n",
    "            best_loss = average_training_loss\n",
    "            torch.save(model.state_dict(), 'models/attention_exp_LSTM/LSTM_attention_regressor_0.pt')\n",
    "            wandb.save('models/attention_exp_LSTM/LSTM_attention_regressor_0.pt')\n",
    "            print(\"Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_0.pt\")\n",
    "        \n",
    "        if epoch == num_epochs-1: #if last epoch just finished\n",
    "            print(\"Running whole dataset prediction\")\n",
    "            real, pred = predict_consumption(model,whole_dataloader,y_idx=0)\n",
    "            real = [v.item() for v in real]\n",
    "            pred = [v.item() for v in pred]\n",
    "            scaler = dataset.column_scalers[dataset.target_labels[y_idx]]\n",
    "            real_sc = dataset.denormalize_values(real,scaler)\n",
    "            pred_sc = dataset.denormalize_values(pred,scaler)\n",
    "            res_sc = pred_sc-real_sc\n",
    "           # Plotting the main data\n",
    "            plt.subplot(2, 1, 1)  # Create a subplot with 2 rows and 1 column, and select the first subplot\n",
    "            plt.plot(real_sc, label='Real')  # Add a label for the real data\n",
    "            plt.plot(pred_sc, label='Predicted')  # Add a label for the predicted data\n",
    "\n",
    "            # Plotting the residual data\n",
    "            plt.subplot(2, 1, 2)  # Select the second subplot\n",
    "            plt.plot(res_sc, label='Residual')  # Add a label for the residual data\n",
    "            wandb.log({\"KWh hourly in 2022\": plt})\n",
    "\n",
    "                        # Display the plot\n",
    "            plt.show()\n",
    "\n",
    "                    \n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Y=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/josepsmachine/miniforge3/envs/ML/lib/python3.10/site-packages/torch/nn/modules/rnn.py:71: UserWarning:\n",
      "\n",
      "dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/josepsmachine/Documents/UNI/SYNTHS_PROJECT/energy_analysis_project/wandb/run-20230601_110443-fk83e03s</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/energy_project_uab/energy_project_uab/runs/fk83e03s' target=\"_blank\">leafy-water-739</a></strong> to <a href='https://wandb.ai/energy_project_uab/energy_project_uab' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/energy_project_uab/energy_project_uab' target=\"_blank\">https://wandb.ai/energy_project_uab/energy_project_uab</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/energy_project_uab/energy_project_uab/runs/fk83e03s' target=\"_blank\">https://wandb.ai/energy_project_uab/energy_project_uab/runs/fk83e03s</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/200: 71it [00:17,  3.95it/s, Batch Loss=0.016]   \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 33.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.001]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/200: 71it [00:12,  5.91it/s, Batch Loss=0.00699] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 46.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.001]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/200: 71it [00:11,  6.08it/s, Batch Loss=0.0195]  \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 45.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.001]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/200: 71it [00:10,  6.70it/s, Batch Loss=0.025]   \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 48.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.001]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/200: 71it [00:10,  6.71it/s, Batch Loss=0.00326] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 52.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.0009000000000000001]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/200: 71it [00:10,  6.65it/s, Batch Loss=0.00494] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 43.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.0009000000000000001]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/200: 71it [00:11,  6.00it/s, Batch Loss=0.00268] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 24.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.0009000000000000001]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/200: 71it [00:10,  6.51it/s, Batch Loss=0.00416] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 44.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.0009000000000000001]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/200: 71it [00:10,  6.50it/s, Batch Loss=0.00461] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 43.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.0009000000000000001]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/200: 71it [00:11,  6.24it/s, Batch Loss=0.0023] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 29.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.0008100000000000001]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/200: 71it [00:14,  4.76it/s, Batch Loss=0.00128]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 18.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.0008100000000000001]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/200: 71it [00:12,  5.49it/s, Batch Loss=0.000502]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 32.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.0008100000000000001]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/200: 71it [00:13,  5.32it/s, Batch Loss=0.00171]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 38.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.0008100000000000001]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/200: 71it [00:11,  6.05it/s, Batch Loss=0.00682]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 47.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.0008100000000000001]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/200: 71it [00:10,  6.58it/s, Batch Loss=0.00666]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 46.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.000729]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/200: 71it [00:10,  6.50it/s, Batch Loss=0.00369]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 49.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.000729]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/200: 71it [00:10,  6.51it/s, Batch Loss=0.000555]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 45.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.000729]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/200: 71it [00:11,  6.36it/s, Batch Loss=0.00109]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 42.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.000729]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/200: 71it [00:12,  5.48it/s, Batch Loss=0.00125] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 28.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.000729]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/200: 71it [00:11,  6.30it/s, Batch Loss=0.00121]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 43.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.0006561000000000001]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/200: 71it [00:10,  6.60it/s, Batch Loss=0.0013] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 46.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.0006561000000000001]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/200: 71it [00:11,  6.05it/s, Batch Loss=0.00104]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 35.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.0006561000000000001]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/200: 71it [00:11,  6.01it/s, Batch Loss=0.00226]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 41.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.0006561000000000001]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/200: 71it [00:11,  6.10it/s, Batch Loss=0.00568] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 44.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.0006561000000000001]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/200: 71it [00:11,  6.31it/s, Batch Loss=0.00486] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 38.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00059049]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/200: 71it [00:11,  6.36it/s, Batch Loss=0.00488] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 45.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00059049]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/200: 71it [00:10,  6.48it/s, Batch Loss=0.00916] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 41.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00059049]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/200: 71it [00:12,  5.60it/s, Batch Loss=0.00839] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 19.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00059049]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/200: 71it [00:12,  5.59it/s, Batch Loss=0.008]   \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 40.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00059049]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/200: 71it [00:13,  5.08it/s, Batch Loss=0.00761] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 30.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.000531441]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/200: 71it [00:14,  4.97it/s, Batch Loss=0.00675] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 20.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.000531441]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32/200: 71it [00:13,  5.26it/s, Batch Loss=0.00248] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 26.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.000531441]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33/200: 71it [00:12,  5.50it/s, Batch Loss=0.00586] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 47.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.000531441]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34/200: 71it [00:11,  5.92it/s, Batch Loss=0.00343] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 37.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.000531441]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35/200: 71it [00:13,  5.29it/s, Batch Loss=0.000962]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 41.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.0004782969]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36/200: 71it [00:13,  5.14it/s, Batch Loss=0.000374]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 28.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.0004782969]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37/200: 71it [00:11,  5.97it/s, Batch Loss=0.000287]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 34.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.0004782969]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38/200: 71it [00:12,  5.89it/s, Batch Loss=0.000467]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 41.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.0004782969]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39/200: 71it [00:11,  6.14it/s, Batch Loss=0.000575]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 46.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.0004782969]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40/200: 71it [00:11,  6.44it/s, Batch Loss=0.000231]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 46.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00043046721]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41/200: 71it [00:10,  6.71it/s, Batch Loss=0.000384]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 46.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00043046721]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42/200: 71it [00:10,  6.66it/s, Batch Loss=0.000435]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 42.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00043046721]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43/200: 71it [00:11,  6.05it/s, Batch Loss=0.00102] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 38.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00043046721]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44/200: 71it [00:12,  5.54it/s, Batch Loss=0.000768]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 30.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00043046721]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45/200: 71it [00:15,  4.72it/s, Batch Loss=0.000367]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 34.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.000387420489]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46/200: 71it [00:12,  5.84it/s, Batch Loss=0.000734]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 28.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.000387420489]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47/200: 71it [00:11,  6.04it/s, Batch Loss=0.000717]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 35.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.000387420489]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48/200: 71it [00:11,  6.28it/s, Batch Loss=0.0005]  \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 35.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.000387420489]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49/200: 71it [00:12,  5.55it/s, Batch Loss=0.000521]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 33.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.000387420489]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50/200: 71it [00:11,  6.39it/s, Batch Loss=0.000661]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 38.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.0003486784401]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 51/200: 71it [00:10,  6.47it/s, Batch Loss=0.000592]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 38.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.0003486784401]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 52/200: 71it [00:11,  6.10it/s, Batch Loss=0.000259]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 39.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.0003486784401]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 53/200: 71it [00:11,  6.09it/s, Batch Loss=0.00042] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 33.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.0003486784401]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 54/200: 71it [00:12,  5.87it/s, Batch Loss=0.000459]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 35.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.0003486784401]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 55/200: 71it [00:13,  5.23it/s, Batch Loss=0.00041] \n",
      "Validation: 100%|██████████| 18/18 [00:01<00:00, 17.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00031381059609000004]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 56/200: 71it [00:12,  5.58it/s, Batch Loss=0.000479]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 29.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00031381059609000004]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 57/200: 71it [00:11,  5.96it/s, Batch Loss=0.000583]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 30.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00031381059609000004]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 58/200: 71it [00:11,  5.98it/s, Batch Loss=0.000694]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 28.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00031381059609000004]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 59/200: 71it [00:11,  6.21it/s, Batch Loss=0.000653]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 43.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00031381059609000004]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 60/200: 71it [00:11,  5.95it/s, Batch Loss=0.000331]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 44.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00028242953648100003]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 61/200: 71it [00:11,  6.32it/s, Batch Loss=0.000535]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 37.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00028242953648100003]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 62/200: 71it [00:11,  6.07it/s, Batch Loss=0.00121] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 40.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00028242953648100003]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 63/200: 71it [00:11,  6.26it/s, Batch Loss=0.000745]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 36.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00028242953648100003]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 64/200: 71it [00:10,  6.46it/s, Batch Loss=0.000447]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 42.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00028242953648100003]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 65/200: 71it [00:10,  6.56it/s, Batch Loss=0.000226]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 43.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00025418658283290005]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 66/200: 71it [00:10,  6.61it/s, Batch Loss=0.000287]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 40.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00025418658283290005]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 67/200: 71it [00:11,  6.37it/s, Batch Loss=0.000598]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 38.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00025418658283290005]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 68/200: 71it [00:11,  6.40it/s, Batch Loss=0.000889]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 39.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00025418658283290005]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 69/200: 71it [00:10,  6.60it/s, Batch Loss=0.000491]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 44.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00025418658283290005]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 70/200: 71it [00:10,  6.60it/s, Batch Loss=0.000409]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 42.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00022876792454961005]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 71/200: 71it [00:10,  6.57it/s, Batch Loss=0.00038] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 40.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00022876792454961005]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 72/200: 71it [00:11,  6.40it/s, Batch Loss=0.0014]  \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 41.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00022876792454961005]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 73/200: 71it [00:11,  6.32it/s, Batch Loss=0.00217] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 37.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00022876792454961005]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 74/200: 71it [00:11,  6.45it/s, Batch Loss=0.000476]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 48.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00022876792454961005]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 75/200: 71it [00:10,  6.65it/s, Batch Loss=0.000495]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 45.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00020589113209464906]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 76/200: 71it [00:11,  6.13it/s, Batch Loss=0.000826]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 38.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00020589113209464906]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 77/200: 71it [00:11,  6.39it/s, Batch Loss=0.000402]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 47.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00020589113209464906]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 78/200: 71it [00:10,  6.54it/s, Batch Loss=0.000458]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 45.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00020589113209464906]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 79/200: 71it [00:10,  6.56it/s, Batch Loss=0.00123] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 38.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00020589113209464906]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 80/200: 71it [00:10,  6.58it/s, Batch Loss=0.00126] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 44.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00018530201888518417]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 81/200: 71it [00:11,  6.11it/s, Batch Loss=0.000375]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 37.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00018530201888518417]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 82/200: 71it [00:12,  5.49it/s, Batch Loss=0.000749]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 18.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00018530201888518417]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 83/200: 71it [00:12,  5.83it/s, Batch Loss=0.000292]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 34.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00018530201888518417]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 84/200: 71it [00:11,  6.00it/s, Batch Loss=0.000251]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 23.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00018530201888518417]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 85/200: 71it [00:12,  5.51it/s, Batch Loss=0.00049] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 32.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00016677181699666576]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 86/200: 71it [00:12,  5.76it/s, Batch Loss=0.00143] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 33.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00016677181699666576]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 87/200: 71it [00:13,  5.21it/s, Batch Loss=0.00171] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 35.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00016677181699666576]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 88/200: 56it [00:15,  2.84it/s, Batch Loss=0.000437]"
     ]
    }
   ],
   "source": [
    "y_idx = 1\n",
    "model = attentiveLSTM_model(espai_emb_dim=50,hidden_dim=384,lstm_nl=1,nheads=2,attnFCdim=80)\n",
    "model.init_weights()\n",
    "model.to(device)\n",
    "\n",
    "criterion =  nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001) #lr used in that \n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=(1 - 0.0001 / 0.001))\n",
    "num_epochs = 200\n",
    "best_loss = float('inf')\n",
    "epoch_loss_tr = []\n",
    "epoch_loss_vl = []\n",
    "with wandb.init(project=\"energy_project_uab\", entity = \"energy_project_uab\") as run:\n",
    "    run.name = f\"LSTM_attention_regressor_1\"\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        training_losses = [] # renamed from epoch_losses\n",
    "        progress_bar = tqdm(enumerate(train_dataloader), desc=f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "        for batch,data in progress_bar:\n",
    "            ocu_emb, espai_enc, general_data = data[\"ocu_ber_emb\"].float().to(device) ,data[\"espai_enc\"].float().to(device) ,data[\"general_data\"].float().to(device)\n",
    "            y = data[\"y\"][:,y_idx].float().to(device) #we'll do one counter for now\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            #current batch size size\n",
    "            b_sz = ocu_emb.shape[0]\n",
    "\n",
    "            #note the dataloader with a batch of 100 when reachs the end expects a batch of 60\n",
    "            h, c = model.init_hidden(b_sz) # Start with a new state in each batch            \n",
    "            h = h.to(device)\n",
    "            c = c.to(device)\n",
    "            y_pred, h,c= model(ocu_emb, espai_enc, general_data, h, c)\n",
    "            y_pred = y_pred[:,0,0]\n",
    "\n",
    "            loss = criterion(y_pred,y)  #cross entropy loss needs (N,C,seq_lenght)\n",
    "            loss.backward()\n",
    "            optimizer.step()    \n",
    "\n",
    "            training_losses.append(loss.item())\n",
    "            progress_bar.set_postfix({'Batch Loss': loss.item()})\n",
    "\n",
    "        average_training_loss = sum(training_losses) / len(training_losses) # renamed from avg_loss\n",
    "        epoch_loss_tr.append(average_training_loss)\n",
    "        wandb.log({\"Train_loss\":average_training_loss})\n",
    "        #average_training_loss = np.power(dataset.denormalize_values(np.sqrt(average_training_loss),scaler),2)\n",
    "\n",
    "        model.eval()  \n",
    "        with torch.no_grad():  \n",
    "            validation_losses = [] # renamed from val_losses\n",
    "            for batch in tqdm(val_dataloader, desc='Validation'):\n",
    "                ocu_emb, espai_enc, general_data = data[\"ocu_ber_emb\"].float().to(device) ,data[\"espai_enc\"].float().to(device) ,data[\"general_data\"].float().to(device)\n",
    "                y = data[\"y\"][:,y_idx].float().to(device) #we'll do one counter for now\n",
    "\n",
    "                #current batch size size\n",
    "                b_sz = ocu_emb.shape[0]\n",
    "\n",
    "                #note the dataloader with a batch of 100 when reachs the end expects a batch of 60\n",
    "                h, c = model.init_hidden(b_sz) # Start with a new state in each batch            \n",
    "                h = h.to(device)\n",
    "                c = c.to(device)\n",
    "                y_pred, h,c= model(ocu_emb, espai_enc, general_data, h, c)\n",
    "                y_pred = y_pred[:,0,0]\n",
    "                \n",
    "                loss = criterion(y_pred,y) \n",
    "                validation_losses.append(loss.item())\n",
    "\n",
    "            average_validation_loss = sum(validation_losses) / len(validation_losses) # renamed from avg_val_loss\n",
    "            #average_validation_loss = np.power(dataset.denormalize_values(np.sqrt(average_validation_loss),scaler),2)\n",
    "            epoch_loss_vl.append(average_validation_loss)\n",
    "            wandb.log({\"Val_loss\":average_validation_loss})\n",
    "        \n",
    "        scheduler.step() #change lr\n",
    "        print(f\"lr:{scheduler.get_last_lr()}\")#print current lr\n",
    "\n",
    "        if average_validation_loss < best_loss:\n",
    "            best_loss = average_training_loss\n",
    "            torch.save(model.state_dict(), 'models/attention_exp_LSTM/LSTM_attention_regressor_1.pt')\n",
    "            wandb.save('models/attention_exp_LSTM/LSTM_attention_regressor_1.pt')\n",
    "            print(\"Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_1.pt\")\n",
    "        \n",
    "        if epoch == num_epochs-1: #if last epoch just finished\n",
    "            print(\"Running whole dataset prediction\")\n",
    "            real, pred = predict_consumption(model,whole_dataloader,y_idx)\n",
    "            real = [v.item() for v in real]\n",
    "            pred = [v.item() for v in pred]\n",
    "            scaler = dataset.column_scalers[dataset.target_labels[y_idx]]\n",
    "            real_sc = dataset.denormalize_values(real,scaler)\n",
    "            pred_sc = dataset.denormalize_values(pred,scaler)\n",
    "            res_sc = pred_sc-real_sc\n",
    "           # Plotting the main data\n",
    "            plt.subplot(2, 1, 1)  # Create a subplot with 2 rows and 1 column, and select the first subplot\n",
    "            plt.plot(real_sc, label='Real')  # Add a label for the real data\n",
    "            plt.plot(pred_sc, label='Predicted')  # Add a label for the predicted data\n",
    "\n",
    "            # Plotting the residual data\n",
    "            plt.subplot(2, 1, 2)  # Select the second subplot\n",
    "            plt.plot(res_sc, label='Residual')  # Add a label for the residual data\n",
    "            wandb.log({\"KWh hourly in 2022\": plt})\n",
    "\n",
    "                        # Display the plot\n",
    "            plt.show()\n",
    "\n",
    "                    \n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Y=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/josepsmachine/miniforge3/envs/ML/lib/python3.10/site-packages/torch/nn/modules/rnn.py:71: UserWarning:\n",
      "\n",
      "dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/josepsmachine/Documents/UNI/SYNTHS_PROJECT/energy_analysis_project/wandb/run-20230601_031140-wr52s5p1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/energy_project_uab/energy_project_uab/runs/wr52s5p1' target=\"_blank\">ancient-paper-738</a></strong> to <a href='https://wandb.ai/energy_project_uab/energy_project_uab' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/energy_project_uab/energy_project_uab' target=\"_blank\">https://wandb.ai/energy_project_uab/energy_project_uab</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/energy_project_uab/energy_project_uab/runs/wr52s5p1' target=\"_blank\">https://wandb.ai/energy_project_uab/energy_project_uab/runs/wr52s5p1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/200: 71it [00:17,  4.16it/s, Batch Loss=0.00417] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 38.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.001]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/200: 71it [00:10,  6.47it/s, Batch Loss=0.000797]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 46.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.001]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/200: 71it [00:10,  6.55it/s, Batch Loss=0.00781] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 46.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.001]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/200: 71it [00:10,  6.49it/s, Batch Loss=0.00306] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 44.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.001]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/200: 71it [00:10,  6.49it/s, Batch Loss=0.00141] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 46.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.0009000000000000001]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/200: 71it [00:11,  6.40it/s, Batch Loss=0.00505] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 52.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.0009000000000000001]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/200: 71it [00:11,  6.35it/s, Batch Loss=0.00375] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 51.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.0009000000000000001]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/200: 71it [00:10,  6.52it/s, Batch Loss=0.00361]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 44.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.0009000000000000001]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/200: 71it [00:10,  6.70it/s, Batch Loss=0.0116]  \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 45.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.0009000000000000001]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/200: 71it [00:10,  6.69it/s, Batch Loss=0.00597]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 47.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.0008100000000000001]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/200: 71it [00:10,  6.70it/s, Batch Loss=0.00532] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 48.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.0008100000000000001]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/200: 71it [00:10,  6.65it/s, Batch Loss=0.0158]  \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 46.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.0008100000000000001]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/200: 71it [00:10,  6.61it/s, Batch Loss=0.00576] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 47.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.0008100000000000001]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/200: 71it [00:10,  6.65it/s, Batch Loss=0.00188] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 44.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.0008100000000000001]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/200: 71it [00:10,  6.61it/s, Batch Loss=0.0145]  \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 42.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.000729]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/200: 71it [00:10,  6.68it/s, Batch Loss=0.00153]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 45.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.000729]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/200: 71it [00:10,  6.67it/s, Batch Loss=0.00704] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 41.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.000729]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/200: 71it [00:10,  6.64it/s, Batch Loss=0.00229] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 45.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.000729]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/200: 71it [00:10,  6.67it/s, Batch Loss=0.0082]  \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 45.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.000729]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/200: 71it [00:10,  6.71it/s, Batch Loss=0.034]   \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 45.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.0006561000000000001]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/200: 71it [00:10,  6.71it/s, Batch Loss=0.00437] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 42.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.0006561000000000001]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/200: 71it [00:10,  6.64it/s, Batch Loss=0.00125] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 46.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.0006561000000000001]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/200: 71it [00:10,  6.65it/s, Batch Loss=0.00154] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 46.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.0006561000000000001]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/200: 71it [00:10,  6.62it/s, Batch Loss=0.00244] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 38.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.0006561000000000001]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/200: 71it [00:10,  6.65it/s, Batch Loss=0.0164]  \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 44.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00059049]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/200: 71it [00:10,  6.65it/s, Batch Loss=0.0111]  \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 45.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00059049]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/200: 71it [00:10,  6.64it/s, Batch Loss=0.00107]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 44.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00059049]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/200: 71it [00:10,  6.67it/s, Batch Loss=0.00139] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 44.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00059049]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/200: 71it [00:10,  6.64it/s, Batch Loss=0.00644] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 46.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00059049]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/200: 71it [00:10,  6.64it/s, Batch Loss=0.00674] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 46.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.000531441]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/200: 71it [00:10,  6.65it/s, Batch Loss=0.00518] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 44.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.000531441]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32/200: 71it [00:10,  6.64it/s, Batch Loss=0.000783]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 43.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.000531441]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33/200: 71it [00:10,  6.46it/s, Batch Loss=0.0071] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 47.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.000531441]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34/200: 71it [00:10,  6.56it/s, Batch Loss=0.049]   \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 44.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.000531441]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35/200: 71it [00:10,  6.57it/s, Batch Loss=0.0726]  \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 47.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.0004782969]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36/200: 71it [00:10,  6.68it/s, Batch Loss=0.0808]  \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 43.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.0004782969]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37/200: 71it [00:10,  6.63it/s, Batch Loss=0.071]  \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 45.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.0004782969]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38/200: 71it [00:10,  6.66it/s, Batch Loss=0.0651]  \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 47.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.0004782969]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39/200: 71it [00:10,  6.66it/s, Batch Loss=0.0622]  \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 46.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.0004782969]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40/200: 71it [00:10,  6.67it/s, Batch Loss=0.0556] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 46.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00043046721]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41/200: 71it [00:10,  6.67it/s, Batch Loss=0.0399]  \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 45.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00043046721]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42/200: 71it [00:10,  6.66it/s, Batch Loss=0.0353] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 43.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00043046721]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43/200: 71it [00:10,  6.67it/s, Batch Loss=0.0537]  \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 46.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00043046721]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44/200: 71it [00:10,  6.63it/s, Batch Loss=0.0483]  \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 47.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00043046721]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45/200: 71it [00:10,  6.67it/s, Batch Loss=0.055]   \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 43.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.000387420489]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46/200: 71it [00:10,  6.65it/s, Batch Loss=0.0349] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 47.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.000387420489]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47/200: 71it [00:10,  6.70it/s, Batch Loss=0.0261]  \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 48.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.000387420489]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48/200: 71it [00:10,  6.65it/s, Batch Loss=0.0416]  \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 46.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.000387420489]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49/200: 71it [00:10,  6.67it/s, Batch Loss=0.00229] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 46.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.000387420489]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50/200: 71it [00:10,  6.65it/s, Batch Loss=0.0162]  \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 46.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.0003486784401]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 51/200: 71it [00:10,  6.68it/s, Batch Loss=0.000183]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 42.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.0003486784401]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 52/200: 71it [00:10,  6.69it/s, Batch Loss=0.00132] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 43.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.0003486784401]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 53/200: 71it [00:10,  6.68it/s, Batch Loss=0.000649]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 46.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.0003486784401]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 54/200: 71it [00:10,  6.66it/s, Batch Loss=0.00032] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 48.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.0003486784401]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 55/200: 71it [00:10,  6.64it/s, Batch Loss=0.00279] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 44.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00031381059609000004]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 56/200: 71it [00:10,  6.67it/s, Batch Loss=0.000774]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 51.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00031381059609000004]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 57/200: 71it [00:10,  6.67it/s, Batch Loss=0.000307]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 42.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00031381059609000004]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 58/200: 71it [00:10,  6.68it/s, Batch Loss=0.000124]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 45.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00031381059609000004]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 59/200: 71it [00:10,  6.69it/s, Batch Loss=0.000404]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 45.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00031381059609000004]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 60/200: 71it [00:10,  6.68it/s, Batch Loss=0.000154]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 44.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00028242953648100003]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 61/200: 71it [00:10,  6.72it/s, Batch Loss=0.00225] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 48.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00028242953648100003]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 62/200: 71it [00:10,  6.67it/s, Batch Loss=0.0002]  \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 45.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00028242953648100003]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 63/200: 71it [00:10,  6.67it/s, Batch Loss=0.000393]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 47.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00028242953648100003]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 64/200: 71it [00:10,  6.66it/s, Batch Loss=0.00335] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 46.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00028242953648100003]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 65/200: 71it [00:10,  6.69it/s, Batch Loss=0.000271]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 45.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00025418658283290005]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 66/200: 71it [00:10,  6.65it/s, Batch Loss=0.000433]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 43.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00025418658283290005]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 67/200: 71it [00:10,  6.68it/s, Batch Loss=0.00525] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 45.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00025418658283290005]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 68/200: 71it [00:10,  6.70it/s, Batch Loss=0.000232]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 47.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00025418658283290005]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 69/200: 71it [00:10,  6.64it/s, Batch Loss=0.000163]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 42.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00025418658283290005]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 70/200: 71it [00:10,  6.65it/s, Batch Loss=0.000231]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 41.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00022876792454961005]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 71/200: 71it [00:10,  6.64it/s, Batch Loss=0.00015] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 44.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00022876792454961005]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 72/200: 71it [00:10,  6.61it/s, Batch Loss=0.000101]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 46.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00022876792454961005]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 73/200: 71it [00:10,  6.62it/s, Batch Loss=0.000115]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 46.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00022876792454961005]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 74/200: 71it [00:10,  6.62it/s, Batch Loss=0.000136]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 47.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00022876792454961005]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 75/200: 71it [00:10,  6.64it/s, Batch Loss=8.03e-5] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 47.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00020589113209464906]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 76/200: 71it [00:10,  6.65it/s, Batch Loss=8.63e-5] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 45.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00020589113209464906]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 77/200: 71it [00:10,  6.63it/s, Batch Loss=0.000163]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 47.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00020589113209464906]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 78/200: 71it [00:10,  6.64it/s, Batch Loss=8.56e-5] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 45.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00020589113209464906]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 79/200: 71it [00:10,  6.68it/s, Batch Loss=0.00011] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 45.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00020589113209464906]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 80/200: 71it [00:10,  6.66it/s, Batch Loss=0.00015] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 48.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00018530201888518417]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 81/200: 71it [00:10,  6.66it/s, Batch Loss=5.22e-5] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 46.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00018530201888518417]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 82/200: 71it [00:10,  6.66it/s, Batch Loss=5.08e-5] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 42.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00018530201888518417]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 83/200: 71it [00:10,  6.62it/s, Batch Loss=0.000135]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 46.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00018530201888518417]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 84/200: 71it [00:10,  6.68it/s, Batch Loss=4.36e-5] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 46.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00018530201888518417]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 85/200: 71it [00:10,  6.69it/s, Batch Loss=6.48e-5] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 46.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00016677181699666576]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 86/200: 71it [00:10,  6.63it/s, Batch Loss=0.000106]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 48.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00016677181699666576]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 87/200: 71it [00:10,  6.64it/s, Batch Loss=5.93e-5] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 45.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00016677181699666576]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 88/200: 71it [00:10,  6.67it/s, Batch Loss=7.36e-5] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 42.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00016677181699666576]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 89/200: 71it [00:10,  6.61it/s, Batch Loss=0.000102]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 47.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00016677181699666576]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 90/200: 71it [00:10,  6.66it/s, Batch Loss=0.000114]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 41.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.0001500946352969992]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 91/200: 71it [00:10,  6.64it/s, Batch Loss=9.77e-5] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 45.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.0001500946352969992]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 92/200: 71it [00:10,  6.66it/s, Batch Loss=0.000117]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 44.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.0001500946352969992]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 93/200: 71it [00:10,  6.65it/s, Batch Loss=0.000136]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 45.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.0001500946352969992]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 94/200: 71it [00:10,  6.71it/s, Batch Loss=0.000104]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 46.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.0001500946352969992]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 95/200: 71it [00:10,  6.66it/s, Batch Loss=0.000139]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 44.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.0001350851717672993]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 96/200: 71it [00:10,  6.66it/s, Batch Loss=0.000146]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 45.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.0001350851717672993]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 97/200: 71it [00:10,  6.63it/s, Batch Loss=8.63e-5] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 45.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.0001350851717672993]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 98/200: 71it [00:10,  6.66it/s, Batch Loss=9.36e-5] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 42.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.0001350851717672993]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 99/200: 71it [00:10,  6.71it/s, Batch Loss=0.000148]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 46.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.0001350851717672993]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 100/200: 71it [00:10,  6.62it/s, Batch Loss=7.79e-5] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 45.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00012157665459056936]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 101/200: 71it [00:10,  6.63it/s, Batch Loss=7.59e-5] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 49.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00012157665459056936]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 102/200: 71it [00:10,  6.64it/s, Batch Loss=0.000101]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 44.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00012157665459056936]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 103/200: 71it [00:10,  6.66it/s, Batch Loss=7.64e-5] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 48.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00012157665459056936]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 104/200: 71it [00:10,  6.70it/s, Batch Loss=7.37e-5] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 48.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00012157665459056936]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 105/200: 71it [00:10,  6.64it/s, Batch Loss=8.04e-5] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 43.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00010941898913151243]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 106/200: 71it [00:10,  6.69it/s, Batch Loss=7.55e-5] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 44.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00010941898913151243]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 107/200: 71it [00:10,  6.67it/s, Batch Loss=7.16e-5] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 43.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00010941898913151243]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 108/200: 71it [00:10,  6.65it/s, Batch Loss=5.85e-5] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 45.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00010941898913151243]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 109/200: 71it [00:10,  6.69it/s, Batch Loss=5.68e-5] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 44.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[0.00010941898913151243]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 110/200: 71it [00:10,  6.69it/s, Batch Loss=7.12e-5] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 43.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[9.847709021836118e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 111/200: 71it [00:10,  6.69it/s, Batch Loss=8.31e-5] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 47.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[9.847709021836118e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 112/200: 71it [00:10,  6.67it/s, Batch Loss=5.4e-5]  \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 45.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[9.847709021836118e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 113/200: 71it [00:10,  6.60it/s, Batch Loss=4.63e-5] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 43.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[9.847709021836118e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 114/200: 71it [00:10,  6.64it/s, Batch Loss=5.77e-5] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 44.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[9.847709021836118e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 115/200: 71it [00:10,  6.69it/s, Batch Loss=6.74e-5] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 42.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[8.862938119652506e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 116/200: 71it [00:10,  6.73it/s, Batch Loss=7.09e-5] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 46.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[8.862938119652506e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 117/200: 71it [00:10,  6.66it/s, Batch Loss=4.63e-5] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 45.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[8.862938119652506e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 118/200: 71it [00:10,  6.70it/s, Batch Loss=5.94e-5] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 46.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[8.862938119652506e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 119/200: 71it [00:10,  6.67it/s, Batch Loss=9.33e-5] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 43.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[8.862938119652506e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 120/200: 71it [00:10,  6.66it/s, Batch Loss=9.96e-5] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 44.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[7.976644307687256e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 121/200: 71it [00:10,  6.65it/s, Batch Loss=6.73e-5] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 42.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[7.976644307687256e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 122/200: 71it [00:10,  6.68it/s, Batch Loss=7.75e-5] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 45.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[7.976644307687256e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 123/200: 71it [00:10,  6.65it/s, Batch Loss=0.000109]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 45.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[7.976644307687256e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 124/200: 71it [00:10,  6.71it/s, Batch Loss=8.76e-5] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 46.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[7.976644307687256e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 125/200: 71it [00:10,  6.70it/s, Batch Loss=8.67e-5] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 46.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[7.17897987691853e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 126/200: 71it [00:10,  6.67it/s, Batch Loss=8.35e-5] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 45.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[7.17897987691853e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 127/200: 71it [00:10,  6.62it/s, Batch Loss=7.96e-5] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 44.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[7.17897987691853e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 128/200: 71it [00:10,  6.69it/s, Batch Loss=8.51e-5] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 44.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[7.17897987691853e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 129/200: 71it [00:10,  6.66it/s, Batch Loss=8.37e-5] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 41.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[7.17897987691853e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 130/200: 71it [00:10,  6.67it/s, Batch Loss=7.81e-5] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 47.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[6.461081889226677e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 131/200: 71it [00:10,  6.65it/s, Batch Loss=8.96e-5] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 43.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[6.461081889226677e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 132/200: 71it [00:10,  6.66it/s, Batch Loss=8.62e-5] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 45.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[6.461081889226677e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 133/200: 71it [00:10,  6.66it/s, Batch Loss=8.36e-5] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 45.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[6.461081889226677e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 134/200: 71it [00:10,  6.63it/s, Batch Loss=9.07e-5] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 47.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[6.461081889226677e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 135/200: 71it [00:10,  6.64it/s, Batch Loss=8.96e-5] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 42.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[5.81497370030401e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 136/200: 71it [00:10,  6.67it/s, Batch Loss=8.62e-5] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 46.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[5.81497370030401e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 137/200: 71it [00:10,  6.59it/s, Batch Loss=8.71e-5] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 44.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[5.81497370030401e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 138/200: 71it [00:10,  6.64it/s, Batch Loss=9.23e-5] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 44.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[5.81497370030401e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 139/200: 71it [00:10,  6.66it/s, Batch Loss=8.8e-5]  \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 43.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[5.81497370030401e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 140/200: 71it [00:10,  6.68it/s, Batch Loss=9.23e-5] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 46.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[5.233476330273609e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 141/200: 71it [00:10,  6.65it/s, Batch Loss=9.71e-5] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 45.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[5.233476330273609e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 142/200: 71it [00:10,  6.69it/s, Batch Loss=9.49e-5] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 46.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[5.233476330273609e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 143/200: 71it [00:10,  6.65it/s, Batch Loss=9.38e-5] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 47.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[5.233476330273609e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 144/200: 71it [00:10,  6.67it/s, Batch Loss=9.63e-5] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 44.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[5.233476330273609e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 145/200: 71it [00:10,  6.65it/s, Batch Loss=9.88e-5] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 42.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[4.7101286972462485e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 146/200: 71it [00:10,  6.67it/s, Batch Loss=9.75e-5] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 46.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[4.7101286972462485e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 147/200: 71it [00:10,  6.67it/s, Batch Loss=0.0001]  \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 44.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[4.7101286972462485e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 148/200: 71it [00:10,  6.63it/s, Batch Loss=9.92e-5] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 45.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[4.7101286972462485e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 149/200: 71it [00:10,  6.68it/s, Batch Loss=0.000103]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 43.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[4.7101286972462485e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 150/200: 71it [00:10,  6.66it/s, Batch Loss=0.000102]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 46.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[4.239115827521624e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 151/200: 71it [00:10,  6.69it/s, Batch Loss=0.000101]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 46.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[4.239115827521624e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 152/200: 71it [00:10,  6.61it/s, Batch Loss=0.000104]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 42.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[4.239115827521624e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 153/200: 71it [00:10,  6.66it/s, Batch Loss=0.000104]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 44.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[4.239115827521624e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 154/200: 71it [00:10,  6.66it/s, Batch Loss=0.000104]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 46.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[4.239115827521624e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 155/200: 71it [00:10,  6.66it/s, Batch Loss=0.000104]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 41.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[3.8152042447694614e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 156/200: 71it [00:10,  6.63it/s, Batch Loss=0.000106]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 45.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[3.8152042447694614e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 157/200: 71it [00:10,  6.65it/s, Batch Loss=0.000106]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 45.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[3.8152042447694614e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 158/200: 71it [00:10,  6.66it/s, Batch Loss=0.000105]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 46.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[3.8152042447694614e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 159/200: 71it [00:10,  6.67it/s, Batch Loss=0.000109]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 45.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[3.8152042447694614e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 160/200: 71it [00:10,  6.67it/s, Batch Loss=0.000107]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 44.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[3.433683820292515e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 161/200: 71it [00:10,  6.68it/s, Batch Loss=0.000108]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 46.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[3.433683820292515e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 162/200: 71it [00:10,  6.67it/s, Batch Loss=0.000109]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 43.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[3.433683820292515e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 163/200: 71it [00:10,  6.68it/s, Batch Loss=0.00011] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 44.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[3.433683820292515e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 164/200: 71it [00:10,  6.67it/s, Batch Loss=0.000108]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 44.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[3.433683820292515e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 165/200: 71it [00:10,  6.65it/s, Batch Loss=0.000111]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 47.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[3.090315438263264e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 166/200: 71it [00:10,  6.64it/s, Batch Loss=0.000111]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 46.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[3.090315438263264e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 167/200: 71it [00:10,  6.67it/s, Batch Loss=0.000108]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 43.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[3.090315438263264e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 168/200: 71it [00:10,  6.70it/s, Batch Loss=0.000111]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 47.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[3.090315438263264e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 169/200: 71it [00:10,  6.63it/s, Batch Loss=0.000112]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 45.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[3.090315438263264e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 170/200: 71it [00:10,  6.65it/s, Batch Loss=0.000111]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 47.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[2.7812838944369376e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 171/200: 71it [00:10,  6.63it/s, Batch Loss=0.000112]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 45.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[2.7812838944369376e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 172/200: 71it [00:10,  6.63it/s, Batch Loss=0.000109]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 46.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[2.7812838944369376e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 173/200: 71it [00:10,  6.62it/s, Batch Loss=0.000111]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 45.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[2.7812838944369376e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 174/200: 71it [00:10,  6.68it/s, Batch Loss=0.000111]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 45.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[2.7812838944369376e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 175/200: 71it [00:10,  6.62it/s, Batch Loss=0.000113]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 48.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[2.503155504993244e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 176/200: 71it [00:10,  6.64it/s, Batch Loss=0.000112]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 47.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[2.503155504993244e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 177/200: 71it [00:10,  6.46it/s, Batch Loss=0.000112]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 47.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[2.503155504993244e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 178/200: 71it [00:10,  6.50it/s, Batch Loss=0.000113]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 49.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[2.503155504993244e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 179/200: 71it [00:10,  6.56it/s, Batch Loss=0.000113]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 47.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[2.503155504993244e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 180/200: 71it [00:10,  6.69it/s, Batch Loss=0.000112]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 43.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[2.2528399544939195e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 181/200: 71it [00:10,  6.63it/s, Batch Loss=0.000112]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 44.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[2.2528399544939195e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 182/200: 71it [00:10,  6.64it/s, Batch Loss=0.000111]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 44.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[2.2528399544939195e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 183/200: 71it [00:10,  6.66it/s, Batch Loss=0.000112]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 46.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[2.2528399544939195e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 184/200: 71it [00:10,  6.68it/s, Batch Loss=0.000109]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 44.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[2.2528399544939195e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 185/200: 71it [00:10,  6.66it/s, Batch Loss=0.000112]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 46.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[2.0275559590445276e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 186/200: 71it [00:10,  6.67it/s, Batch Loss=0.00011] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 45.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[2.0275559590445276e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 187/200: 71it [00:10,  6.68it/s, Batch Loss=0.000109]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 49.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[2.0275559590445276e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 188/200: 71it [00:10,  6.66it/s, Batch Loss=0.00011] \n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 46.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[2.0275559590445276e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 189/200: 71it [00:10,  6.66it/s, Batch Loss=0.000109]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 43.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[2.0275559590445276e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 190/200: 71it [00:10,  6.64it/s, Batch Loss=0.000109]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 45.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[1.8248003631400748e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 191/200: 71it [00:10,  6.67it/s, Batch Loss=0.000108]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 47.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[1.8248003631400748e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 192/200: 71it [00:10,  6.68it/s, Batch Loss=0.000109]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 47.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[1.8248003631400748e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 193/200: 71it [00:10,  6.67it/s, Batch Loss=0.000107]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 45.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[1.8248003631400748e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 194/200: 71it [00:10,  6.66it/s, Batch Loss=0.000108]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 46.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[1.8248003631400748e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 195/200: 71it [00:10,  6.67it/s, Batch Loss=0.000107]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 47.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[1.6423203268260675e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 196/200: 71it [00:10,  6.66it/s, Batch Loss=0.000107]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 45.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[1.6423203268260675e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 197/200: 71it [00:10,  6.72it/s, Batch Loss=0.000107]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 47.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[1.6423203268260675e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 198/200: 71it [00:10,  6.67it/s, Batch Loss=0.000106]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 44.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[1.6423203268260675e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 199/200: 71it [00:10,  6.65it/s, Batch Loss=0.000106]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 46.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[1.6423203268260675e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 200/200: 71it [00:10,  6.67it/s, Batch Loss=0.000105]\n",
      "Validation: 100%|██████████| 18/18 [00:00<00:00, 42.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:[1.4780882941434607e-05]\n",
      "Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\n",
      "Running whole dataset prediction\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Train_loss</td><td>▆█▅▅▄█▆█▇▇▄▄▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Val_loss</td><td>▁▁▂▁▁▂▁█▄▄▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Train_loss</td><td>0.00201</td></tr><tr><td>Val_loss</td><td>0.0001</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">ancient-paper-738</strong> at: <a href='https://wandb.ai/energy_project_uab/energy_project_uab/runs/wr52s5p1' target=\"_blank\">https://wandb.ai/energy_project_uab/energy_project_uab/runs/wr52s5p1</a><br/>Synced 6 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230601_031140-wr52s5p1/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_idx = 2\n",
    "model = attentiveLSTM_model(espai_emb_dim=50,hidden_dim=384,lstm_nl=1,nheads=2,attnFCdim=80)\n",
    "model.init_weights()\n",
    "model.to(device)\n",
    "\n",
    "criterion =  nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001) #lr used in that \n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=(1 - 0.0001 / 0.001))\n",
    "num_epochs = 200\n",
    "best_loss = float('inf')\n",
    "epoch_loss_tr = []\n",
    "epoch_loss_vl = []\n",
    "with wandb.init(project=\"energy_project_uab\", entity = \"energy_project_uab\") as run:\n",
    "    run.name = f\"LSTM_attention_regressor_2\"\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        training_losses = [] # renamed from epoch_losses\n",
    "        progress_bar = tqdm(enumerate(train_dataloader), desc=f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "        for batch,data in progress_bar:\n",
    "            ocu_emb, espai_enc, general_data = data[\"ocu_ber_emb\"].float().to(device) ,data[\"espai_enc\"].float().to(device) ,data[\"general_data\"].float().to(device)\n",
    "            y = data[\"y\"][:,y_idx].float().to(device) #we'll do one counter for now\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            #current batch size size\n",
    "            b_sz = ocu_emb.shape[0]\n",
    "\n",
    "            #note the dataloader with a batch of 100 when reachs the end expects a batch of 60\n",
    "            h, c = model.init_hidden(b_sz) # Start with a new state in each batch            \n",
    "            h = h.to(device)\n",
    "            c = c.to(device)\n",
    "            y_pred, h,c= model(ocu_emb, espai_enc, general_data, h, c)\n",
    "            y_pred = y_pred[:,0,0]\n",
    "\n",
    "            loss = criterion(y_pred,y)  #cross entropy loss needs (N,C,seq_lenght)\n",
    "            loss.backward()\n",
    "            optimizer.step()    \n",
    "\n",
    "            training_losses.append(loss.item())\n",
    "            progress_bar.set_postfix({'Batch Loss': loss.item()})\n",
    "\n",
    "        average_training_loss = sum(training_losses) / len(training_losses) # renamed from avg_loss\n",
    "        epoch_loss_tr.append(average_training_loss)\n",
    "        wandb.log({\"Train_loss\":average_training_loss})\n",
    "        #average_training_loss = np.power(dataset.denormalize_values(np.sqrt(average_training_loss),scaler),2)\n",
    "\n",
    "        model.eval()  \n",
    "        with torch.no_grad():  \n",
    "            validation_losses = [] # renamed from val_losses\n",
    "            for batch in tqdm(val_dataloader, desc='Validation'):\n",
    "                ocu_emb, espai_enc, general_data = data[\"ocu_ber_emb\"].float().to(device) ,data[\"espai_enc\"].float().to(device) ,data[\"general_data\"].float().to(device)\n",
    "                y = data[\"y\"][:,y_idx].float().to(device) #we'll do one counter for now\n",
    "\n",
    "                #current batch size size\n",
    "                b_sz = ocu_emb.shape[0]\n",
    "\n",
    "                #note the dataloader with a batch of 100 when reachs the end expects a batch of 60\n",
    "                h, c = model.init_hidden(b_sz) # Start with a new state in each batch            \n",
    "                h = h.to(device)\n",
    "                c = c.to(device)\n",
    "                y_pred, h,c= model(ocu_emb, espai_enc, general_data, h, c)\n",
    "                y_pred = y_pred[:,0,0]\n",
    "                \n",
    "                loss = criterion(y_pred,y) \n",
    "                validation_losses.append(loss.item())\n",
    "\n",
    "            average_validation_loss = sum(validation_losses) / len(validation_losses) # renamed from avg_val_loss\n",
    "            #average_validation_loss = np.power(dataset.denormalize_values(np.sqrt(average_validation_loss),scaler),2)\n",
    "            epoch_loss_vl.append(average_validation_loss)\n",
    "            wandb.log({\"Val_loss\":average_validation_loss})\n",
    "        \n",
    "        scheduler.step() #change lr\n",
    "        print(f\"lr:{scheduler.get_last_lr()}\")#print current lr\n",
    "\n",
    "        if average_validation_loss < best_loss:\n",
    "            best_loss = average_training_loss\n",
    "            torch.save(model.state_dict(), 'models/attention_exp_LSTM/LSTM_attention_regressor_2.pt')\n",
    "            wandb.save('models/attention_exp_LSTM/LSTM_attention_regressor_2.pt')\n",
    "            print(\"Model saved at models/attention_exp_LSTM/LSTM_attention_regressor_2.pt\")\n",
    "        \n",
    "        if epoch == num_epochs-1: #if last epoch just finished\n",
    "            print(\"Running whole dataset prediction\")\n",
    "            real, pred = predict_consumption(model,whole_dataloader,y_idx)\n",
    "            real = [v.item() for v in real]\n",
    "            pred = [v.item() for v in pred]\n",
    "            scaler = dataset.column_scalers[dataset.target_labels[y_idx]]\n",
    "            real_sc = dataset.denormalize_values(real,scaler)\n",
    "            pred_sc = dataset.denormalize_values(pred,scaler)\n",
    "            res_sc = pred_sc-real_sc\n",
    "           # Plotting the main data\n",
    "            plt.subplot(2, 1, 1)  # Create a subplot with 2 rows and 1 column, and select the first subplot\n",
    "            plt.plot(real_sc, label='Real')  # Add a label for the real data\n",
    "            plt.plot(pred_sc, label='Predicted')  # Add a label for the predicted data\n",
    "\n",
    "            # Plotting the residual data\n",
    "            plt.subplot(2, 1, 2)  # Select the second subplot\n",
    "            plt.plot(res_sc, label='Residual')  # Add a label for the residual data\n",
    "            wandb.log({\"KWh hourly in 2022\": plt})\n",
    "\n",
    "                        # Display the plot\n",
    "            plt.show()\n",
    "\n",
    "                    \n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We thought that instead of doing that manually by trying and error we will create a second model, given this first one is frozen that will try to minimize the energy consumption by given some input of activities generating the Espai where it should be hold in. We'll put in an important loss for repeating the same espai for different activities. \n",
    "\n",
    "Then we'll do the same but for the opposite, make it attempt to using the same mechanism make the energy consumption as high as possible. This way with both, we'll be able to detect what \"espais\" are related with more consumption."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could further do the same for activities but we are going to keep it simple for now..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.9 ('ML')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "da600ade1a771c82ddf6d22a5a41f856afbf3528a3611e1c80e3ac6da17c9450"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
