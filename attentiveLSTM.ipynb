{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%cd drive/MyDrive/energy_project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"mps\"\n",
    "#device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.attention_exp_LSTM.dataset import energyProject_dataset\n",
    "from models.attention_exp_LSTM.network import attentiveLSTM_model\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import yaml\n",
    "import wandb\n",
    "from typing import Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m dataset\u001b[38;5;241m.\u001b[39mactivitivity_encoding_mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;66;03m#or any value\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Splitting the dataset into training and validation sets\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m train_data, val_data \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m train_dataloader \u001b[38;5;241m=\u001b[39m DataLoader(train_data, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     23\u001b[0m val_dataloader \u001b[38;5;241m=\u001b[39m DataLoader(val_data, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniforge3/envs/ML/lib/python3.10/site-packages/sklearn/model_selection/_split.py:2585\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2581\u001b[0m     cv \u001b[39m=\u001b[39m CVClass(test_size\u001b[39m=\u001b[39mn_test, train_size\u001b[39m=\u001b[39mn_train, random_state\u001b[39m=\u001b[39mrandom_state)\n\u001b[1;32m   2583\u001b[0m     train, test \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(cv\u001b[39m.\u001b[39msplit(X\u001b[39m=\u001b[39marrays[\u001b[39m0\u001b[39m], y\u001b[39m=\u001b[39mstratify))\n\u001b[0;32m-> 2585\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39;49m(\n\u001b[1;32m   2586\u001b[0m     chain\u001b[39m.\u001b[39;49mfrom_iterable(\n\u001b[1;32m   2587\u001b[0m         (_safe_indexing(a, train), _safe_indexing(a, test)) \u001b[39mfor\u001b[39;49;00m a \u001b[39min\u001b[39;49;00m arrays\n\u001b[1;32m   2588\u001b[0m     )\n\u001b[1;32m   2589\u001b[0m )\n",
      "File \u001b[0;32m~/miniforge3/envs/ML/lib/python3.10/site-packages/sklearn/model_selection/_split.py:2587\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   2581\u001b[0m     cv \u001b[39m=\u001b[39m CVClass(test_size\u001b[39m=\u001b[39mn_test, train_size\u001b[39m=\u001b[39mn_train, random_state\u001b[39m=\u001b[39mrandom_state)\n\u001b[1;32m   2583\u001b[0m     train, test \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(cv\u001b[39m.\u001b[39msplit(X\u001b[39m=\u001b[39marrays[\u001b[39m0\u001b[39m], y\u001b[39m=\u001b[39mstratify))\n\u001b[1;32m   2585\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39m(\n\u001b[1;32m   2586\u001b[0m     chain\u001b[39m.\u001b[39mfrom_iterable(\n\u001b[0;32m-> 2587\u001b[0m         (_safe_indexing(a, train), _safe_indexing(a, test)) \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m arrays\n\u001b[1;32m   2588\u001b[0m     )\n\u001b[1;32m   2589\u001b[0m )\n",
      "File \u001b[0;32m~/miniforge3/envs/ML/lib/python3.10/site-packages/sklearn/utils/__init__.py:358\u001b[0m, in \u001b[0;36m_safe_indexing\u001b[0;34m(X, indices, axis)\u001b[0m\n\u001b[1;32m    356\u001b[0m     \u001b[39mreturn\u001b[39;00m _array_indexing(X, indices, indices_dtype, axis\u001b[39m=\u001b[39maxis)\n\u001b[1;32m    357\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 358\u001b[0m     \u001b[39mreturn\u001b[39;00m _list_indexing(X, indices, indices_dtype)\n",
      "File \u001b[0;32m~/miniforge3/envs/ML/lib/python3.10/site-packages/sklearn/utils/__init__.py:212\u001b[0m, in \u001b[0;36m_list_indexing\u001b[0;34m(X, key, key_dtype)\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39m(compress(X, key))\n\u001b[1;32m    211\u001b[0m \u001b[39m# key is a integer array-like of key\u001b[39;00m\n\u001b[0;32m--> 212\u001b[0m \u001b[39mreturn\u001b[39;00m [X[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m key]\n",
      "File \u001b[0;32m~/miniforge3/envs/ML/lib/python3.10/site-packages/sklearn/utils/__init__.py:212\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39m(compress(X, key))\n\u001b[1;32m    211\u001b[0m \u001b[39m# key is a integer array-like of key\u001b[39;00m\n\u001b[0;32m--> 212\u001b[0m \u001b[39mreturn\u001b[39;00m [X[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m key]\n",
      "File \u001b[0;32m~/Documents/UNI/SYNTHS_PROJECT/energy_analysis_project/models/attention_exp_LSTM/dataset.py:251\u001b[0m, in \u001b[0;36menergyProject_dataset.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    248\u001b[0m target_tens \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(row[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_labels])\n\u001b[1;32m    250\u001b[0m \u001b[39m#Get activities at given time and date\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m activities \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mactivty_class_perT(row[\u001b[39m\"\u001b[39;49m\u001b[39mdate\u001b[39;49m\u001b[39m\"\u001b[39;49m],row[\u001b[39m\"\u001b[39;49m\u001b[39mtime\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n\u001b[1;32m    252\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mactivitivity_encoding_mode \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    253\u001b[0m     one_hot \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mactivity_class_one_hot(activities)\n",
      "File \u001b[0;32m~/Documents/UNI/SYNTHS_PROJECT/energy_analysis_project/models/attention_exp_LSTM/dataset.py:164\u001b[0m, in \u001b[0;36menergyProject_dataset.activty_class_perT\u001b[0;34m(self, date, time)\u001b[0m\n\u001b[1;32m    162\u001b[0m day2day_ocu \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moccupation_df[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moccupation_df[\u001b[39m\"\u001b[39m\u001b[39mData inicial\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m==\u001b[39m date ] \n\u001b[1;32m    163\u001b[0m h \u001b[39m=\u001b[39m datetime\u001b[39m.\u001b[39mtime(\u001b[39mint\u001b[39m(time))\n\u001b[0;32m--> 164\u001b[0m hour2hour_ocu \u001b[39m=\u001b[39m day2day_ocu[(day2day_ocu[\u001b[39m\"\u001b[39;49m\u001b[39mHora inicial\u001b[39;49m\u001b[39m\"\u001b[39;49m] \u001b[39m<\u001b[39;49m\u001b[39m=\u001b[39;49m h) \u001b[39m&\u001b[39;49m (day2day_ocu[\u001b[39m\"\u001b[39;49m\u001b[39mHora final\u001b[39;49m\u001b[39m\"\u001b[39;49m] \u001b[39m>\u001b[39;49m h)]\n\u001b[1;32m    165\u001b[0m \u001b[39mreturn\u001b[39;00m pd\u001b[39m.\u001b[39mDataFrame(hour2hour_ocu)\n",
      "File \u001b[0;32m~/miniforge3/envs/ML/lib/python3.10/site-packages/pandas/core/frame.py:3798\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3796\u001b[0m \u001b[39m# Do we have a (boolean) 1d indexer?\u001b[39;00m\n\u001b[1;32m   3797\u001b[0m \u001b[39mif\u001b[39;00m com\u001b[39m.\u001b[39mis_bool_indexer(key):\n\u001b[0;32m-> 3798\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_bool_array(key)\n\u001b[1;32m   3800\u001b[0m \u001b[39m# We are left with two options: a single key, and a collection of keys,\u001b[39;00m\n\u001b[1;32m   3801\u001b[0m \u001b[39m# We interpret tuples as collections only for non-MultiIndex\u001b[39;00m\n\u001b[1;32m   3802\u001b[0m is_single_key \u001b[39m=\u001b[39m \u001b[39misinstance\u001b[39m(key, \u001b[39mtuple\u001b[39m) \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m is_list_like(key)\n",
      "File \u001b[0;32m~/miniforge3/envs/ML/lib/python3.10/site-packages/pandas/core/frame.py:3853\u001b[0m, in \u001b[0;36mDataFrame._getitem_bool_array\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3851\u001b[0m key \u001b[39m=\u001b[39m check_bool_indexer(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex, key)\n\u001b[1;32m   3852\u001b[0m indexer \u001b[39m=\u001b[39m key\u001b[39m.\u001b[39mnonzero()[\u001b[39m0\u001b[39m]\n\u001b[0;32m-> 3853\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_take_with_is_copy(indexer, axis\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n",
      "File \u001b[0;32m~/miniforge3/envs/ML/lib/python3.10/site-packages/pandas/core/generic.py:3902\u001b[0m, in \u001b[0;36mNDFrame._take_with_is_copy\u001b[0;34m(self, indices, axis)\u001b[0m\n\u001b[1;32m   3894\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_take_with_is_copy\u001b[39m(\u001b[39mself\u001b[39m: NDFrameT, indices, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m NDFrameT:\n\u001b[1;32m   3895\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   3896\u001b[0m \u001b[39m    Internal version of the `take` method that sets the `_is_copy`\u001b[39;00m\n\u001b[1;32m   3897\u001b[0m \u001b[39m    attribute to keep track of the parent dataframe (using in indexing\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3900\u001b[0m \u001b[39m    See the docstring of `take` for full explanation of the parameters.\u001b[39;00m\n\u001b[1;32m   3901\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3902\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_take(indices\u001b[39m=\u001b[39;49mindices, axis\u001b[39m=\u001b[39;49maxis)\n\u001b[1;32m   3903\u001b[0m     \u001b[39m# Maybe set copy if we didn't actually change the index.\u001b[39;00m\n\u001b[1;32m   3904\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m result\u001b[39m.\u001b[39m_get_axis(axis)\u001b[39m.\u001b[39mequals(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_axis(axis)):\n",
      "File \u001b[0;32m~/miniforge3/envs/ML/lib/python3.10/site-packages/pandas/core/generic.py:3886\u001b[0m, in \u001b[0;36mNDFrame._take\u001b[0;34m(self, indices, axis, convert_indices)\u001b[0m\n\u001b[1;32m   3879\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   3880\u001b[0m \u001b[39mInternal version of the `take` allowing specification of additional args.\u001b[39;00m\n\u001b[1;32m   3881\u001b[0m \n\u001b[1;32m   3882\u001b[0m \u001b[39mSee the docstring of `take` for full explanation of the parameters.\u001b[39;00m\n\u001b[1;32m   3883\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   3884\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_consolidate_inplace()\n\u001b[0;32m-> 3886\u001b[0m new_data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mgr\u001b[39m.\u001b[39;49mtake(\n\u001b[1;32m   3887\u001b[0m     indices,\n\u001b[1;32m   3888\u001b[0m     axis\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_block_manager_axis(axis),\n\u001b[1;32m   3889\u001b[0m     verify\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   3890\u001b[0m     convert_indices\u001b[39m=\u001b[39;49mconvert_indices,\n\u001b[1;32m   3891\u001b[0m )\n\u001b[1;32m   3892\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_constructor(new_data)\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtake\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniforge3/envs/ML/lib/python3.10/site-packages/pandas/core/internals/managers.py:975\u001b[0m, in \u001b[0;36mBaseBlockManager.take\u001b[0;34m(self, indexer, axis, verify, convert_indices)\u001b[0m\n\u001b[1;32m    973\u001b[0m n \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshape[axis]\n\u001b[1;32m    974\u001b[0m \u001b[39mif\u001b[39;00m convert_indices:\n\u001b[0;32m--> 975\u001b[0m     indexer \u001b[39m=\u001b[39m maybe_convert_indices(indexer, n, verify\u001b[39m=\u001b[39;49mverify)\n\u001b[1;32m    977\u001b[0m new_labels \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxes[axis]\u001b[39m.\u001b[39mtake(indexer)\n\u001b[1;32m    978\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreindex_indexer(\n\u001b[1;32m    979\u001b[0m     new_axis\u001b[39m=\u001b[39mnew_labels,\n\u001b[1;32m    980\u001b[0m     indexer\u001b[39m=\u001b[39mindexer,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    983\u001b[0m     copy\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    984\u001b[0m )\n",
      "File \u001b[0;32m~/miniforge3/envs/ML/lib/python3.10/site-packages/pandas/core/indexers/utils.py:279\u001b[0m, in \u001b[0;36mmaybe_convert_indices\u001b[0;34m(indices, n, verify)\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mempty(\u001b[39m0\u001b[39m, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mintp)\n\u001b[1;32m    278\u001b[0m mask \u001b[39m=\u001b[39m indices \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m--> 279\u001b[0m \u001b[39mif\u001b[39;00m mask\u001b[39m.\u001b[39;49many():\n\u001b[1;32m    280\u001b[0m     indices \u001b[39m=\u001b[39m indices\u001b[39m.\u001b[39mcopy()\n\u001b[1;32m    281\u001b[0m     indices[mask] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m n\n",
      "File \u001b[0;32m~/miniforge3/envs/ML/lib/python3.10/site-packages/numpy/core/_methods.py:58\u001b[0m, in \u001b[0;36m_any\u001b[0;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_any\u001b[39m(a, axis\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, out\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, keepdims\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, \u001b[39m*\u001b[39m, where\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m     56\u001b[0m     \u001b[39m# Parsing keyword arguments is currently fairly slow, so avoid it for now\u001b[39;00m\n\u001b[1;32m     57\u001b[0m     \u001b[39mif\u001b[39;00m where \u001b[39mis\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m         \u001b[39mreturn\u001b[39;00m umr_any(a, axis, dtype, out, keepdims)\n\u001b[1;32m     59\u001b[0m     \u001b[39mreturn\u001b[39;00m umr_any(a, axis, dtype, out, keepdims, where\u001b[39m=\u001b[39mwhere)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def nested_dict(original_dict):\n",
    "    nested_dict = {}\n",
    "    for key, value in original_dict.items():\n",
    "        parts = key.split(\".\")\n",
    "        d = nested_dict\n",
    "        for part in parts[:-1]:\n",
    "            if part not in d:\n",
    "                d[part] = {}\n",
    "            d = d[part]\n",
    "        d[parts[-1]] = value\n",
    "    return nested_dict\n",
    "\n",
    "\n",
    "#load dataset object file\n",
    "with (open('data/dataset_class.pkl', \"rb\")) as openfile:\n",
    "    dataset = pickle.load(openfile)\n",
    "\n",
    "dataset.activitivity_encoding_mode = 2 #or any value\n",
    "# Splitting the dataset into training and validation sets\n",
    "train_data, val_data = train_test_split(dataset, test_size=0.2, random_state=42)\n",
    "\n",
    "train_dataloader = DataLoader(train_data, batch_size=100, shuffle=False)\n",
    "val_dataloader = DataLoader(val_data, batch_size=100, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup wandb stuff\n",
    "with open('models/attention_exp_LSTM/config.yaml', 'r') as stream:\n",
    "    try:\n",
    "        sweep_config = yaml.safe_load(stream)\n",
    "    except yaml.YAMLError as exc:\n",
    "        print(exc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_idx=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(config: Dict = None):\n",
    "    with wandb.init(config=config):\n",
    "        config = wandb.config\n",
    "        config = nested_dict(config)\n",
    "        optimizer_config = config[\"optimizer\"]\n",
    "        model = attentiveLSTM_model(espai_emb_dim=config[\"espai_emb_dim\"],hidden_dim=config['hidden_size'],lstm_nl=config['num_layers'],nheads=config['heads'],attnFCdim=config['attnFCdim'])\n",
    "        model.init_weights()\n",
    "        model.to(device)\n",
    "\n",
    "        criterion =  nn.MSELoss()\n",
    "\n",
    "        if optimizer_config[\"type\"] == 'adam':\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr = optimizer_config['lr'])\n",
    "\n",
    "        num_epochs = 80\n",
    "        best_loss = float('inf')\n",
    "        for epoch in range(num_epochs):\n",
    "            model.train()\n",
    "            training_losses = [] # renamed from epoch_losses\n",
    "            progress_bar = tqdm(enumerate(train_dataloader), desc=f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "            for batch,data in progress_bar:\n",
    "                ocu_emb, espai_enc, general_data = data[\"ocu_ber_emb\"].float().to(device) ,data[\"espai_enc\"].float().to(device) ,data[\"general_data\"].float().to(device)\n",
    "                y = data[\"y\"][:,y_idx].float().to(device) #we'll do one counter for now\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                #current batch size size\n",
    "                b_sz = ocu_emb.shape[0]\n",
    "\n",
    "                #note the dataloader with a batch of 100 when reachs the end expects a batch of 60\n",
    "                h, c = model.init_hidden(b_sz) # Start with a new state in each batch            \n",
    "                h = h.to(device)\n",
    "                c = c.to(device)\n",
    "                y_pred, h,c= model(ocu_emb, espai_enc, general_data, h, c)\n",
    "                y_pred = y_pred[:,0,0]\n",
    "\n",
    "                loss = criterion(y_pred,y)  #cross entropy loss needs (N,C,seq_lenght)\n",
    "                loss.backward()\n",
    "                optimizer.step()    \n",
    "\n",
    "                training_losses.append(loss.item())\n",
    "                progress_bar.set_postfix({'Batch Loss': loss.item()})\n",
    "\n",
    "            average_training_loss = sum(training_losses) / len(training_losses) # renamed from avg_loss\n",
    "            wandb.log({'Train_Epoch_Loss': average_training_loss})\n",
    "\n",
    "            model.eval()  \n",
    "            with torch.no_grad():  \n",
    "                validation_losses = [] # renamed from val_losses\n",
    "                for batch in tqdm(val_dataloader, desc='Validation'):\n",
    "                    ocu_emb, espai_enc, general_data = data[\"ocu_ber_emb\"].float().to(device) ,data[\"espai_enc\"].float().to(device) ,data[\"general_data\"].float().to(device)\n",
    "                    y = data[\"y\"][:,y_idx].float().to(device) #we'll do one counter for now\n",
    "\n",
    "                    #current batch size size\n",
    "                    b_sz = ocu_emb.shape[0]\n",
    "\n",
    "                    #note the dataloader with a batch of 100 when reachs the end expects a batch of 60\n",
    "                    h, c = model.init_hidden(b_sz) # Start with a new state in each batch            \n",
    "                    h = h.to(device)\n",
    "                    c = c.to(device)\n",
    "                    y_pred, h,c= model(ocu_emb, espai_enc, general_data, h, c)\n",
    "                    y_pred = y_pred[:,0,0]\n",
    "                    \n",
    "                    loss = criterion(y_pred,y) \n",
    "                    validation_losses.append(loss.item())\n",
    "\n",
    "                average_validation_loss = sum(validation_losses) / len(validation_losses) # renamed from avg_val_loss\n",
    "                wandb.log({'Validation_Epoch_Loss': average_validation_loss})\n",
    "\n",
    "            if average_training_loss < best_loss:\n",
    "                best_loss = average_training_loss\n",
    "                torch.save(model.state_dict(), 'models/attention_exp_LSTM/tranformLSTM.pt')\n",
    "                wandb.save('gru_model.pt')\n",
    "                print(f\"Model saved at {'gru_model.pt'}\")\n",
    "\n",
    "        wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mharadai\u001b[0m (\u001b[33menergy_project_uab\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    }
   ],
   "source": [
    "!wandb login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: zth7l7rp\n",
      "Sweep URL: https://wandb.ai/energy_project_uab/energy_project_uab/sweeps/zth7l7rp\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'zth7l7rp'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sweep_id = wandb.sweep(sweep_config, project=\"energy_project_uab\")\n",
    "sweep_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: jwk5morh with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tattnFCdim: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tespai_emb_dim: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \theads: 24\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 384\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: {'lr': 0.06618753620611678, 'type': 'adam'}\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mharadai\u001b[0m (\u001b[33menergy_project_uab\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/josepsmachine/Documents/UNI/SYNTHS_PROJECT/energy_analysis_project/models/attention_exp_LSTM/wandb/run-20230520_171803-jwk5morh</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/energy_project_uab/energy_project_uab/runs/jwk5morh' target=\"_blank\">exalted-sweep-1</a></strong> to <a href='https://wandb.ai/energy_project_uab/energy_project_uab' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/energy_project_uab/energy_project_uab/sweeps/zth7l7rp' target=\"_blank\">https://wandb.ai/energy_project_uab/energy_project_uab/sweeps/zth7l7rp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/energy_project_uab/energy_project_uab' target=\"_blank\">https://wandb.ai/energy_project_uab/energy_project_uab</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/energy_project_uab/energy_project_uab/sweeps/zth7l7rp' target=\"_blank\">https://wandb.ai/energy_project_uab/energy_project_uab/sweeps/zth7l7rp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/energy_project_uab/energy_project_uab/runs/jwk5morh' target=\"_blank\">https://wandb.ai/energy_project_uab/energy_project_uab/runs/jwk5morh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/80: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:red\">(failed 1).</strong> Press Control-C to abort syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">exalted-sweep-1</strong> at: <a href='https://wandb.ai/energy_project_uab/energy_project_uab/runs/jwk5morh' target=\"_blank\">https://wandb.ai/energy_project_uab/energy_project_uab/runs/jwk5morh</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230520_171803-jwk5morh/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Run jwk5morh errored: RuntimeError('Multi-layer LSTM support in MPS available only on MacOS 13 onwards')\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run jwk5morh errored: RuntimeError('Multi-layer LSTM support in MPS available only on MacOS 13 onwards')\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 41cx8zxt with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tattnFCdim: 80\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tespai_emb_dim: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \theads: 24\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 96\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: {'lr': 0.07377180095912118, 'type': 'adam'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/josepsmachine/Documents/UNI/SYNTHS_PROJECT/energy_analysis_project/models/attention_exp_LSTM/wandb/run-20230520_171842-41cx8zxt</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/energy_project_uab/energy_project_uab/runs/41cx8zxt' target=\"_blank\">twilight-sweep-2</a></strong> to <a href='https://wandb.ai/energy_project_uab/energy_project_uab' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/energy_project_uab/energy_project_uab/sweeps/zth7l7rp' target=\"_blank\">https://wandb.ai/energy_project_uab/energy_project_uab/sweeps/zth7l7rp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/energy_project_uab/energy_project_uab' target=\"_blank\">https://wandb.ai/energy_project_uab/energy_project_uab</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/energy_project_uab/energy_project_uab/sweeps/zth7l7rp' target=\"_blank\">https://wandb.ai/energy_project_uab/energy_project_uab/sweeps/zth7l7rp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/energy_project_uab/energy_project_uab/runs/41cx8zxt' target=\"_blank\">https://wandb.ai/energy_project_uab/energy_project_uab/runs/41cx8zxt</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/80: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:red\">(failed 1).</strong> Press Control-C to abort syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">twilight-sweep-2</strong> at: <a href='https://wandb.ai/energy_project_uab/energy_project_uab/runs/41cx8zxt' target=\"_blank\">https://wandb.ai/energy_project_uab/energy_project_uab/runs/41cx8zxt</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230520_171842-41cx8zxt/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Run 41cx8zxt errored: RuntimeError('Multi-layer LSTM support in MPS available only on MacOS 13 onwards')\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run 41cx8zxt errored: RuntimeError('Multi-layer LSTM support in MPS available only on MacOS 13 onwards')\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 3fstwnsi with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tattnFCdim: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tespai_emb_dim: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \theads: 12\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 96\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: {'lr': 0.04500445351034593, 'type': 'adam'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/josepsmachine/Documents/UNI/SYNTHS_PROJECT/energy_analysis_project/models/attention_exp_LSTM/wandb/run-20230520_171916-3fstwnsi</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/energy_project_uab/energy_project_uab/runs/3fstwnsi' target=\"_blank\">glamorous-sweep-3</a></strong> to <a href='https://wandb.ai/energy_project_uab/energy_project_uab' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/energy_project_uab/energy_project_uab/sweeps/zth7l7rp' target=\"_blank\">https://wandb.ai/energy_project_uab/energy_project_uab/sweeps/zth7l7rp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/energy_project_uab/energy_project_uab' target=\"_blank\">https://wandb.ai/energy_project_uab/energy_project_uab</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/energy_project_uab/energy_project_uab/sweeps/zth7l7rp' target=\"_blank\">https://wandb.ai/energy_project_uab/energy_project_uab/sweeps/zth7l7rp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/energy_project_uab/energy_project_uab/runs/3fstwnsi' target=\"_blank\">https://wandb.ai/energy_project_uab/energy_project_uab/runs/3fstwnsi</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/80: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:red\">(failed 1).</strong> Press Control-C to abort syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Ctrl + C detected. Stopping sweep.\n"
     ]
    }
   ],
   "source": [
    "wandb.agent(sweep_id, function=train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.9 ('ML')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "da600ade1a771c82ddf6d22a5a41f856afbf3528a3611e1c80e3ac6da17c9450"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
