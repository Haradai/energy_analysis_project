{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting jsons file from the sketchy website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "weather_data = pd.DataFrame(columns=[\"date\"])\n",
    "for month in range(1,12+1):\n",
    "    with open(f'data/jsons_weather_monthly/{str(month).zfill(2)}.json') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    for daily in data[\"data\"][\"weather\"]:\n",
    "        hourly_data = []\n",
    "        for hourly in daily[\"hourly\"]:\n",
    "            hourly_data.append(pd.DataFrame.from_dict(hourly))\n",
    "        daily_data = pd.concat(hourly_data)\n",
    "        daily_data[\"date\"] = daily[\"date\"]\n",
    "        weather_data = pd.concat([weather_data, daily_data])\n",
    "\n",
    "weather_data.to_csv(\"data/weather_hourly.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>tempC</th>\n",
       "      <th>tempF</th>\n",
       "      <th>windspeedMiles</th>\n",
       "      <th>windspeedKmph</th>\n",
       "      <th>winddirDegree</th>\n",
       "      <th>winddir16Point</th>\n",
       "      <th>weatherCode</th>\n",
       "      <th>weatherIconUrl</th>\n",
       "      <th>...</th>\n",
       "      <th>HeatIndexF</th>\n",
       "      <th>DewPointC</th>\n",
       "      <th>DewPointF</th>\n",
       "      <th>WindChillC</th>\n",
       "      <th>WindChillF</th>\n",
       "      <th>WindGustMiles</th>\n",
       "      <th>WindGustKmph</th>\n",
       "      <th>FeelsLikeC</th>\n",
       "      <th>FeelsLikeF</th>\n",
       "      <th>uvIndex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>44</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>337</td>\n",
       "      <td>NNW</td>\n",
       "      <td>113</td>\n",
       "      <td>{'value': 'https://cdn.worldweatheronline.com/...</td>\n",
       "      <td>...</td>\n",
       "      <td>44</td>\n",
       "      <td>-3</td>\n",
       "      <td>27</td>\n",
       "      <td>6</td>\n",
       "      <td>43</td>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>100</td>\n",
       "      <td>6</td>\n",
       "      <td>43</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>337</td>\n",
       "      <td>NNW</td>\n",
       "      <td>113</td>\n",
       "      <td>{'value': 'https://cdn.worldweatheronline.com/...</td>\n",
       "      <td>...</td>\n",
       "      <td>43</td>\n",
       "      <td>-4</td>\n",
       "      <td>24</td>\n",
       "      <td>5</td>\n",
       "      <td>41</td>\n",
       "      <td>13</td>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>200</td>\n",
       "      <td>6</td>\n",
       "      <td>42</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>338</td>\n",
       "      <td>NNW</td>\n",
       "      <td>113</td>\n",
       "      <td>{'value': 'https://cdn.worldweatheronline.com/...</td>\n",
       "      <td>...</td>\n",
       "      <td>42</td>\n",
       "      <td>-6</td>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>13</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>300</td>\n",
       "      <td>5</td>\n",
       "      <td>41</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>339</td>\n",
       "      <td>NNW</td>\n",
       "      <td>113</td>\n",
       "      <td>{'value': 'https://cdn.worldweatheronline.com/...</td>\n",
       "      <td>...</td>\n",
       "      <td>41</td>\n",
       "      <td>-7</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>39</td>\n",
       "      <td>13</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>400</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>342</td>\n",
       "      <td>NNW</td>\n",
       "      <td>113</td>\n",
       "      <td>{'value': 'https://cdn.worldweatheronline.com/...</td>\n",
       "      <td>...</td>\n",
       "      <td>40</td>\n",
       "      <td>-8</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>37</td>\n",
       "      <td>13</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-12-31</td>\n",
       "      <td>1900</td>\n",
       "      <td>8</td>\n",
       "      <td>46</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>226</td>\n",
       "      <td>SW</td>\n",
       "      <td>113</td>\n",
       "      <td>{'value': 'https://cdn.worldweatheronline.com/...</td>\n",
       "      <td>...</td>\n",
       "      <td>46</td>\n",
       "      <td>3</td>\n",
       "      <td>38</td>\n",
       "      <td>7</td>\n",
       "      <td>44</td>\n",
       "      <td>16</td>\n",
       "      <td>26</td>\n",
       "      <td>7</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-12-31</td>\n",
       "      <td>2000</td>\n",
       "      <td>9</td>\n",
       "      <td>48</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>223</td>\n",
       "      <td>SW</td>\n",
       "      <td>113</td>\n",
       "      <td>{'value': 'https://cdn.worldweatheronline.com/...</td>\n",
       "      <td>...</td>\n",
       "      <td>48</td>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "      <td>8</td>\n",
       "      <td>46</td>\n",
       "      <td>16</td>\n",
       "      <td>25</td>\n",
       "      <td>8</td>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-12-31</td>\n",
       "      <td>2100</td>\n",
       "      <td>8</td>\n",
       "      <td>47</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>219</td>\n",
       "      <td>SW</td>\n",
       "      <td>113</td>\n",
       "      <td>{'value': 'https://cdn.worldweatheronline.com/...</td>\n",
       "      <td>...</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>7</td>\n",
       "      <td>45</td>\n",
       "      <td>16</td>\n",
       "      <td>26</td>\n",
       "      <td>7</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-12-31</td>\n",
       "      <td>2200</td>\n",
       "      <td>8</td>\n",
       "      <td>46</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>227</td>\n",
       "      <td>SW</td>\n",
       "      <td>113</td>\n",
       "      <td>{'value': 'https://cdn.worldweatheronline.com/...</td>\n",
       "      <td>...</td>\n",
       "      <td>46</td>\n",
       "      <td>-3</td>\n",
       "      <td>26</td>\n",
       "      <td>7</td>\n",
       "      <td>44</td>\n",
       "      <td>18</td>\n",
       "      <td>30</td>\n",
       "      <td>7</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-12-31</td>\n",
       "      <td>2300</td>\n",
       "      <td>8</td>\n",
       "      <td>46</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>235</td>\n",
       "      <td>SW</td>\n",
       "      <td>113</td>\n",
       "      <td>{'value': 'https://cdn.worldweatheronline.com/...</td>\n",
       "      <td>...</td>\n",
       "      <td>46</td>\n",
       "      <td>-7</td>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>44</td>\n",
       "      <td>21</td>\n",
       "      <td>33</td>\n",
       "      <td>6</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8760 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          date  time tempC tempF windspeedMiles windspeedKmph winddirDegree  \\\n",
       "0   2022-01-01     0     7    44              4             6           337   \n",
       "0   2022-01-01   100     6    43              4             6           337   \n",
       "0   2022-01-01   200     6    42              4             6           338   \n",
       "0   2022-01-01   300     5    41              4             6           339   \n",
       "0   2022-01-01   400     4    40              4             6           342   \n",
       "..         ...   ...   ...   ...            ...           ...           ...   \n",
       "0   2022-12-31  1900     8    46              4             7           226   \n",
       "0   2022-12-31  2000     9    48              5             7           223   \n",
       "0   2022-12-31  2100     8    47              5             8           219   \n",
       "0   2022-12-31  2200     8    46              5             8           227   \n",
       "0   2022-12-31  2300     8    46              5             8           235   \n",
       "\n",
       "   winddir16Point weatherCode  \\\n",
       "0             NNW         113   \n",
       "0             NNW         113   \n",
       "0             NNW         113   \n",
       "0             NNW         113   \n",
       "0             NNW         113   \n",
       "..            ...         ...   \n",
       "0              SW         113   \n",
       "0              SW         113   \n",
       "0              SW         113   \n",
       "0              SW         113   \n",
       "0              SW         113   \n",
       "\n",
       "                                       weatherIconUrl  ... HeatIndexF  \\\n",
       "0   {'value': 'https://cdn.worldweatheronline.com/...  ...         44   \n",
       "0   {'value': 'https://cdn.worldweatheronline.com/...  ...         43   \n",
       "0   {'value': 'https://cdn.worldweatheronline.com/...  ...         42   \n",
       "0   {'value': 'https://cdn.worldweatheronline.com/...  ...         41   \n",
       "0   {'value': 'https://cdn.worldweatheronline.com/...  ...         40   \n",
       "..                                                ...  ...        ...   \n",
       "0   {'value': 'https://cdn.worldweatheronline.com/...  ...         46   \n",
       "0   {'value': 'https://cdn.worldweatheronline.com/...  ...         48   \n",
       "0   {'value': 'https://cdn.worldweatheronline.com/...  ...         47   \n",
       "0   {'value': 'https://cdn.worldweatheronline.com/...  ...         46   \n",
       "0   {'value': 'https://cdn.worldweatheronline.com/...  ...         46   \n",
       "\n",
       "   DewPointC DewPointF WindChillC WindChillF WindGustMiles WindGustKmph  \\\n",
       "0         -3        27          6         43            12           19   \n",
       "0         -4        24          5         41            13           21   \n",
       "0         -6        22          4         40            13           21   \n",
       "0         -7        19          4         39            13           21   \n",
       "0         -8        17          3         37            13           21   \n",
       "..       ...       ...        ...        ...           ...          ...   \n",
       "0          3        38          7         44            16           26   \n",
       "0          2        36          8         46            16           25   \n",
       "0          1        34          7         45            16           26   \n",
       "0         -3        26          7         44            18           30   \n",
       "0         -7        19          6         44            21           33   \n",
       "\n",
       "   FeelsLikeC FeelsLikeF uvIndex  \n",
       "0           6         43       1  \n",
       "0           5         41       1  \n",
       "0           4         40       1  \n",
       "0           4         39       1  \n",
       "0           3         37       1  \n",
       "..        ...        ...     ...  \n",
       "0           7         44       1  \n",
       "0           8         46       1  \n",
       "0           7         45       1  \n",
       "0           7         44       1  \n",
       "0           6         44       1  \n",
       "\n",
       "[8760 rows x 30 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### filter interesting columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_data = weather_data[['date', 'time', 'tempC','windspeedKmph','weatherCode','precipMM','humidity','pressure','cloudcover','WindChillC','WindGustKmph','FeelsLikeC','uvIndex']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>tempC</th>\n",
       "      <th>windspeedKmph</th>\n",
       "      <th>weatherCode</th>\n",
       "      <th>precipMM</th>\n",
       "      <th>humidity</th>\n",
       "      <th>pressure</th>\n",
       "      <th>cloudcover</th>\n",
       "      <th>WindChillC</th>\n",
       "      <th>WindGustKmph</th>\n",
       "      <th>FeelsLikeC</th>\n",
       "      <th>uvIndex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>113</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66</td>\n",
       "      <td>1032</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>100</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>113</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64</td>\n",
       "      <td>1032</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>200</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>113</td>\n",
       "      <td>0.0</td>\n",
       "      <td>62</td>\n",
       "      <td>1032</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>300</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>113</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60</td>\n",
       "      <td>1032</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>400</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>113</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58</td>\n",
       "      <td>1032</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-12-31</td>\n",
       "      <td>1900</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>113</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72</td>\n",
       "      <td>1026</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>26</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-12-31</td>\n",
       "      <td>2000</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>113</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69</td>\n",
       "      <td>1026</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>25</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-12-31</td>\n",
       "      <td>2100</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>113</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66</td>\n",
       "      <td>1027</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>26</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-12-31</td>\n",
       "      <td>2200</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>113</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54</td>\n",
       "      <td>1027</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>30</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-12-31</td>\n",
       "      <td>2300</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>113</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42</td>\n",
       "      <td>1027</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>33</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8760 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          date  time tempC windspeedKmph weatherCode precipMM humidity  \\\n",
       "0   2022-01-01     0     7             6         113      0.0       66   \n",
       "0   2022-01-01   100     6             6         113      0.0       64   \n",
       "0   2022-01-01   200     6             6         113      0.0       62   \n",
       "0   2022-01-01   300     5             6         113      0.0       60   \n",
       "0   2022-01-01   400     4             6         113      0.0       58   \n",
       "..         ...   ...   ...           ...         ...      ...      ...   \n",
       "0   2022-12-31  1900     8             7         113      0.0       72   \n",
       "0   2022-12-31  2000     9             7         113      0.0       69   \n",
       "0   2022-12-31  2100     8             8         113      0.0       66   \n",
       "0   2022-12-31  2200     8             8         113      0.0       54   \n",
       "0   2022-12-31  2300     8             8         113      0.0       42   \n",
       "\n",
       "   pressure cloudcover WindChillC WindGustKmph FeelsLikeC uvIndex  \n",
       "0      1032          0          6           19          6       1  \n",
       "0      1032          0          5           21          5       1  \n",
       "0      1032          0          4           21          4       1  \n",
       "0      1032          0          4           21          4       1  \n",
       "0      1032          0          3           21          3       1  \n",
       "..      ...        ...        ...          ...        ...     ...  \n",
       "0      1026          3          7           26          7       1  \n",
       "0      1026          2          8           25          8       1  \n",
       "0      1027          0          7           26          7       1  \n",
       "0      1027          2          7           30          7       1  \n",
       "0      1027          4          6           33          6       1  \n",
       "\n",
       "[8760 rows x 13 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine the datasets in one csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Read weather data\n",
    "weather_data = {}\n",
    "\n",
    "with open(\"data/weather_hourly.csv\", \"r\") as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    for row in reader:\n",
    "        date = row[\"date\"]\n",
    "        time = row[\"time\"]\n",
    "        hour = int(time) // 100\n",
    "        dt = datetime.datetime.strptime(date, \"%Y-%m-%d\").replace(hour=hour)\n",
    "        weather_data[dt] = row\n",
    "\"\"\"\n",
    "# Read and encode occupation data\n",
    "occupation_df = pd.read_csv(\"data/ocupacio_enginyeria_2022.csv\")\n",
    "columns_to_encode = ['Espai', 'Estudi', 'Activitat', 'Modalitat docencia']\n",
    "\n",
    "#for col in columns_to_encode:\n",
    "#    label_encoder = LabelEncoder()\n",
    "#    occupation_df[col] = label_encoder.fit_transform(occupation_df[col].astype(str))\n",
    "\n",
    "occupation_data = {}\n",
    "\n",
    "for _, row in occupation_df.iterrows():\n",
    "    if not row[\"Data inicial\"].strip():  # Check if the date string is empty\n",
    "        continue\n",
    "    start_date = datetime.datetime.strptime(row[\"Data inicial\"], \"%d/%m/%Y\")\n",
    "    start_hour = int(row[\"Hora inicial\"].split(\":\")[0])\n",
    "    start_dt = start_date.replace(hour=start_hour)\n",
    "    occupation_data[start_dt] = row.to_dict()\n",
    "\n",
    "\"\"\"\n",
    "# Read target data\n",
    "target_data = {}\n",
    "\n",
    "with open(\"data/Consum horari electricitat Enginyeries 2022.csv\", \"r\") as f:\n",
    "    reader = csv.DictReader(f, delimiter=\";\")\n",
    "    for row in reader:\n",
    "        date = datetime.datetime.strptime(row[\"Date\"], \"%d/%m/%Y\")\n",
    "        hour = int(row[\"Hour\"].split(\":\")[0])\n",
    "        dt = date.replace(hour=hour)\n",
    "        target_data[dt] = row\n",
    "\n",
    "# Merge the data\n",
    "merged_data = []\n",
    "for dt in sorted(weather_data.keys()):\n",
    "    merged_row = weather_data[dt]\n",
    "    \"\"\"\n",
    "    if dt in occupation_data:\n",
    "        merged_row.update(occupation_data[dt])\n",
    "    \"\"\"\n",
    "    if dt in target_data:\n",
    "        merged_row.update(target_data[dt])\n",
    "\n",
    "    merged_data.append(merged_row)\n",
    "\n",
    "# Save the merged data to a CSV file\n",
    "with open(\"data/merged_data.csv\", \"w\", newline=\"\") as f:\n",
    "    fieldnames = set()\n",
    "    for row in merged_data:\n",
    "        fieldnames.update(row.keys())\n",
    "    fieldnames = list(fieldnames)\n",
    "\n",
    "    writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    for row in merged_data:\n",
    "        writer.writerow(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.read_csv(\"data/merged_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "merged_df = pd.read_csv(\"data/merged_data.csv\")\n",
    "\n",
    "#columns_to_drop = ['Unnamed: 0', 'Data inicial', 'Data final', 'Hora inicial', 'Hora final', 'time', 'weatherIconUrl', 'winddir16Point', 'Date', 'Hour', 'Observacions', 'tempF', 'WindChillF', 'HeatIndexF', 'FeelsLikeF', 'DewPointF', 'WindGustMiles', 'visibilityMiles', 'pressureInches', 'precipInches']\n",
    "columns_to_drop = ['Unnamed: 0', 'weatherIconUrl', 'winddir16Point', 'Date', 'Hour', 'tempF', 'WindChillF', 'weatherDesc','HeatIndexF', 'FeelsLikeF', 'DewPointF', 'WindGustMiles', 'visibilityMiles', 'pressureInches', 'precipInches']\n",
    "merged_df = merged_df.drop(columns=columns_to_drop)\n",
    "merged_df[\"time\"] = merged_df[\"time\"]/100\n",
    "# Save the updated DataFrame to a new CSV file\n",
    "coloms_with_coma_decimal = [\"Q-Enginyeria (Cos Central) [kWh] [Q-Enginyeria]\",\"Q-Enginyeria (Espina 4) [kWh] [Q-Enginyeria]\",\"Q-Enginyeria (Química) [kWh] [Q-Enginyeria]\"]\n",
    "for col in coloms_with_coma_decimal:\n",
    "    changed = []\n",
    "    for i,val in enumerate(merged_df[col]):\n",
    "        if val == val:\n",
    "            changed.append(val.replace(\",\",\".\"))\n",
    "        else: #we got a nan. interpolate by having previous value\n",
    "            changed.append(changed[-1])\n",
    "    \n",
    "    merged_df[col] = changed\n",
    "\n",
    "merged_df.to_csv(\"data/updated_merged_data.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.read_csv(\"data/updated_merged_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['winddirDegree', 'WindGustKmph', 'visibility', 'DewPointC',\n",
       "       'Q-Enginyeria (Espina 4) [kWh] [Q-Enginyeria]',\n",
       "       'Q-Enginyeria (Química) [kWh] [Q-Enginyeria]', 'uvIndex', 'HeatIndexC',\n",
       "       'Q-Enginyeria (Cos Central) [kWh] [Q-Enginyeria]', 'precipMM',\n",
       "       'windspeedMiles', 'weatherCode', 'tempC', 'cloudcover', 'windspeedKmph',\n",
       "       'date', 'time', 'pressure', 'FeelsLikeC', 'WindChillC', 'humidity'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: In the future we could play with [observations, Estudi,Modalitat docencia] columns and NLP to get some representation of the activity being done and its impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "occupation_data = pd.read_csv(\"data/ocupacio_enginyeria_2022.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating and embedding for the title of activities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem we have is that we have too many activities to create a one hot vector of each of them.\n",
    "Second problem we have is that if we wanted to add a new activity this would break the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data inicial</th>\n",
       "      <th>Hora inicial</th>\n",
       "      <th>Data final</th>\n",
       "      <th>Hora final</th>\n",
       "      <th>Total hores</th>\n",
       "      <th>Espai</th>\n",
       "      <th>Estudi</th>\n",
       "      <th>Activitat</th>\n",
       "      <th>Alumnes matriculats</th>\n",
       "      <th>Modalitat docencia</th>\n",
       "      <th>Observacions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>04/01/2022</td>\n",
       "      <td>15:00</td>\n",
       "      <td>04/01/2022</td>\n",
       "      <td>18:00</td>\n",
       "      <td>3</td>\n",
       "      <td>Q1/0007</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Classe presencial MUEBA - M. Eugenia Suarez</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>07/01/2022</td>\n",
       "      <td>09:00</td>\n",
       "      <td>07/01/2022</td>\n",
       "      <td>11:30</td>\n",
       "      <td>2.5</td>\n",
       "      <td>Q3/1007</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Examen 102712 SSD (GEST) 2 aules</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>07/01/2022</td>\n",
       "      <td>09:00</td>\n",
       "      <td>07/01/2022</td>\n",
       "      <td>11:30</td>\n",
       "      <td>2.5</td>\n",
       "      <td>Q1/1003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Examen 104525 Intro.ciutat conemporània (GCIS)...</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>07/01/2022</td>\n",
       "      <td>09:00</td>\n",
       "      <td>07/01/2022</td>\n",
       "      <td>11:30</td>\n",
       "      <td>2.5</td>\n",
       "      <td>Q3/1011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Examen 102712 SSD (GEST) 2 aules</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>07/01/2022</td>\n",
       "      <td>09:00</td>\n",
       "      <td>07/01/2022</td>\n",
       "      <td>11:30</td>\n",
       "      <td>2.5</td>\n",
       "      <td>Q2/1013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Examen 106040 Matemàtiques (GEQ) 2 aules</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42006</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Q3/0003</td>\n",
       "      <td>10064 Enginyeria de Sistemes de Telecomunicació</td>\n",
       "      <td>102712 Senyals i Sistemes Discrets - 331</td>\n",
       "      <td>Sense grup de matricula</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42007</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Q3/0003</td>\n",
       "      <td>6084 Enginyeria de Telecomunicació / Telecommu...</td>\n",
       "      <td>102712 Senyals i Sistemes Discrets - 331</td>\n",
       "      <td>Sense grup de matricula</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42008</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Q3/0003</td>\n",
       "      <td>10063 Enginyeria Electrònica de Telecomunicació</td>\n",
       "      <td>102712 Senyals i Sistemes Discrets - 331</td>\n",
       "      <td>Sense grup de matricula</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42009</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Q3/0003</td>\n",
       "      <td>10088 Enginyeria Informàtica i Enginyeria de S...</td>\n",
       "      <td>102712 Senyals i Sistemes Discrets - 331</td>\n",
       "      <td>Sense grup de matricula</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42010</th>\n",
       "      <td>23/12/2022</td>\n",
       "      <td>15:00</td>\n",
       "      <td>23/12/2022</td>\n",
       "      <td>18:00</td>\n",
       "      <td>3</td>\n",
       "      <td>Q4/0003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1170- Docència Màster Eng. Telecomunicació (PLAB)</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42011 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Data inicial Hora inicial  Data final Hora final Total hores    Espai  \\\n",
       "0       04/01/2022        15:00  04/01/2022      18:00           3  Q1/0007   \n",
       "1       07/01/2022        09:00  07/01/2022      11:30         2.5  Q3/1007   \n",
       "2       07/01/2022        09:00  07/01/2022      11:30         2.5  Q1/1003   \n",
       "3       07/01/2022        09:00  07/01/2022      11:30         2.5  Q3/1011   \n",
       "4       07/01/2022        09:00  07/01/2022      11:30         2.5  Q2/1013   \n",
       "...            ...          ...         ...        ...         ...      ...   \n",
       "42006                                                               Q3/0003   \n",
       "42007                                                               Q3/0003   \n",
       "42008                                                               Q3/0003   \n",
       "42009                                                               Q3/0003   \n",
       "42010   23/12/2022        15:00  23/12/2022      18:00           3  Q4/0003   \n",
       "\n",
       "                                                  Estudi  \\\n",
       "0                                                    NaN   \n",
       "1                                                    NaN   \n",
       "2                                                    NaN   \n",
       "3                                                    NaN   \n",
       "4                                                    NaN   \n",
       "...                                                  ...   \n",
       "42006    10064 Enginyeria de Sistemes de Telecomunicació   \n",
       "42007  6084 Enginyeria de Telecomunicació / Telecommu...   \n",
       "42008    10063 Enginyeria Electrònica de Telecomunicació   \n",
       "42009  10088 Enginyeria Informàtica i Enginyeria de S...   \n",
       "42010                                                NaN   \n",
       "\n",
       "                                               Activitat  \\\n",
       "0            Classe presencial MUEBA - M. Eugenia Suarez   \n",
       "1                       Examen 102712 SSD (GEST) 2 aules   \n",
       "2      Examen 104525 Intro.ciutat conemporània (GCIS)...   \n",
       "3                       Examen 102712 SSD (GEST) 2 aules   \n",
       "4               Examen 106040 Matemàtiques (GEQ) 2 aules   \n",
       "...                                                  ...   \n",
       "42006           102712 Senyals i Sistemes Discrets - 331   \n",
       "42007           102712 Senyals i Sistemes Discrets - 331   \n",
       "42008           102712 Senyals i Sistemes Discrets - 331   \n",
       "42009           102712 Senyals i Sistemes Discrets - 331   \n",
       "42010  1170- Docència Màster Eng. Telecomunicació (PLAB)   \n",
       "\n",
       "           Alumnes matriculats Modalitat docencia Observacions  \n",
       "0                            0                                  \n",
       "1                            0                                  \n",
       "2                            0                                  \n",
       "3                            0                                  \n",
       "4                            0                                  \n",
       "...                        ...                ...          ...  \n",
       "42006  Sense grup de matricula                                  \n",
       "42007  Sense grup de matricula                                  \n",
       "42008  Sense grup de matricula                                  \n",
       "42009  Sense grup de matricula                                  \n",
       "42010                        0                                  \n",
       "\n",
       "[42011 rows x 11 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#All activities we have.\n",
    "occupation_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the future it would be cool to create our own model that creates some embedding optimized for owr problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now we'll use some pretrained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/josepsmachine/miniforge3/envs/ML/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_token = \"[CLS] \"\n",
    "end_token = \" [SEP]\"\n",
    "test_txt = start_token + \"This class is chaotic and boring at the same time. \" + end_token\n",
    "tokenized_text = tokenizer.tokenize(test_txt)\n",
    "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "segments_ids = [1] * len(tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load pre-trained model (weights)\n",
    "model = BertModel.from_pretrained('bert-base-multilingual-cased',\n",
    "                                  output_hidden_states = True, # Whether the model returns all hidden-states.\n",
    "                                  )\n",
    "\n",
    "# Put the model in \"evaluation\" mode, meaning feed-forward operation.\n",
    "model.eval()\n",
    "model.to(\"mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert inputs to PyTorch tensors\n",
    "tokens_tensor = torch.tensor([indexed_tokens]).to(\"mps\")\n",
    "segments_tensors = torch.tensor([segments_ids]).to(\"mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the text through BERT, and collect all of the hidden states produced\n",
    "# from all 12 layers. \n",
    "with torch.no_grad():\n",
    "\n",
    "    outputs = model(tokens_tensor, segments_tensors)\n",
    "\n",
    "    # Evaluating the model will return a different number of objects based on \n",
    "    # how it's  configured in the `from_pretrained` call earlier. In this case, \n",
    "    # becase we set `output_hidden_states = True`, the third item will be the \n",
    "    # hidden states from all layers. See the documentation for more details:\n",
    "    # https://huggingface.co/transformers/model_doc/bert.html#bertmodel\n",
    "    hidden_states = outputs[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([768])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# `token_vecs` is a tensor with sha pe [Ntokens x 768]\n",
    "token_vecs = hidden_states[-2][0] #second to last hiden layer\n",
    "\n",
    "# Calculate the average of all Ntokens token vectors.\n",
    "sentence_embedding = torch.mean(token_vecs, dim=0)\n",
    "sentence_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence2hidden_states(txt):\n",
    "    test_txt = start_token + txt + end_token\n",
    "    tokenized_text = tokenizer.tokenize(test_txt)\n",
    "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text) \n",
    "    segments_ids = [1] * len(tokenized_text)\n",
    "\n",
    "    # Convert inputs to PyTorch tensors\n",
    "    tokens_tensor = torch.tensor([indexed_tokens]).to(\"mps\")\n",
    "    segments_tensors = torch.tensor([segments_ids]).to(\"mps\")\n",
    "    with torch.no_grad():\n",
    "        outputs = model(tokens_tensor, segments_tensors)\n",
    "    \n",
    "    hidden_states = outputs[2]\n",
    "    return hidden_states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have an embedding for each sentence of size (768)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll try to apply kmeans to kluster all titles by their semantic meaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42011/42011 [00:41<00:00, 1023.64it/s]\n"
     ]
    }
   ],
   "source": [
    "vectors = {}\n",
    "h_states = {}\n",
    "occupations = set()\n",
    "for occu in tqdm(occupation_data[\"Activitat\"]):\n",
    "    if occu not in occupations:\n",
    "        h = sentence2hidden_states(occu)[-2][0].to(\"cpu\") #get all layers first batch\n",
    "        h_states[occu] =h\n",
    "\n",
    "        # Calculate the average of all Ntokens token vectors.\n",
    "        sentence_embedding = torch.mean(h, dim=0)\n",
    "        vectors[occu] = sentence_embedding.numpy()\n",
    "        occupations.add(occu) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll do the same but encode the classroom the activity is in the text also"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors_plus = {}\n",
    "h_states_plus = {}\n",
    "occupations_plus = set()\n",
    "for occu, espai in zip(occupation_data[\"Activitat\"],occupation_data[\"Espai\"]):\n",
    "    if occu + \" \" + espai not in occupations_plus:\n",
    "        h = sentence2hidden_states(occu + \" \" + espai)[-2][0].to(\"cpu\") #get all layers first batch\n",
    "        h_states_plus[occu + \" \" + espai] = h\n",
    "        \n",
    "        # Calculate the average of all Ntokens token vectors.\n",
    "        sentence_embedding = torch.mean(h, dim=0)\n",
    "        vectors_plus[occu + \" \" + espai] = sentence_embedding.numpy()\n",
    "        occupations_plus.add(occu + \" \" + espai) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save data to pickle file for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "#bert_data = {\n",
    "#    \"single_ocu\":{\"mean_vect\":vectors,\"h_states\":h_states},\n",
    "#    \"ocu_plus_space\":{\"mean_vect\":vectors_plus,\"h_states\":h_states_plus}\n",
    "#    }\n",
    "\n",
    "bert_data = {\n",
    "    \"single_ocu\":{\"mean_vect\":vectors},\n",
    "    \"ocu_plus_space\":{\"mean_vect\":vectors_plus}\n",
    "    }\n",
    "\n",
    "# Open a file and use dump()\n",
    "with open('data/bert_embedded.pkl', 'wb') as file:\n",
    "      \n",
    "    pickle.dump(bert_data, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll do some fast clustering to see if it makes any sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(n_clusters=4, random_state=0, n_init=\"auto\").fit(list(vectors_plus.values()))\n",
    "cluster_cent = kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_map = pd.DataFrame()\n",
    "cluster_map['data_index'] = list(vectors_plus.keys())\n",
    "cluster_map['cluster'] = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "data_index                                                           cluster\n",
       "  958-03 102775-AC 1/4 Q3/1003                                       0          1\n",
       "951-03 106045 Química inorg i de l'equilib (9:00-13:00) 1/2 Q4/0007  0          1\n",
       "951-03 106054 Bases experim. Enginyeia química 1/2 Q4/0007           0          1\n",
       "951-03 Cinètica química Q1/1007                                      0          1\n",
       "951-03 Cinètica química Q1/1011                                      0          1\n",
       "                                                                               ..\n",
       "106043 Física - 21 Q4/0011                                           0          1\n",
       "106043 Física - 21 Q4/1005                                           0          1\n",
       "106043 Física - 211 Q4/0007                                          0          1\n",
       "106043 Física - 211 Q4/0011                                          0          1\n",
       "Eamen 104341 Enginyeria del rendiment (GED) Q1/1011                  0          1\n",
       "Length: 914, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_map[cluster_map[\"cluster\"]==0].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "data_index                                                                cluster\n",
       "102401 Ampliació d'Operacions de Separació - 220 Q4/1009                  1          1\n",
       "104356 Programació Parallela - 811 Q1/0007                               1          1\n",
       "104358 Desenvolupament Daplicacions de Dades Massives - 81 Q1/0019       1          1\n",
       "104357 Computació en Entorns Al Núvol - 812 Q2/0017                       1          1\n",
       "104357 Computació en Entorns Al Núvol - 811 Q1/0019                       1          1\n",
       "                                                                                    ..\n",
       "102764 Metodologia de la Programació - 472 Q2/1005                        1          1\n",
       "102764 Metodologia de la Programació - 472 Q1/0019                        1          1\n",
       "102764 Metodologia de la Programació - 471 Q2/1009                        1          1\n",
       "102764 Metodologia de la Programació - 471 Q1/0019                        1          1\n",
       "classe del Màster de Modelització per a la Ciència i lEnginyeri Q2/1005  1          1\n",
       "Length: 1219, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_map[cluster_map[\"cluster\"]==1].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "data_index                                                               cluster\n",
       "0004-01 Reunió d'equip MELISSA - Daniella Emiliani QC/0019               2          1\n",
       "951-09 Docència seminaris Circulació de Fluids (GEQ) Q4/0011             2          1\n",
       "951-09 Química inorgànica (recuperació classe) Q4/0007                   2          1\n",
       "951-09 Química inorgànica industrial Q4/0007                             2          1\n",
       "951-09 Recuperació Ciències dels materials GEQ - Fernando Novio Q3/0003  2          1\n",
       "                                                                                   ..\n",
       "2634-06 Prova Tesis Doctoral QC/0019                                     2          1\n",
       "2634-07 Seminari de recerca DEQBA Q1/0003                                2          1\n",
       "2634-08 Trucada amb una altra universitat. Laia Miranda QC/0019          2          1\n",
       "2634-11 Catèring Teresa Gea QC/0015                                      2          1\n",
       "assaig tesis Q1/0003                                                     2          1\n",
       "Length: 789, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_map[cluster_map[\"cluster\"]==2].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "data_index                                            cluster\n",
       "115_19 JPO - GED Q4/0007                              3          1\n",
       "Examen 104341 Enginyeria del rendiment (GED) Q1/1007  3          1\n",
       "Examen 103805 FE (GEI) 2 aules Q1/1011                3          1\n",
       "Examen 103805 FE (GEI) 2 aules Q1/1007                3          1\n",
       "Examen 103803 Estadistica (GEI) 3 aules Q3/1011       3          1\n",
       "                                                                ..\n",
       "Examen 102741 GABD (GEI) 2 aules Q4/1013              3          1\n",
       "Examen 102741 GABD (GEI) 2 aules Q4/1009              3          1\n",
       "Examen 102741 GABD (GEI)  Q3/1011                     3          1\n",
       "Examen 102740 SD (GEI) Q1/1011                        3          1\n",
       "examen de practiques Q2/0007                          3          1\n",
       "Length: 323, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_map[cluster_map[\"cluster\"]==3].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll not sure if it makes any sense XD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll add to the dataset a column for the hiddent states of bert. We'll pass a text through bert if the input class doesn't exist."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import preprocessing \n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class energyProject_dataset(Dataset):\n",
    "    def __init__(self,dataset_pth,occupacio_pth,bert_embeddings_pkl_pth,pca_pkl_pth=None):\n",
    "        self.df = pd.read_csv(dataset_pth)\n",
    "        with (open(bert_embeddings_pkl_pth, \"rb\")) as openfile:\n",
    "            self.bert_embeddings = pickle.load(openfile)\n",
    "        self.activitivity_encoding_mode = 0\n",
    "        \n",
    "        #order of values in target tensor will follow this\n",
    "        self.target_labels = [\"Q-Enginyeria (Cos Central) [kWh] [Q-Enginyeria]\",\"Q-Enginyeria (Espina 4) [kWh] [Q-Enginyeria]\",\"Q-Enginyeria (Química) [kWh] [Q-Enginyeria]\"]\n",
    "       \n",
    "        #load occupation data\n",
    "        self.occupation_df = pd.read_csv(occupacio_pth)\n",
    "        #we'll remove entries without date\n",
    "        self.occupation_df = self.occupation_df[self.occupation_df[\"Data inicial\"] != \" \"]\n",
    "\n",
    "        #convert date string to be in the form y-m-d instead of d/m/y\n",
    "        #convert hour data to datetime object so we can compare them\n",
    "        for i, row in self.occupation_df.iterrows(): \n",
    "            self.occupation_df.loc[i][\"Data inicial\"] =  datetime.datetime.strptime(self.occupation_df.loc[i][\"Data inicial\"], \"%d/%m/%Y\").strftime(\"%Y-%m-%d\")\n",
    "            self.occupation_df.loc[i][\"Hora inicial\"] = datetime.datetime.strptime(self.occupation_df.loc[i][\"Hora inicial\"] ,\"%H:%M\").time()\n",
    "            self.occupation_df.loc[i][\"Hora final\"] = datetime.datetime.strptime(self.occupation_df.loc[i][\"Hora final\"] ,\"%H:%M\").time()\n",
    "        \n",
    "        self.ocup_vocab = list(set(self.occupation_df[\"Activitat\"]))\n",
    "        self.espais_vocab = list(set(self.occupation_df[\"Espai\"]))\n",
    "        #Add a padding occupation\n",
    "        self.espais_vocab.append(\"NO ESPAI\")\n",
    "\n",
    "        #Normalize all climate data to be between 0-1\n",
    "        #we'll keep their scaler objects so we can transform their values back to original\n",
    "        #and not loose meaning.\n",
    "        self.column_scalers = {}\n",
    "        columns_to_process = ['winddirDegree', 'precipMM', 'visibility', 'WindChillC',\n",
    "       'humidity', 'pressure','windspeedMiles', 'uvIndex', 'DewPointC',\n",
    "       'FeelsLikeC', 'tempC','weatherCode','HeatIndexC', 'WindGustKmph', 'cloudcover',\n",
    "       'windspeedKmph']\n",
    "     \n",
    "        for col in columns_to_process:\n",
    "            scaler, values = self.normalize_values(self.df[col])\n",
    "            self.df[col] = values\n",
    "            self.column_scalers[col] = scaler\n",
    "        \n",
    "        #If we want this dataset to work with batches in modes different than 0 and 1.\n",
    "        #We need to know what is the maximum number of activities at the same time so we can\n",
    "        #padd the samples smaller. We need the batch to have the same shape samples every time.\n",
    "\n",
    "        #we'll use that we are iterating throught this to compute all the one_hot vectors of the encodings\n",
    "        #and fit a PCA object so we can have it with dimensionality reduction.\n",
    "\n",
    "        self.max_ocu_lenght = 0\n",
    "        self.all_one_hots = []\n",
    "        for i, row in self.df.iterrows():\n",
    "            day2day_ocu = self.activty_class_perT(row[\"date\"],row[\"time\"])\n",
    "            \n",
    "            #find largest occupation size per hour\n",
    "            day2day_ocu_l = len(day2day_ocu)\n",
    "            if day2day_ocu_l > self.max_ocu_lenght:\n",
    "                self.max_ocu_lenght = day2day_ocu_l\n",
    "                \n",
    "            if pca_pkl_pth == True: #if we have to calculate the PCA\n",
    "                #compute one_hot vectors of occupation at this time\n",
    "                self.all_one_hots.append(self.activity_class_one_hot(day2day_ocu))\n",
    "        \n",
    "        if (pca_pkl_pth == True): #nan value, recalculate and save file\n",
    "            self.all_one_hots = np.array(self.all_one_hots)\n",
    "            #compute PCA on all the one_hot vectors\n",
    "            self.ocu_one_hot_pca = PCA(n_components=1000) #1000 size output vector (number chosen by hand)\n",
    "            self.ocu_one_hot_pca.fit(self.all_one_hots)\n",
    "            # Open a file and use dump()\n",
    "            with open('data/pca_occupation.pkl', 'wb') as file:\n",
    "                pickle.dump(self.ocu_one_hot_pca, file)\n",
    "        else:\n",
    "            with (open(pca_pkl_pth, \"rb\")) as openfile:\n",
    "                self.ocu_one_hot_pca = pickle.load(openfile)\n",
    "        \n",
    "        ##free memory by removing unnecessary variables.\n",
    "        del self.all_one_hots\n",
    "        \n",
    "            \n",
    "\n",
    "    def normalize_values(self,x):\n",
    "        \"\"\"\n",
    "        Input a list of values\n",
    "        Output a sklearn scaler object and the list normalized.\n",
    "        We need to keep the scaler to be able to re-scale the data back and now what value it is in reality.\n",
    "        \"\"\"\n",
    "        to_scale = np.array(x).reshape(-1, 1) #the library needs this extra dimensions trick to interpret properly\n",
    "        min_max_scaler = preprocessing.MinMaxScaler(feature_range=(0, 1))\n",
    "        x_scaled = min_max_scaler.fit_transform(to_scale)\n",
    "        return min_max_scaler, x_scaled\n",
    "    \n",
    "    def denormalize_values(self,x_n,scaler):\n",
    "        \"\"\"\n",
    "        Given some set of values and a sklearn scaler object\n",
    "        Transform back the values to their original \"space\"ArithmeticError\n",
    "        return: set of values same shape as input\n",
    "        \"\"\"\n",
    "        to_scale = np.array(x_n).reshape(-1, 1)\n",
    "        return scaler.inverse_transform(to_scale)\n",
    "\n",
    "    def datetime_enc(self,date, time)->torch.tensor:\n",
    "        \"\"\"\n",
    "        Encodes incoming date and time strings as two values for each that \n",
    "        come from infering the index value on a sin function and cos function.\n",
    "        Its nice beacause we encode the smoothness and circularity of the trigonometric\n",
    "        functions.\n",
    "\n",
    "        input <- (date: str, time:str)\n",
    "        output -> (torch.tensor((1,5)))\n",
    "        \"\"\"\n",
    "        \n",
    "        date_obj =  datetime.datetime.strptime(date, \"%Y-%m-%d\")\n",
    "        \n",
    "        #encode year as floas\n",
    "        year_enc = float(date_obj.year)/1000 # divide by 100 to have reasonable value\n",
    "        \n",
    "        ##\n",
    "        ##Encoding: (sin, cos) value for each day month\n",
    "        ##\n",
    "        idx_d = date_obj.timetuple().tm_yday #day of the year number\n",
    "        date_enc= [np.sin((idx_d/365) * 2*np.pi),np.cos((idx_d/365) * 2*np.pi)]  #365 days a yar +1 offset so we don't have negative value\n",
    "        \n",
    "        #encode time by hour in the day\n",
    "        time_enc = [np.sin((time/24) * 2*np.pi),np.cos((time/24) * 2*np.pi)]  #24 hours a day. +1 offset so we don't have negative values\n",
    "        \n",
    "        return torch.tensor([year_enc]+date_enc+time_enc) \n",
    "\n",
    "    def datetime_dec(self,enc_tens):\n",
    "        \"\"\"\n",
    "        Decodes incoming encoded date and time tensor as the two respective\n",
    "        date time string values\n",
    "\n",
    "        input <- (torch.tensor([torch.float,torch.float]))\n",
    "        output -> date: str, time:str\n",
    "        \"\"\"\n",
    "        #decode year\n",
    "        year = int(enc_tens[0].item() * 1000)\n",
    "\n",
    "        #decode date\n",
    "        penc_date = np.arctan2(enc_tens[1].item(),enc_tens[2].item()) / (2*np.pi) * 365\n",
    "        date = datetime.datetime(year, 1, 1) + datetime.timedelta(penc_date - 1)\n",
    "        date = date.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "        #decode time\n",
    "        time = np.round((np.arctan2(enc_tens[3].item(),enc_tens[4].item()) / (2*np.pi) * 24)% 24)\n",
    "        \n",
    "        return date,time\n",
    "\n",
    "    def activty_class_perT(self,date,time)->pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Returns slice of the pd Dataframe of activities active given some date and time\n",
    "        \"\"\"\n",
    "        #filter dataset to see activities that day\n",
    "        day2day_ocu = self.occupation_df[self.occupation_df[\"Data inicial\"] == date ] \n",
    "        h = datetime.time(int(time))\n",
    "        hour2hour_ocu = day2day_ocu[(day2day_ocu[\"Hora inicial\"] <= h) & (day2day_ocu[\"Hora final\"] > h)]\n",
    "        return pd.DataFrame(hour2hour_ocu)\n",
    "\n",
    "    def activity_class_one_hot(self,activities)->np.array:\n",
    "        \"\"\" \n",
    "        returns flattenned coocurrence one-hot matrix of activities and classrooms\n",
    "        \"\"\"\n",
    "        occurrence_matrix = np.zeros((len(self.ocup_vocab),len(self.espais_vocab)))\n",
    "        for i,actv in activities.iterrows(): #iterate found activities\n",
    "            ocup_idx = self.ocup_vocab.index(actv[\"Activitat\"])\n",
    "            espais_idx = self.espais_vocab.index(actv[\"Espai\"])\n",
    "            occurrence_matrix[ocup_idx,espais_idx] = 1\n",
    "            \n",
    "        #now flatten the occurrence matrix into a one hot vector\n",
    "        one_hot = occurrence_matrix.flatten()\n",
    "        return one_hot\n",
    "    \n",
    "    def class_one_hot(self,activitats)->torch.tensor:\n",
    "        \"\"\"\n",
    "        Returns \"one hot\" encoding of activitat.\n",
    "        In reality will not be a true one hot but a list of indexes\n",
    "        that can later on be passed to some embedding layer\n",
    "        \"\"\"\n",
    "        activitats[\"Espai\"]\n",
    "        one_hot_esp = [self.espais_vocab.index(key) for key in activitats[\"Espai\"]]\n",
    "        return torch.tensor(one_hot_esp)\n",
    "       \n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df) \n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        This function will return more than one object depending on the mode it is on.\n",
    "        Activity encoding mode:\n",
    "            0: I.very large one-hot encoding of all the combinations of classroom and activity concatenated\n",
    "                with all other features.\n",
    "               II. target values\n",
    "            \n",
    "            1:  I. 0 but first with some PCA applied to reduce dimensionality of \n",
    "                the enormous one-hot encoding.\n",
    "                II. target values\n",
    "            \n",
    "            2: returns four objects, \n",
    "                I.mean_encoding of activity from bert(as many as activities at time stamp), \n",
    "                II. classroom one hot encoding for each activity(as many as activities at time stamp)\n",
    "                III. All other features at that time stamp\n",
    "                IV. target values\n",
    "            \n",
    "            2.5:  returns four objects\n",
    "                I. embedding tensor of activity from bert(as many as activities at time stamp), \n",
    "                II. classroom one hot encoding for each activity(as many as activities at time stamp)\n",
    "                III. All other features at that time stamp\n",
    "                IV. target values\n",
    "            \n",
    "            3: returns three objects,\n",
    "                I. mean encoding of activity, classroom pair through bert (as many as activities at time stamp),\n",
    "                II. All other features at that time stamp\n",
    "                III. target values\n",
    "            \n",
    "            3.5:  returns four objects\n",
    "                I. embedding tensor of activity, classroom pair through bert(as many as activities at time stamp), \n",
    "                II. classroom one hot encoding for each activity(as many as activities at time stamp)\n",
    "                III. All other features at that time stamp\n",
    "                IV. target values\n",
    "            \n",
    "            4: returns three objects, raw data thought for model handling.\n",
    "                I. activities in text form paired with their classroom\n",
    "                II. All other features at that time stamp\n",
    "                III. target values\n",
    "        \"\"\"\n",
    "\n",
    "        #get row in df for data to be evaluated:\n",
    "        row = self.df.iloc[index]\n",
    "\n",
    "        #First getting the \"all other data \" features tensor\n",
    "        #Date-time encoding tensor\n",
    "        enc_dt_tens = self.datetime_enc(row[\"date\"],row[\"time\"]) #date-time encoding\n",
    "\n",
    "        #weather data tensor\n",
    "        weather_tens = torch.tensor(row.drop([\"date\",\"time\",\"Q-Enginyeria (Cos Central) [kWh] [Q-Enginyeria]\",\"Q-Enginyeria (Espina 4) [kWh] [Q-Enginyeria]\",\"Q-Enginyeria (Química) [kWh] [Q-Enginyeria]\"]))\n",
    "\n",
    "        #second get the target values tensor\n",
    "        target_tens = torch.tensor(row[self.target_labels])\n",
    "        \n",
    "        #Get activities at given time and date\n",
    "        activities = self.activty_class_perT(row[\"date\"],row[\"time\"])\n",
    "        if self.activitivity_encoding_mode <= 1:\n",
    "            one_hot = self.activity_class_one_hot(activities)\n",
    "            \n",
    "            if(self.activitivity_encoding_mode == 0):\n",
    "                one_hot = torch.tensor(one_hot)\n",
    "                #return values\n",
    "                sample = {'x': torch.cat((enc_dt_tens,weather_tens,one_hot),axis=0), 'y': target_tens}\n",
    "                return sample\n",
    "            \n",
    "            if(self.activitivity_encoding_mode == 1):\n",
    "                one_hot = one_hot.reshape(1, -1) #create extra dimension because this counts as only one sample\n",
    "                smaller_x = torch.tensor(self.ocu_one_hot_pca.transform(one_hot))[0] #get rid of extra dim\n",
    "                sample = {'x': torch.cat((enc_dt_tens,weather_tens,smaller_x),axis=0), 'y': target_tens}\n",
    "                return sample\n",
    "        \n",
    "        if self.activitivity_encoding_mode == 2:\n",
    "            #get bert embeddings\n",
    "            emb_activ = []\n",
    "            for i,actv in activities.iterrows(): #iterate found activities   \n",
    "                emb_activ.append(self.bert_embeddings[\"ocu_plus_space\"][\"mean_vect\"][actv[\"Activitat\"] + \" \" + actv[\"Espai\"]])\n",
    "            emb_activ = torch.tensor(np.array(emb_activ))\n",
    "\n",
    "            #get espai one-hot\n",
    "            espai_one_hot = self.class_one_hot(activities)\n",
    "\n",
    "            #padd with occupation 0 vector so all samples are same shape and espai with \"\"NO ESPAI\"\n",
    "            if emb_activ.shape[0] < self.max_ocu_lenght: \n",
    "                emb_activ = torch.cat((emb_activ,torch.zeros((self.max_ocu_lenght-emb_activ.shape[0],768))),axis=0)\n",
    "                espai_padd = pd.DataFrame(columns=[\"Espai\"]) \n",
    "                espai_padd[\"Espai\"] = [\"NO ESPAI\"]* (self.max_ocu_lenght-len(espai_one_hot))\n",
    "                padd_one_hot = self.class_one_hot(espai_padd)\n",
    "                espai_one_hot = torch.cat((espai_one_hot,padd_one_hot))\n",
    "                \n",
    "            sample = {'ocu_ber_emb': emb_activ,'espai_enc':espai_one_hot, \"general_data\":torch.cat((enc_dt_tens,weather_tens),axis=0), 'y': target_tens}\n",
    "            return sample\n",
    "        \n",
    "        if self.activitivity_encoding_mode == 2.5:\n",
    "            assert \"NOT IMPLEMENTED YET\"\n",
    "            pass\n",
    "            \n",
    "        if self.activitivity_encoding_mode == 3:\n",
    "            emb_activ = []\n",
    "            for i,actv in activities.iterrows(): #iterate found activities   \n",
    "                emb_activ.append(self.bert_embeddings[\"ocu_plus_space\"][\"mean_vect\"][actv[\"Activitat\"] + \" \" + actv[\"Espai\"]])\n",
    "            emb_activ = torch.tensor(np.array(emb_activ))\n",
    "\n",
    "            if emb_activ.shape[0] < self.max_ocu_lenght: #padd with occupation 0 vector so all samples are same shape\n",
    "                emb_activ = torch.cat((emb_activ,torch.zeros((self.max_ocu_lenght-emb_activ.shape[0],768))),axis=0)\n",
    "            \n",
    "            #return values\n",
    "            sample = {'activ': torch.tensor(emb_acti), 'general_data':torch.cat((enc_dt_tens,weather_tens),axis=0), 'y': target_tens}\n",
    "            return sample\n",
    "        \n",
    "        if self.activitivity_encoding_mode == 3.5:\n",
    "            assert \"NOT IMPLEMENTED YET\"\n",
    "            #errors to solve have to recalculate bert passing\n",
    "            emb_acti = []\n",
    "            for i,actv in activities.iterrows(): #iterate found activities   \n",
    "                emb_acti.append(self.bert_embeddings[\"ocu_plus_space\"][\"h_states\"][actv[\"Activitat\"] + \" \" + actv[\"Espai\"]])\n",
    "                print(self.bert_embeddings[\"ocu_plus_space\"][\"h_states\"][actv[\"Activitat\"] + \" \" + actv[\"Espai\"]].shape)\n",
    "            emb_acti = torch.tensor(emb_acti)\n",
    "            \n",
    "            print(emb_acti.shape)\n",
    "            #return values\n",
    "            return torch.tensor(emb_acti), torch.cat((enc_dt_tens,weather_tens),axis=0) , target_tens\n",
    "\n",
    "        if self.activitivity_encoding_mode == 4:\n",
    "            assert \"NOT IMPLEMENTED YET\"\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = energyProject_dataset(\"data/updated_merged_data.csv\",\"data/ocupacio_enginyeria_2022.csv\",\"data/bert_embedded.pkl\",True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save dataset as pickle so we don't have to run init every time and it is only one file to handle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open a file and use dump()\n",
    "with open('data/dataset_class.pkl', 'wb') as file:\n",
    "    pickle.dump(dataset, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Usage instructions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import dataset class\n",
    "from dataset import energyProject_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load dataset object file\n",
    "import pickle\n",
    "with (open('data/dataset_class.pkl', \"rb\")) as openfile:\n",
    "    dataset = pickle.load(openfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now you can create a dataloader and use it!\n",
    "from torch.utils.data import DataLoader\n",
    "dataloader = DataLoader(dataset, batch_size=100, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': tensor([[2.0220, 0.0172, 0.9999,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [2.0220, 0.0172, 0.9999,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [2.0220, 0.0172, 0.9999,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         ...,\n",
       "         [2.0220, 0.0860, 0.9963,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [2.0220, 0.0860, 0.9963,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [2.0220, 0.0860, 0.9963,  ..., 0.0000, 0.0000, 0.0000]],\n",
       "        dtype=torch.float64),\n",
       " 'y': tensor([[26.5500,  1.6300, 71.3800],\n",
       "         [26.7800,  1.6400, 74.7900],\n",
       "         [27.0800,  1.6300, 70.6500],\n",
       "         [26.7900,  1.6500, 69.7500],\n",
       "         [27.2000,  1.6400, 69.6200],\n",
       "         [27.0300,  1.6500, 71.2400],\n",
       "         [27.4300,  1.6100, 72.7100],\n",
       "         [26.4800,  1.6400, 72.4300],\n",
       "         [25.1300,  1.5000, 70.7000],\n",
       "         [25.9100,  1.5200, 72.1000],\n",
       "         [25.1200,  1.5100, 72.3000],\n",
       "         [26.0700,  1.5200, 75.0000],\n",
       "         [26.5000,  1.4800, 78.6500],\n",
       "         [25.6500,  1.4800, 80.8500],\n",
       "         [25.5800,  1.5000, 81.7500],\n",
       "         [26.4800,  1.4800, 83.6500],\n",
       "         [26.1600,  1.5500, 81.3800],\n",
       "         [26.5700,  1.5500, 78.8100],\n",
       "         [27.5700,  1.6400, 78.8100],\n",
       "         [27.8800,  1.6600, 75.8000],\n",
       "         [27.7600,  1.6300, 75.6000],\n",
       "         [27.3300,  1.6500, 75.0000],\n",
       "         [28.2700,  1.6800, 72.6000],\n",
       "         [27.3000,  1.6100, 72.2900],\n",
       "         [27.0500,  1.6300, 71.2900],\n",
       "         [27.5500,  1.6400, 70.7600],\n",
       "         [27.0500,  1.6500, 71.1400],\n",
       "         [27.6800,  1.6300, 68.6200],\n",
       "         [27.0300,  1.6300, 70.0000],\n",
       "         [27.1000,  1.6300, 69.3300],\n",
       "         [27.8500,  1.6300, 70.4300],\n",
       "         [27.0800,  1.6200, 71.3400],\n",
       "         [25.5000,  1.5900, 69.8500],\n",
       "         [25.5700,  1.4600, 68.8500],\n",
       "         [25.5500,  1.5000, 69.6000],\n",
       "         [25.5000,  1.4800, 73.1000],\n",
       "         [25.6800,  1.4800, 72.7500],\n",
       "         [26.4800,  1.5600, 78.2200],\n",
       "         [26.0500,  1.4900, 76.6200],\n",
       "         [26.1800,  1.4900, 74.0500],\n",
       "         [26.2400,  1.4800, 75.7600],\n",
       "         [26.1800,  1.5900, 75.6500],\n",
       "         [27.8500,  1.6600, 74.8500],\n",
       "         [27.5300,  1.6300, 74.9000],\n",
       "         [27.0300,  1.6100, 74.6500],\n",
       "         [27.5300,  1.6300, 72.4800],\n",
       "         [27.2300,  1.6300, 76.7300],\n",
       "         [28.4300,  1.6300, 70.8500],\n",
       "         [27.2400,  1.6500, 72.1500],\n",
       "         [27.0500,  1.6300, 71.5500],\n",
       "         [27.5400,  1.6300, 70.9500],\n",
       "         [37.7000,  1.6300, 70.2500],\n",
       "         [45.7200,  1.6400, 69.2500],\n",
       "         [44.3300,  1.6200, 69.3500],\n",
       "         [45.0000,  1.6200, 70.1000],\n",
       "         [31.5000,  1.6900, 71.9700],\n",
       "         [30.4800,  1.5400, 71.1900],\n",
       "         [31.5200,  1.5700, 72.3900],\n",
       "         [33.4000,  1.5600, 76.7500],\n",
       "         [33.4500,  1.5800, 78.7500],\n",
       "         [33.4500,  1.5600, 78.2500],\n",
       "         [32.4500,  1.5400, 82.4000],\n",
       "         [33.4500,  1.5900, 79.6000],\n",
       "         [31.2800,  1.5300, 79.6000],\n",
       "         [30.2300,  1.5600, 83.9200],\n",
       "         [29.8500,  1.6200, 81.6200],\n",
       "         [31.9500,  1.7200, 80.1000],\n",
       "         [32.1800,  1.6700, 78.9600],\n",
       "         [31.3300,  1.7100, 77.0500],\n",
       "         [29.9300,  1.6900, 74.9500],\n",
       "         [27.7400,  1.6500, 75.0500],\n",
       "         [27.5300,  1.6300, 72.7500],\n",
       "         [27.0500,  1.6400, 73.8500],\n",
       "         [27.1500,  1.6000, 73.6700],\n",
       "         [27.4500,  1.6400, 71.3800],\n",
       "         [27.0100,  1.6300, 71.9000],\n",
       "         [27.1000,  1.6500, 70.9500],\n",
       "         [37.5500,  1.6300, 72.4500],\n",
       "         [46.2000,  1.6100, 72.0500],\n",
       "         [39.1500,  1.6700, 83.9500],\n",
       "         [29.2300,  1.5800, 76.5500],\n",
       "         [31.2300,  1.5300, 76.9500],\n",
       "         [31.9500,  1.5400, 80.7800],\n",
       "         [32.8000,  1.5700, 82.8100],\n",
       "         [33.1000,  1.5400, 84.7100],\n",
       "         [33.2500,  1.5900, 88.5000],\n",
       "         [32.6500,  1.5400, 84.6000],\n",
       "         [31.4500,  1.5800, 86.5500],\n",
       "         [30.7400,  1.5900, 85.5500],\n",
       "         [30.9800,  1.6200, 87.3000],\n",
       "         [31.7900,  1.7100, 82.1000],\n",
       "         [31.6700,  1.6800, 84.3000],\n",
       "         [30.9800,  1.7000, 79.9000],\n",
       "         [29.7300,  1.6600, 78.0500],\n",
       "         [27.9300,  1.6500, 77.7200],\n",
       "         [28.2000,  1.6300, 74.2900],\n",
       "         [28.4500,  1.6600, 74.8600],\n",
       "         [28.0000,  1.6200, 76.4900],\n",
       "         [27.5500,  1.6100, 74.5500],\n",
       "         [28.0200,  1.6500, 74.3500]], dtype=torch.float64)}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default the dataset is in 0 mode. Here are the modes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m\n",
      "This function will return more than one object depending on the mode it is on.\n",
      "Activity encoding mode:\n",
      "    0: I.very large one-hot encoding of all the combinations of classroom and activity concatenated\n",
      "        with all other features.\n",
      "       II. target values\n",
      "    \n",
      "    1:  I. 0 but first with some PCA applied to reduce dimensionality of \n",
      "        the enormous one-hot encoding.\n",
      "        II. target values\n",
      "    \n",
      "    2: returns four objects, \n",
      "        I.mean_encoding of activity from bert(as many as activities at time stamp), \n",
      "        II. classroom one hot encoding for each activity(as many as activities at time stamp)\n",
      "        III. All other features at that time stamp\n",
      "        IV. target values\n",
      "    \n",
      "    2.5:  returns four objects\n",
      "        I. embedding tensor of activity from bert(as many as activities at time stamp), \n",
      "        II. classroom one hot encoding for each activity(as many as activities at time stamp)\n",
      "        III. All other features at that time stamp\n",
      "        IV. target values\n",
      "    \n",
      "    3: returns three objects,\n",
      "        I. mean encoding of activity, classroom pair through bert (as many as activities at time stamp),\n",
      "        II. All other features at that time stamp\n",
      "        III. target values\n",
      "    \n",
      "    3.5:  returns four objects\n",
      "        I. embedding tensor of activity, classroom pair through bert(as many as activities at time stamp), \n",
      "        II. classroom one hot encoding for each activity(as many as activities at time stamp)\n",
      "        III. All other features at that time stamp\n",
      "        IV. target values\n",
      "    \n",
      "    4: returns three objects, raw data thought for model handling.\n",
      "        I. activities in text form paired with their classroom\n",
      "        II. All other features at that time stamp\n",
      "        III. target values\n",
      "\u001b[0;31mFile:\u001b[0m      ~/Documents/UNI/SYNTHS_PROJECT/energy_analysis_project/dataset.py\n",
      "\u001b[0;31mType:\u001b[0m      method"
     ]
    }
   ],
   "source": [
    "dataset.__getitem__?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To change the dataset mode just do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.activitivity_encoding_mode = 2 #or any value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And you don't even have to update the dataloader!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ocu_ber_emb': tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]], dtype=torch.float64),\n",
       " 'espai_enc': tensor([[53., 53., 53.,  ..., 53., 53., 53.],\n",
       "         [53., 53., 53.,  ..., 53., 53., 53.],\n",
       "         [53., 53., 53.,  ..., 53., 53., 53.],\n",
       "         ...,\n",
       "         [53., 53., 53.,  ..., 53., 53., 53.],\n",
       "         [53., 53., 53.,  ..., 53., 53., 53.],\n",
       "         [53., 53., 53.,  ..., 53., 53., 53.]]),\n",
       " 'general_data': tensor([[2.0220, 0.0172, 0.9999,  ..., 0.4792, 0.4600, 0.6047],\n",
       "         [2.0220, 0.0172, 0.9999,  ..., 0.4583, 0.4400, 0.5814],\n",
       "         [2.0220, 0.0172, 0.9999,  ..., 0.4375, 0.4200, 0.5581],\n",
       "         ...,\n",
       "         [2.0220, 0.0860, 0.9963,  ..., 0.3333, 0.3200, 0.9535],\n",
       "         [2.0220, 0.0860, 0.9963,  ..., 0.3125, 0.3000, 0.9535],\n",
       "         [2.0220, 0.0860, 0.9963,  ..., 0.2917, 0.2800, 0.9419]],\n",
       "        dtype=torch.float64),\n",
       " 'y': tensor([[26.5500,  1.6300, 71.3800],\n",
       "         [26.7800,  1.6400, 74.7900],\n",
       "         [27.0800,  1.6300, 70.6500],\n",
       "         [26.7900,  1.6500, 69.7500],\n",
       "         [27.2000,  1.6400, 69.6200],\n",
       "         [27.0300,  1.6500, 71.2400],\n",
       "         [27.4300,  1.6100, 72.7100],\n",
       "         [26.4800,  1.6400, 72.4300],\n",
       "         [25.1300,  1.5000, 70.7000],\n",
       "         [25.9100,  1.5200, 72.1000],\n",
       "         [25.1200,  1.5100, 72.3000],\n",
       "         [26.0700,  1.5200, 75.0000],\n",
       "         [26.5000,  1.4800, 78.6500],\n",
       "         [25.6500,  1.4800, 80.8500],\n",
       "         [25.5800,  1.5000, 81.7500],\n",
       "         [26.4800,  1.4800, 83.6500],\n",
       "         [26.1600,  1.5500, 81.3800],\n",
       "         [26.5700,  1.5500, 78.8100],\n",
       "         [27.5700,  1.6400, 78.8100],\n",
       "         [27.8800,  1.6600, 75.8000],\n",
       "         [27.7600,  1.6300, 75.6000],\n",
       "         [27.3300,  1.6500, 75.0000],\n",
       "         [28.2700,  1.6800, 72.6000],\n",
       "         [27.3000,  1.6100, 72.2900],\n",
       "         [27.0500,  1.6300, 71.2900],\n",
       "         [27.5500,  1.6400, 70.7600],\n",
       "         [27.0500,  1.6500, 71.1400],\n",
       "         [27.6800,  1.6300, 68.6200],\n",
       "         [27.0300,  1.6300, 70.0000],\n",
       "         [27.1000,  1.6300, 69.3300],\n",
       "         [27.8500,  1.6300, 70.4300],\n",
       "         [27.0800,  1.6200, 71.3400],\n",
       "         [25.5000,  1.5900, 69.8500],\n",
       "         [25.5700,  1.4600, 68.8500],\n",
       "         [25.5500,  1.5000, 69.6000],\n",
       "         [25.5000,  1.4800, 73.1000],\n",
       "         [25.6800,  1.4800, 72.7500],\n",
       "         [26.4800,  1.5600, 78.2200],\n",
       "         [26.0500,  1.4900, 76.6200],\n",
       "         [26.1800,  1.4900, 74.0500],\n",
       "         [26.2400,  1.4800, 75.7600],\n",
       "         [26.1800,  1.5900, 75.6500],\n",
       "         [27.8500,  1.6600, 74.8500],\n",
       "         [27.5300,  1.6300, 74.9000],\n",
       "         [27.0300,  1.6100, 74.6500],\n",
       "         [27.5300,  1.6300, 72.4800],\n",
       "         [27.2300,  1.6300, 76.7300],\n",
       "         [28.4300,  1.6300, 70.8500],\n",
       "         [27.2400,  1.6500, 72.1500],\n",
       "         [27.0500,  1.6300, 71.5500],\n",
       "         [27.5400,  1.6300, 70.9500],\n",
       "         [37.7000,  1.6300, 70.2500],\n",
       "         [45.7200,  1.6400, 69.2500],\n",
       "         [44.3300,  1.6200, 69.3500],\n",
       "         [45.0000,  1.6200, 70.1000],\n",
       "         [31.5000,  1.6900, 71.9700],\n",
       "         [30.4800,  1.5400, 71.1900],\n",
       "         [31.5200,  1.5700, 72.3900],\n",
       "         [33.4000,  1.5600, 76.7500],\n",
       "         [33.4500,  1.5800, 78.7500],\n",
       "         [33.4500,  1.5600, 78.2500],\n",
       "         [32.4500,  1.5400, 82.4000],\n",
       "         [33.4500,  1.5900, 79.6000],\n",
       "         [31.2800,  1.5300, 79.6000],\n",
       "         [30.2300,  1.5600, 83.9200],\n",
       "         [29.8500,  1.6200, 81.6200],\n",
       "         [31.9500,  1.7200, 80.1000],\n",
       "         [32.1800,  1.6700, 78.9600],\n",
       "         [31.3300,  1.7100, 77.0500],\n",
       "         [29.9300,  1.6900, 74.9500],\n",
       "         [27.7400,  1.6500, 75.0500],\n",
       "         [27.5300,  1.6300, 72.7500],\n",
       "         [27.0500,  1.6400, 73.8500],\n",
       "         [27.1500,  1.6000, 73.6700],\n",
       "         [27.4500,  1.6400, 71.3800],\n",
       "         [27.0100,  1.6300, 71.9000],\n",
       "         [27.1000,  1.6500, 70.9500],\n",
       "         [37.5500,  1.6300, 72.4500],\n",
       "         [46.2000,  1.6100, 72.0500],\n",
       "         [39.1500,  1.6700, 83.9500],\n",
       "         [29.2300,  1.5800, 76.5500],\n",
       "         [31.2300,  1.5300, 76.9500],\n",
       "         [31.9500,  1.5400, 80.7800],\n",
       "         [32.8000,  1.5700, 82.8100],\n",
       "         [33.1000,  1.5400, 84.7100],\n",
       "         [33.2500,  1.5900, 88.5000],\n",
       "         [32.6500,  1.5400, 84.6000],\n",
       "         [31.4500,  1.5800, 86.5500],\n",
       "         [30.7400,  1.5900, 85.5500],\n",
       "         [30.9800,  1.6200, 87.3000],\n",
       "         [31.7900,  1.7100, 82.1000],\n",
       "         [31.6700,  1.6800, 84.3000],\n",
       "         [30.9800,  1.7000, 79.9000],\n",
       "         [29.7300,  1.6600, 78.0500],\n",
       "         [27.9300,  1.6500, 77.7200],\n",
       "         [28.2000,  1.6300, 74.2900],\n",
       "         [28.4500,  1.6600, 74.8600],\n",
       "         [28.0000,  1.6200, 76.4900],\n",
       "         [27.5500,  1.6100, 74.5500],\n",
       "         [28.0200,  1.6500, 74.3500]], dtype=torch.float64)}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(dataloader))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.9 ('ML')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "da600ade1a771c82ddf6d22a5a41f856afbf3528a3611e1c80e3ac6da17c9450"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
