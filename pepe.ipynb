{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import dataset class\n",
    "from dataset import energyProject_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import yaml\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mharadai\u001b[0m (\u001b[33menergy_project_uab\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "!wandb login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load dataset object file\n",
    "with (open('data/dataset_class.pkl', \"rb\")) as openfile:\n",
    "    dataset = pickle.load(openfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now you can create a dataloader and use it!\n",
    "dataloader = DataLoader(dataset, batch_size=100, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m\n",
      "This function will return more than one object depending on the mode it is on.\n",
      "Activity encoding mode:\n",
      "    0: I.very large one-hot encoding of all the combinations of classroom and activity concatenated\n",
      "        with all other features.\n",
      "       II. target values\n",
      "    \n",
      "    1:  I. 0 but first with some PCA applied to reduce dimensionality of \n",
      "        the enormous one-hot encoding.\n",
      "        II. target values\n",
      "    \n",
      "    2: returns four objects, \n",
      "        I.mean_encoding of activity from bert(as many as activities at time stamp), \n",
      "        II. classroom one hot encoding for each activity(as many as activities at time stamp)\n",
      "        III. All other features at that time stamp\n",
      "        IV. target values\n",
      "    \n",
      "    2.5:  returns four objects\n",
      "        I. embedding tensor of activity from bert(as many as activities at time stamp), \n",
      "        II. classroom one hot encoding for each activity(as many as activities at time stamp)\n",
      "        III. All other features at that time stamp\n",
      "        IV. target values\n",
      "    \n",
      "    3: returns three objects,\n",
      "        I. mean encoding of activity, classroom pair through bert (as many as activities at time stamp),\n",
      "        II. All other features at that time stamp\n",
      "        III. target values\n",
      "    \n",
      "    3.5:  returns four objects\n",
      "        I. embedding tensor of activity, classroom pair through bert(as many as activities at time stamp), \n",
      "        II. classroom one hot encoding for each activity(as many as activities at time stamp)\n",
      "        III. All other features at that time stamp\n",
      "        IV. target values\n",
      "    \n",
      "    4: returns three objects, raw data thought for model handling.\n",
      "        I. activities in text form paired with their classroom\n",
      "        II. All other features at that time stamp\n",
      "        III. target values\n",
      "\u001b[0;31mFile:\u001b[0m      ~/Documents/UNI/SYNTHS_PROJECT/energy_analysis_project/dataset.py\n",
      "\u001b[0;31mType:\u001b[0m      method"
     ]
    }
   ],
   "source": [
    "dataset.__getitem__?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.activitivity_encoding_mode = 2 #or any value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#batch of 100:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'ocu_ber_emb'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mocu_ber_emb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[0;31mKeyError\u001b[0m: 'ocu_ber_emb'"
     ]
    }
   ],
   "source": [
    "next(iter(dataloader))[\"ocu_ber_emb\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[53., 53., 53.,  ..., 53., 53., 53.],\n",
       "        [53., 53., 53.,  ..., 53., 53., 53.],\n",
       "        [53., 53., 53.,  ..., 53., 53., 53.],\n",
       "        ...,\n",
       "        [53., 53., 53.,  ..., 53., 53., 53.],\n",
       "        [53., 53., 53.,  ..., 53., 53., 53.],\n",
       "        [53., 53., 53.,  ..., 53., 53., 53.]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(dataloader))[\"espai_enc\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 21])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(dataloader))[\"general_data\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset.espais_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 3])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(dataloader))[\"y\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from icecream import ic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "BERT_DIM_EMB = 768\n",
    "TIME_CLIMATE_DIM = 21\n",
    "#classe = activitat + espai encoded\n",
    "\n",
    "class attentive_model_pepemarti(nn.Module):\n",
    "    def __init__(self, espai_emb_dim,hidden_dim,lstm_nl,target_dim):\n",
    "        super(attentive_model_pepemarti, self).__init__()\n",
    "        self.espai_emb_dim = espai_emb_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.lstm_nl = lstm_nl\n",
    "\n",
    "        self.espai_emb = nn.Embedding(num_embeddings=len(dataset.espais_vocab),embedding_dim=espai_emb_dim)\n",
    "        self.classe_repr = nn.Sequential(\n",
    "            nn.Linear(in_features=BERT_DIM_EMB+espai_emb_dim,out_features=601),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=601,out_features=256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=256,out_features=51),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=51,out_features=TIME_CLIMATE_DIM),\n",
    "            nn.Softmax(dim=-1)\n",
    "        )\n",
    "\n",
    "        self.key_gen =  nn.Sequential(\n",
    "            nn.Linear(in_features=TIME_CLIMATE_DIM,out_features=40),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=40,out_features=hidden_dim),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.val_gen =  nn.Sequential(\n",
    "            nn.Linear(in_features=TIME_CLIMATE_DIM,out_features=40),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=40,out_features=hidden_dim),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.query_gen =  nn.Sequential(\n",
    "            nn.Linear(in_features=TIME_CLIMATE_DIM,out_features=40),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=40,out_features=hidden_dim),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        self.multihead_attn = nn.MultiheadAttention(hidden_dim,3,batch_first=True)\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size=hidden_dim, hidden_size=hidden_dim, num_layers=self.lstm_nl, dropout=0, batch_first=True) #input -> BATCH, SEQ_LENGHT, EMBEDDING_DIM\n",
    "        \n",
    "        self.regressFC = nn.Sequential(\n",
    "            nn.Linear(in_features=self.hidden_dim,out_features=64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=64,out_features=256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=256,out_features=64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=64,out_features=16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=16,out_features=target_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self,ocu_ber_emb,espai_enc,general_data,h,c):\n",
    "        #embedd the espais\n",
    "        espai_emb = self.espai_emb(espai_enc.to(torch.int)).float()\n",
    "        #concatenate activity and espai vector\n",
    "        act_cat_espai = torch.cat((ocu_ber_emb,espai_emb),axis=2)\n",
    "\n",
    "        #pass act_cat_espai through a FC to have a \"classe\" representation\n",
    "        classe_repr = self.classe_repr(act_cat_espai.float())\n",
    "    \n",
    "        #get this representation and multiply it with the general data \"sort of attention here\"\n",
    "        #first extend the general data so we have a pair for each class vector\n",
    "        general_rep = general_data.unsqueeze(1).repeat(1, 34, 1)\n",
    "        general_at_per_class = general_rep * classe_repr #element wise multiplication\n",
    "        general_at_per_class = general_at_per_class.float() #convert to float32\n",
    "\n",
    "        key = self.key_gen(general_at_per_class) #generate key with FC\n",
    "        value = self.val_gen(general_at_per_class) #generate value with FC\n",
    "        query = self.query_gen(general_at_per_class) #generate query with FC\n",
    "        \n",
    "        att_mask = torch.sum(ocu_ber_emb,axis=2) != 0.0 #look for what values have to enter. The ones that aren't padding\n",
    "        att_mask = att_mask.unsqueeze(1)\n",
    "        att_mask = att_mask.repeat(3, att_mask.shape[2], 1)#repeat 3 times along batch dim because we have three heads. The other repeat is because we need it to be of shape seqlenxseqlen \n",
    "        output, _ =  self.multihead_attn(key=key, value=value, query=query,attn_mask=att_mask)\n",
    "        output = torch.sum(output,axis=1)\n",
    "\n",
    "        #create extra to output be a sequence of 1\n",
    "        output = output.unsqueeze(1)\n",
    "        \n",
    "        #pass this as the inital state to a LSTM\n",
    "        out, (h,c) = self.lstm(output, (h,c))\n",
    "        out =  self.regressFC(out).float()\n",
    "        return out, h, c\n",
    "    \n",
    "    def init_hidden(self,batch_size):\n",
    "        # Initialize the hidden state and cell state with zeros\n",
    "        h = torch.zeros(self.lstm_nl, batch_size, self.hidden_dim,dtype=torch.float32)\n",
    "        c = torch.zeros(self.lstm_nl, batch_size, self.hidden_dim,dtype=torch.float32)\n",
    "        return h, c\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcount_parameters\u001b[39m(model):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msum\u001b[39m(p\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mparameters() \u001b[38;5;28;01mif\u001b[39;00m p\u001b[38;5;241m.\u001b[39mrequires_grad)\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe model has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcount_parameters(\u001b[43mmodel\u001b[49m)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m trainable parameters\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = attentive_model_pepemarti(espai_emb_dim=30,hidden_dim=30,lstm_nl=1,target_dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 100, 30])"
      ]
     },
     "execution_count": 532,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h, c = model.init_hidden(batch_size)\n",
    "c.shape\n",
    "#model.forward(sample[\"ocu_ber_emb\"],sample[\"espai_enc\"],sample[\"general_data\"],h,c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define train function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"mps\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = attentive_model_pepemarti(espai_emb_dim=30,hidden_dim=30,lstm_nl=1,target_dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now you can create a dataloader and use it!\n",
    "batch_size = 100\n",
    "dataloader = DataLoader(dataset, batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "def train(dataloader, model, batch_size, num_epochs):\n",
    "    model.train()\n",
    "\n",
    "    criterion =  nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    losses = []\n",
    "    for epoch in range(num_epochs):\n",
    "        for batch, data in enumerate(dataloader):\n",
    "            ocu_emb, espai_enc, general_data = data[\"ocu_ber_emb\"].float().to(device) ,data[\"espai_enc\"].float().to(device) ,data[\"general_data\"].float().to(device)\n",
    "            y = data[\"y\"][:,0].float().to(device) #we'll do one counter for now\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            #current batch size size\n",
    "            b_sz = ocu_emb.shape[0]\n",
    "\n",
    "            #note the dataloader with a batch of 100 when reachs the end expects a batch of 60\n",
    "            h, c = model.init_hidden(b_sz) # Start with a new state in each batch            \n",
    "            h = h.to(device)\n",
    "            c = c.to(device)\n",
    "\n",
    "            try:\n",
    "                y_pred, h,c= model(ocu_emb, espai_enc, general_data, h, c)\n",
    "            except:\n",
    "                print(\"error!\")\n",
    "                ic(batch)\n",
    "                ic(ocu_emb.shape)\n",
    "                ic(espai_enc.shape)\n",
    "                ic(general_data.shape)\n",
    "                ic(h.shape)\n",
    "                ic(c.shape)\n",
    "                y_pred, h,c= model(ocu_emb, espai_enc, general_data, h, c)\n",
    "            y_pred = y_pred[:,0,0]\n",
    "            loss = criterion(y_pred,y)  #cross entropy loss needs (N,C,seq_lenght)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if batch%30 == 0:\n",
    "                print({ 'epoch': epoch, 'batch': batch, 'loss': loss.item() })\n",
    "                losses.append(loss.item())\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'batch': 0, 'loss': 886.621826171875}\n",
      "{'epoch': 0, 'batch': 30, 'loss': 6231.90380859375}\n",
      "{'epoch': 0, 'batch': 60, 'loss': 6700.3837890625}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m\n\u001b[0;32m----> 2\u001b[0m losses \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[15], line 10\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(dataloader, model, batch_size, num_epochs)\u001b[0m\n\u001b[1;32m      8\u001b[0m losses \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[0;32m---> 10\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dataloader):\n\u001b[1;32m     11\u001b[0m         ocu_emb, espai_enc, general_data \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mocu_ber_emb\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mto(device) ,data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mespai_enc\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mto(device) ,data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeneral_data\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     12\u001b[0m         y \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m][:,\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mto(device) \u001b[38;5;66;03m#we'll do one counter for now\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/ML/lib/python3.10/site-packages/torch/utils/data/dataloader.py:634\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    632\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    633\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 634\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    635\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    636\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    638\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniforge3/envs/ML/lib/python3.10/site-packages/torch/utils/data/dataloader.py:678\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    676\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    677\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 678\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    679\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    680\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/miniforge3/envs/ML/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/miniforge3/envs/ML/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/Documents/UNI/SYNTHS_PROJECT/energy_analysis_project/dataset.py:245\u001b[0m, in \u001b[0;36menergyProject_dataset.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    242\u001b[0m enc_dt_tens \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdatetime_enc(row[\u001b[39m\"\u001b[39m\u001b[39mdate\u001b[39m\u001b[39m\"\u001b[39m],row[\u001b[39m\"\u001b[39m\u001b[39mtime\u001b[39m\u001b[39m\"\u001b[39m]) \u001b[39m#date-time encoding\u001b[39;00m\n\u001b[1;32m    244\u001b[0m \u001b[39m#weather data tensor\u001b[39;00m\n\u001b[0;32m--> 245\u001b[0m weather_tens \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(row\u001b[39m.\u001b[39;49mdrop([\u001b[39m\"\u001b[39;49m\u001b[39mdate\u001b[39;49m\u001b[39m\"\u001b[39;49m,\u001b[39m\"\u001b[39;49m\u001b[39mtime\u001b[39;49m\u001b[39m\"\u001b[39;49m,\u001b[39m\"\u001b[39;49m\u001b[39mQ-Enginyeria (Cos Central) [kWh] [Q-Enginyeria]\u001b[39;49m\u001b[39m\"\u001b[39;49m,\u001b[39m\"\u001b[39;49m\u001b[39mQ-Enginyeria (Espina 4) [kWh] [Q-Enginyeria]\u001b[39;49m\u001b[39m\"\u001b[39;49m,\u001b[39m\"\u001b[39;49m\u001b[39mQ-Enginyeria (Química) [kWh] [Q-Enginyeria]\u001b[39;49m\u001b[39m\"\u001b[39;49m]))\n\u001b[1;32m    247\u001b[0m \u001b[39m#second get the target values tensor\u001b[39;00m\n\u001b[1;32m    248\u001b[0m target_tens \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(row[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_labels])\n",
      "File \u001b[0;32m~/miniforge3/envs/ML/lib/python3.10/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniforge3/envs/ML/lib/python3.10/site-packages/pandas/core/series.py:5237\u001b[0m, in \u001b[0;36mSeries.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   5140\u001b[0m \u001b[39m@deprecate_nonkeyword_arguments\u001b[39m(version\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, allowed_args\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mself\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mlabels\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m   5141\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdrop\u001b[39m(  \u001b[39m# type: ignore[override]\u001b[39;00m\n\u001b[1;32m   5142\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5149\u001b[0m     errors: IgnoreRaise \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   5150\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Series \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   5151\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   5152\u001b[0m \u001b[39m    Return Series with specified index labels removed.\u001b[39;00m\n\u001b[1;32m   5153\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5235\u001b[0m \u001b[39m    dtype: float64\u001b[39;00m\n\u001b[1;32m   5236\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 5237\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mdrop(\n\u001b[1;32m   5238\u001b[0m         labels\u001b[39m=\u001b[39;49mlabels,\n\u001b[1;32m   5239\u001b[0m         axis\u001b[39m=\u001b[39;49maxis,\n\u001b[1;32m   5240\u001b[0m         index\u001b[39m=\u001b[39;49mindex,\n\u001b[1;32m   5241\u001b[0m         columns\u001b[39m=\u001b[39;49mcolumns,\n\u001b[1;32m   5242\u001b[0m         level\u001b[39m=\u001b[39;49mlevel,\n\u001b[1;32m   5243\u001b[0m         inplace\u001b[39m=\u001b[39;49minplace,\n\u001b[1;32m   5244\u001b[0m         errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m   5245\u001b[0m     )\n",
      "File \u001b[0;32m~/miniforge3/envs/ML/lib/python3.10/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniforge3/envs/ML/lib/python3.10/site-packages/pandas/core/generic.py:4505\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4503\u001b[0m \u001b[39mfor\u001b[39;00m axis, labels \u001b[39min\u001b[39;00m axes\u001b[39m.\u001b[39mitems():\n\u001b[1;32m   4504\u001b[0m     \u001b[39mif\u001b[39;00m labels \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 4505\u001b[0m         obj \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39;49m_drop_axis(labels, axis, level\u001b[39m=\u001b[39;49mlevel, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[1;32m   4507\u001b[0m \u001b[39mif\u001b[39;00m inplace:\n\u001b[1;32m   4508\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[0;32m~/miniforge3/envs/ML/lib/python3.10/site-packages/pandas/core/generic.py:4547\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[0;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[1;32m   4545\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   4546\u001b[0m         new_axis \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39mdrop(labels, errors\u001b[39m=\u001b[39merrors)\n\u001b[0;32m-> 4547\u001b[0m     indexer \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39;49mget_indexer(new_axis)\n\u001b[1;32m   4549\u001b[0m \u001b[39m# Case for non-unique axis\u001b[39;00m\n\u001b[1;32m   4550\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   4551\u001b[0m     is_tuple_labels \u001b[39m=\u001b[39m is_nested_list_like(labels) \u001b[39mor\u001b[39;00m \u001b[39misinstance\u001b[39m(labels, \u001b[39mtuple\u001b[39m)\n",
      "File \u001b[0;32m~/miniforge3/envs/ML/lib/python3.10/site-packages/pandas/core/indexes/base.py:3909\u001b[0m, in \u001b[0;36mIndex.get_indexer\u001b[0;34m(self, target, method, limit, tolerance)\u001b[0m\n\u001b[1;32m   3906\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(target) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   3907\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39marray([], dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mintp)\n\u001b[0;32m-> 3909\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_should_compare(target) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_should_partial_index(target):\n\u001b[1;32m   3910\u001b[0m     \u001b[39m# IntervalIndex get special treatment bc numeric scalars can be\u001b[39;00m\n\u001b[1;32m   3911\u001b[0m     \u001b[39m#  matched to Interval scalars\u001b[39;00m\n\u001b[1;32m   3912\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_indexer_non_comparable(target, method\u001b[39m=\u001b[39mmethod, unique\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m   3914\u001b[0m \u001b[39mif\u001b[39;00m is_categorical_dtype(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdtype):\n\u001b[1;32m   3915\u001b[0m     \u001b[39m# _maybe_cast_listlike_indexer ensures target has our dtype\u001b[39;00m\n\u001b[1;32m   3916\u001b[0m     \u001b[39m#  (could improve perf by doing _should_compare check earlier?)\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/ML/lib/python3.10/site-packages/pandas/core/indexes/base.py:6291\u001b[0m, in \u001b[0;36mIndex._should_compare\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m   6285\u001b[0m \u001b[39m@final\u001b[39m\n\u001b[1;32m   6286\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_should_compare\u001b[39m(\u001b[39mself\u001b[39m, other: Index) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mbool\u001b[39m:\n\u001b[1;32m   6287\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   6288\u001b[0m \u001b[39m    Check if `self == other` can ever have non-False entries.\u001b[39;00m\n\u001b[1;32m   6289\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 6291\u001b[0m     \u001b[39mif\u001b[39;00m (other\u001b[39m.\u001b[39;49mis_boolean() \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_numeric()) \u001b[39mor\u001b[39;00m (\n\u001b[1;32m   6292\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_boolean() \u001b[39mand\u001b[39;00m other\u001b[39m.\u001b[39mis_numeric()\n\u001b[1;32m   6293\u001b[0m     ):\n\u001b[1;32m   6294\u001b[0m         \u001b[39m# GH#16877 Treat boolean labels passed to a numeric index as not\u001b[39;00m\n\u001b[1;32m   6295\u001b[0m         \u001b[39m#  found. Without this fix False and True would be treated as 0 and 1\u001b[39;00m\n\u001b[1;32m   6296\u001b[0m         \u001b[39m#  respectively.\u001b[39;00m\n\u001b[1;32m   6297\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   6299\u001b[0m     other \u001b[39m=\u001b[39m unpack_nested_dtype(other)\n",
      "File \u001b[0;32m~/miniforge3/envs/ML/lib/python3.10/site-packages/pandas/core/indexes/base.py:2455\u001b[0m, in \u001b[0;36mIndex.is_boolean\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2421\u001b[0m \u001b[39m@final\u001b[39m\n\u001b[1;32m   2422\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mis_boolean\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mbool\u001b[39m:\n\u001b[1;32m   2423\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   2424\u001b[0m \u001b[39m    Check if the Index only consists of booleans.\u001b[39;00m\n\u001b[1;32m   2425\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2453\u001b[0m \u001b[39m    False\u001b[39;00m\n\u001b[1;32m   2454\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2455\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minferred_type \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mboolean\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/miniforge3/envs/ML/lib/python3.10/site-packages/pandas/_libs/properties.pyx:36\u001b[0m, in \u001b[0;36mpandas._libs.properties.CachedProperty.__get__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniforge3/envs/ML/lib/python3.10/site-packages/pandas/core/indexes/base.py:2750\u001b[0m, in \u001b[0;36mIndex.inferred_type\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2745\u001b[0m \u001b[39m@cache_readonly\u001b[39m\n\u001b[1;32m   2746\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minferred_type\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m str_t:\n\u001b[1;32m   2747\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   2748\u001b[0m \u001b[39m    Return a string of the type inferred from the values.\u001b[39;00m\n\u001b[1;32m   2749\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2750\u001b[0m     \u001b[39mreturn\u001b[39;00m lib\u001b[39m.\u001b[39;49minfer_dtype(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_values, skipna\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/miniforge3/envs/ML/lib/python3.10/site-packages/pandas/_libs/lib.pyx:1493\u001b[0m, in \u001b[0;36mpandas._libs.lib.infer_dtype\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniforge3/envs/ML/lib/python3.10/site-packages/pandas/_libs/lib.pyx:1349\u001b[0m, in \u001b[0;36mpandas._libs.lib._try_infer_map\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniforge3/envs/ML/lib/python3.10/site-packages/numpy/core/_dtype.py:358\u001b[0m, in \u001b[0;36m_name_get\u001b[0;34m(dtype)\u001b[0m\n\u001b[1;32m    355\u001b[0m     name \u001b[39m=\u001b[39m _kind_name(dtype)\n\u001b[1;32m    357\u001b[0m \u001b[39m# append bit counts\u001b[39;00m\n\u001b[0;32m--> 358\u001b[0m \u001b[39mif\u001b[39;00m _name_includes_bit_suffix(dtype):\n\u001b[1;32m    359\u001b[0m     name \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(dtype\u001b[39m.\u001b[39mitemsize \u001b[39m*\u001b[39m \u001b[39m8\u001b[39m)\n\u001b[1;32m    361\u001b[0m \u001b[39m# append metadata to datetimes\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 20\n",
    "losses = train(dataloader, model, batch_size=100, num_epochs=num_epochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.9 ('ML')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "da600ade1a771c82ddf6d22a5a41f856afbf3528a3611e1c80e3ac6da17c9450"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
